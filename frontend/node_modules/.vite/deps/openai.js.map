{
  "version": 3,
  "sources": ["../../openai/src/version.ts", "../../openai/src/_shims/registry.ts", "../../openai/src/_shims/MultipartBody.ts", "../../openai/src/_shims/web-runtime.ts", "../../openai/_shims/index.mjs", "../../openai/src/error.ts", "../../openai/src/streaming.ts", "../../openai/src/uploads.ts", "../../openai/src/core.ts", "../../openai/src/pagination.ts", "../../openai/src/resource.ts", "../../openai/src/resources/chat/completions.ts", "../../openai/src/resources/chat/chat.ts", "../../openai/src/resources/audio/speech.ts", "../../openai/src/resources/audio/transcriptions.ts", "../../openai/src/resources/audio/translations.ts", "../../openai/src/resources/audio/audio.ts", "../../openai/src/resources/beta/assistants/files.ts", "../../openai/src/resources/beta/assistants/assistants.ts", "../../openai/src/lib/RunnableFunction.ts", "../../openai/src/lib/chatCompletionUtils.ts", "../../openai/src/lib/AbstractChatCompletionRunner.ts", "../../openai/src/lib/ChatCompletionRunner.ts", "../../openai/src/lib/ChatCompletionStream.ts", "../../openai/src/lib/ChatCompletionStreamingRunner.ts", "../../openai/src/resources/beta/chat/completions.ts", "../../openai/src/resources/beta/chat/chat.ts", "../../openai/src/resources/beta/threads/messages/files.ts", "../../openai/src/resources/beta/threads/messages/messages.ts", "../../openai/src/resources/beta/threads/runs/steps.ts", "../../openai/src/resources/beta/threads/runs/runs.ts", "../../openai/src/resources/beta/threads/threads.ts", "../../openai/src/resources/beta/beta.ts", "../../openai/src/resources/completions.ts", "../../openai/src/resources/embeddings.ts", "../../openai/src/resources/files.ts", "../../openai/src/resources/fine-tuning/jobs.ts", "../../openai/src/resources/fine-tuning/fine-tuning.ts", "../../openai/src/resources/images.ts", "../../openai/src/resources/models.ts", "../../openai/src/resources/moderations.ts", "../../openai/src/index.ts"],
  "sourcesContent": ["export const VERSION = '4.28.0'; // x-release-please-version\r\n", "/**\r\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\r\n */\r\nimport { type RequestOptions } from '../core';\r\n\r\nexport interface Shims {\r\n  kind: string;\r\n  fetch: any;\r\n  Request: any;\r\n  Response: any;\r\n  Headers: any;\r\n  FormData: any;\r\n  Blob: any;\r\n  File: any;\r\n  ReadableStream: any;\r\n  getMultipartRequestOptions: <T = Record<string, unknown>>(\r\n    form: Shims['FormData'],\r\n    opts: RequestOptions<T>,\r\n  ) => Promise<RequestOptions<T>>;\r\n  getDefaultAgent: (url: string) => any;\r\n  fileFromPath:\r\n    | ((path: string, filename?: string, options?: {}) => Promise<Shims['File']>)\r\n    | ((path: string, options?: {}) => Promise<Shims['File']>);\r\n  isFsReadStream: (value: any) => boolean;\r\n}\r\n\r\nexport let auto = false;\r\nexport let kind: Shims['kind'] | undefined = undefined;\r\nexport let fetch: Shims['fetch'] | undefined = undefined;\r\nexport let Request: Shims['Request'] | undefined = undefined;\r\nexport let Response: Shims['Response'] | undefined = undefined;\r\nexport let Headers: Shims['Headers'] | undefined = undefined;\r\nexport let FormData: Shims['FormData'] | undefined = undefined;\r\nexport let Blob: Shims['Blob'] | undefined = undefined;\r\nexport let File: Shims['File'] | undefined = undefined;\r\nexport let ReadableStream: Shims['ReadableStream'] | undefined = undefined;\r\nexport let getMultipartRequestOptions: Shims['getMultipartRequestOptions'] | undefined = undefined;\r\nexport let getDefaultAgent: Shims['getDefaultAgent'] | undefined = undefined;\r\nexport let fileFromPath: Shims['fileFromPath'] | undefined = undefined;\r\nexport let isFsReadStream: Shims['isFsReadStream'] | undefined = undefined;\r\n\r\nexport function setShims(shims: Shims, options: { auto: boolean } = { auto: false }) {\r\n  if (auto) {\r\n    throw new Error(\r\n      `you must \\`import 'openai/shims/${shims.kind}'\\` before importing anything else from openai`,\r\n    );\r\n  }\r\n  if (kind) {\r\n    throw new Error(`can't \\`import 'openai/shims/${shims.kind}'\\` after \\`import 'openai/shims/${kind}'\\``);\r\n  }\r\n  auto = options.auto;\r\n  kind = shims.kind;\r\n  fetch = shims.fetch;\r\n  Request = shims.Request;\r\n  Response = shims.Response;\r\n  Headers = shims.Headers;\r\n  FormData = shims.FormData;\r\n  Blob = shims.Blob;\r\n  File = shims.File;\r\n  ReadableStream = shims.ReadableStream;\r\n  getMultipartRequestOptions = shims.getMultipartRequestOptions;\r\n  getDefaultAgent = shims.getDefaultAgent;\r\n  fileFromPath = shims.fileFromPath;\r\n  isFsReadStream = shims.isFsReadStream;\r\n}\r\n", "/**\r\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\r\n */\r\nexport class MultipartBody {\r\n  constructor(public body: any) {}\r\n  get [Symbol.toStringTag](): string {\r\n    return 'MultipartBody';\r\n  }\r\n}\r\n", "/**\r\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\r\n */\r\nimport { MultipartBody } from './MultipartBody';\r\nimport { type RequestOptions } from '../core';\r\nimport { type Shims } from './registry';\r\n\r\nexport function getRuntime({ manuallyImported }: { manuallyImported?: boolean } = {}): Shims {\r\n  const recommendation =\r\n    manuallyImported ?\r\n      `You may need to use polyfills`\r\n    : `Add one of these imports before your first \\`import â€¦ from 'openai'\\`:\r\n- \\`import 'openai/shims/node'\\` (if you're running on Node)\r\n- \\`import 'openai/shims/web'\\` (otherwise)\r\n`;\r\n\r\n  let _fetch, _Request, _Response, _Headers;\r\n  try {\r\n    // @ts-ignore\r\n    _fetch = fetch;\r\n    // @ts-ignore\r\n    _Request = Request;\r\n    // @ts-ignore\r\n    _Response = Response;\r\n    // @ts-ignore\r\n    _Headers = Headers;\r\n  } catch (error) {\r\n    throw new Error(\r\n      `this environment is missing the following Web Fetch API type: ${\r\n        (error as any).message\r\n      }. ${recommendation}`,\r\n    );\r\n  }\r\n\r\n  return {\r\n    kind: 'web',\r\n    fetch: _fetch,\r\n    Request: _Request,\r\n    Response: _Response,\r\n    Headers: _Headers,\r\n    FormData:\r\n      // @ts-ignore\r\n      typeof FormData !== 'undefined' ? FormData : (\r\n        class FormData {\r\n          // @ts-ignore\r\n          constructor() {\r\n            throw new Error(\r\n              `file uploads aren't supported in this environment yet as 'FormData' is undefined. ${recommendation}`,\r\n            );\r\n          }\r\n        }\r\n      ),\r\n    Blob:\r\n      typeof Blob !== 'undefined' ? Blob : (\r\n        class Blob {\r\n          constructor() {\r\n            throw new Error(\r\n              `file uploads aren't supported in this environment yet as 'Blob' is undefined. ${recommendation}`,\r\n            );\r\n          }\r\n        }\r\n      ),\r\n    File:\r\n      // @ts-ignore\r\n      typeof File !== 'undefined' ? File : (\r\n        class File {\r\n          // @ts-ignore\r\n          constructor() {\r\n            throw new Error(\r\n              `file uploads aren't supported in this environment yet as 'File' is undefined. ${recommendation}`,\r\n            );\r\n          }\r\n        }\r\n      ),\r\n    ReadableStream:\r\n      // @ts-ignore\r\n      typeof ReadableStream !== 'undefined' ? ReadableStream : (\r\n        class ReadableStream {\r\n          // @ts-ignore\r\n          constructor() {\r\n            throw new Error(\r\n              `streaming isn't supported in this environment yet as 'ReadableStream' is undefined. ${recommendation}`,\r\n            );\r\n          }\r\n        }\r\n      ),\r\n    getMultipartRequestOptions: async <T = Record<string, unknown>>(\r\n      // @ts-ignore\r\n      form: FormData,\r\n      opts: RequestOptions<T>,\r\n    ): Promise<RequestOptions<T>> => ({\r\n      ...opts,\r\n      body: new MultipartBody(form) as any,\r\n    }),\r\n    getDefaultAgent: (url: string) => undefined,\r\n    fileFromPath: () => {\r\n      throw new Error(\r\n        'The `fileFromPath` function is only supported in Node. See the README for more details: https://www.github.com/openai/openai-node#file-uploads',\r\n      );\r\n    },\r\n    isFsReadStream: (value: any) => false,\r\n  };\r\n}\r\n", "/**\r\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\r\n */\r\nimport * as shims from './registry.mjs';\r\nimport * as auto from 'openai/_shims/auto/runtime';\r\nif (!shims.kind) shims.setShims(auto.getRuntime(), { auto: true });\r\nexport * from './registry.mjs';\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport { castToError, Headers } from './core';\r\n\r\nexport class OpenAIError extends Error {}\r\n\r\nexport class APIError extends OpenAIError {\r\n  readonly status: number | undefined;\r\n  readonly headers: Headers | undefined;\r\n  readonly error: Object | undefined;\r\n\r\n  readonly code: string | null | undefined;\r\n  readonly param: string | null | undefined;\r\n  readonly type: string | undefined;\r\n\r\n  constructor(\r\n    status: number | undefined,\r\n    error: Object | undefined,\r\n    message: string | undefined,\r\n    headers: Headers | undefined,\r\n  ) {\r\n    super(`${APIError.makeMessage(status, error, message)}`);\r\n    this.status = status;\r\n    this.headers = headers;\r\n\r\n    const data = error as Record<string, any>;\r\n    this.error = data;\r\n    this.code = data?.['code'];\r\n    this.param = data?.['param'];\r\n    this.type = data?.['type'];\r\n  }\r\n\r\n  private static makeMessage(status: number | undefined, error: any, message: string | undefined) {\r\n    const msg =\r\n      error?.message ?\r\n        typeof error.message === 'string' ?\r\n          error.message\r\n        : JSON.stringify(error.message)\r\n      : error ? JSON.stringify(error)\r\n      : message;\r\n\r\n    if (status && msg) {\r\n      return `${status} ${msg}`;\r\n    }\r\n    if (status) {\r\n      return `${status} status code (no body)`;\r\n    }\r\n    if (msg) {\r\n      return msg;\r\n    }\r\n    return '(no status code or body)';\r\n  }\r\n\r\n  static generate(\r\n    status: number | undefined,\r\n    errorResponse: Object | undefined,\r\n    message: string | undefined,\r\n    headers: Headers | undefined,\r\n  ) {\r\n    if (!status) {\r\n      return new APIConnectionError({ cause: castToError(errorResponse) });\r\n    }\r\n\r\n    const error = (errorResponse as Record<string, any>)?.['error'];\r\n\r\n    if (status === 400) {\r\n      return new BadRequestError(status, error, message, headers);\r\n    }\r\n\r\n    if (status === 401) {\r\n      return new AuthenticationError(status, error, message, headers);\r\n    }\r\n\r\n    if (status === 403) {\r\n      return new PermissionDeniedError(status, error, message, headers);\r\n    }\r\n\r\n    if (status === 404) {\r\n      return new NotFoundError(status, error, message, headers);\r\n    }\r\n\r\n    if (status === 409) {\r\n      return new ConflictError(status, error, message, headers);\r\n    }\r\n\r\n    if (status === 422) {\r\n      return new UnprocessableEntityError(status, error, message, headers);\r\n    }\r\n\r\n    if (status === 429) {\r\n      return new RateLimitError(status, error, message, headers);\r\n    }\r\n\r\n    if (status >= 500) {\r\n      return new InternalServerError(status, error, message, headers);\r\n    }\r\n\r\n    return new APIError(status, error, message, headers);\r\n  }\r\n}\r\n\r\nexport class APIUserAbortError extends APIError {\r\n  override readonly status: undefined = undefined;\r\n\r\n  constructor({ message }: { message?: string } = {}) {\r\n    super(undefined, undefined, message || 'Request was aborted.', undefined);\r\n  }\r\n}\r\n\r\nexport class APIConnectionError extends APIError {\r\n  override readonly status: undefined = undefined;\r\n\r\n  constructor({ message, cause }: { message?: string; cause?: Error | undefined }) {\r\n    super(undefined, undefined, message || 'Connection error.', undefined);\r\n    // in some environments the 'cause' property is already declared\r\n    // @ts-ignore\r\n    if (cause) this.cause = cause;\r\n  }\r\n}\r\n\r\nexport class APIConnectionTimeoutError extends APIConnectionError {\r\n  constructor({ message }: { message?: string } = {}) {\r\n    super({ message: message ?? 'Request timed out.' });\r\n  }\r\n}\r\n\r\nexport class BadRequestError extends APIError {\r\n  override readonly status: 400 = 400;\r\n}\r\n\r\nexport class AuthenticationError extends APIError {\r\n  override readonly status: 401 = 401;\r\n}\r\n\r\nexport class PermissionDeniedError extends APIError {\r\n  override readonly status: 403 = 403;\r\n}\r\n\r\nexport class NotFoundError extends APIError {\r\n  override readonly status: 404 = 404;\r\n}\r\n\r\nexport class ConflictError extends APIError {\r\n  override readonly status: 409 = 409;\r\n}\r\n\r\nexport class UnprocessableEntityError extends APIError {\r\n  override readonly status: 422 = 422;\r\n}\r\n\r\nexport class RateLimitError extends APIError {\r\n  override readonly status: 429 = 429;\r\n}\r\n\r\nexport class InternalServerError extends APIError {}\r\n", "import { ReadableStream, type Response } from './_shims/index';\r\nimport { OpenAIError } from './error';\r\n\r\nimport { APIError } from \"./error\";\r\n\r\ntype Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\r\n\r\nexport type ServerSentEvent = {\r\n  event: string | null;\r\n  data: string;\r\n  raw: string[];\r\n};\r\n\r\nexport class Stream<Item> implements AsyncIterable<Item> {\r\n  controller: AbortController;\r\n\r\n  constructor(\r\n    private iterator: () => AsyncIterator<Item>,\r\n    controller: AbortController,\r\n  ) {\r\n    this.controller = controller;\r\n  }\r\n\r\n  static fromSSEResponse<Item>(response: Response, controller: AbortController) {\r\n    let consumed = false;\r\n    const decoder = new SSEDecoder();\r\n\r\n    async function* iterMessages(): AsyncGenerator<ServerSentEvent, void, unknown> {\r\n      if (!response.body) {\r\n        controller.abort();\r\n        throw new OpenAIError(`Attempted to iterate over a response with no body`);\r\n      }\r\n\r\n      const lineDecoder = new LineDecoder();\r\n\r\n      const iter = readableStreamAsyncIterable<Bytes>(response.body);\r\n      for await (const chunk of iter) {\r\n        for (const line of lineDecoder.decode(chunk)) {\r\n          const sse = decoder.decode(line);\r\n          if (sse) yield sse;\r\n        }\r\n      }\r\n\r\n      for (const line of lineDecoder.flush()) {\r\n        const sse = decoder.decode(line);\r\n        if (sse) yield sse;\r\n      }\r\n    }\r\n\r\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\r\n      if (consumed) {\r\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\r\n      }\r\n      consumed = true;\r\n      let done = false;\r\n      try {\r\n        for await (const sse of iterMessages()) {\r\n          if (done) continue;\r\n\r\n          if (sse.data.startsWith('[DONE]')) {\r\n            done = true;\r\n            continue;\r\n          }\r\n\r\n          if (sse.event === null) {\r\n            let data;\r\n\r\n            try {\r\n              data = JSON.parse(sse.data);\r\n            } catch (e) {\r\n              console.error(`Could not parse message into JSON:`, sse.data);\r\n              console.error(`From chunk:`, sse.raw);\r\n              throw e;\r\n            }\r\n\r\n            if (data && data.error) {\r\n              throw new APIError(undefined, data.error, undefined, undefined);\r\n            }\r\n\r\n            yield data;\r\n          }\r\n        }\r\n        done = true;\r\n      } catch (e) {\r\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\r\n        if (e instanceof Error && e.name === 'AbortError') return;\r\n        throw e;\r\n      } finally {\r\n        // If the user `break`s, abort the ongoing request.\r\n        if (!done) controller.abort();\r\n      }\r\n    }\r\n\r\n    return new Stream(iterator, controller);\r\n  }\r\n\r\n  /**\r\n   * Generates a Stream from a newline-separated ReadableStream\r\n   * where each item is a JSON value.\r\n   */\r\n  static fromReadableStream<Item>(readableStream: ReadableStream, controller: AbortController) {\r\n    let consumed = false;\r\n\r\n    async function* iterLines(): AsyncGenerator<string, void, unknown> {\r\n      const lineDecoder = new LineDecoder();\r\n\r\n      const iter = readableStreamAsyncIterable<Bytes>(readableStream);\r\n      for await (const chunk of iter) {\r\n        for (const line of lineDecoder.decode(chunk)) {\r\n          yield line;\r\n        }\r\n      }\r\n\r\n      for (const line of lineDecoder.flush()) {\r\n        yield line;\r\n      }\r\n    }\r\n\r\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\r\n      if (consumed) {\r\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\r\n      }\r\n      consumed = true;\r\n      let done = false;\r\n      try {\r\n        for await (const line of iterLines()) {\r\n          if (done) continue;\r\n          if (line) yield JSON.parse(line);\r\n        }\r\n        done = true;\r\n      } catch (e) {\r\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\r\n        if (e instanceof Error && e.name === 'AbortError') return;\r\n        throw e;\r\n      } finally {\r\n        // If the user `break`s, abort the ongoing request.\r\n        if (!done) controller.abort();\r\n      }\r\n    }\r\n\r\n    return new Stream(iterator, controller);\r\n  }\r\n\r\n  [Symbol.asyncIterator](): AsyncIterator<Item> {\r\n    return this.iterator();\r\n  }\r\n\r\n  /**\r\n   * Splits the stream into two streams which can be\r\n   * independently read from at different speeds.\r\n   */\r\n  tee(): [Stream<Item>, Stream<Item>] {\r\n    const left: Array<Promise<IteratorResult<Item>>> = [];\r\n    const right: Array<Promise<IteratorResult<Item>>> = [];\r\n    const iterator = this.iterator();\r\n\r\n    const teeIterator = (queue: Array<Promise<IteratorResult<Item>>>): AsyncIterator<Item> => {\r\n      return {\r\n        next: () => {\r\n          if (queue.length === 0) {\r\n            const result = iterator.next();\r\n            left.push(result);\r\n            right.push(result);\r\n          }\r\n          return queue.shift()!;\r\n        },\r\n      };\r\n    };\r\n\r\n    return [\r\n      new Stream(() => teeIterator(left), this.controller),\r\n      new Stream(() => teeIterator(right), this.controller),\r\n    ];\r\n  }\r\n\r\n  /**\r\n   * Converts this stream to a newline-separated ReadableStream of\r\n   * JSON stringified values in the stream\r\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\r\n   */\r\n  toReadableStream(): ReadableStream {\r\n    const self = this;\r\n    let iter: AsyncIterator<Item>;\r\n    const encoder = new TextEncoder();\r\n\r\n    return new ReadableStream({\r\n      async start() {\r\n        iter = self[Symbol.asyncIterator]();\r\n      },\r\n      async pull(ctrl) {\r\n        try {\r\n          const { value, done } = await iter.next();\r\n          if (done) return ctrl.close();\r\n\r\n          const bytes = encoder.encode(JSON.stringify(value) + '\\n');\r\n\r\n          ctrl.enqueue(bytes);\r\n        } catch (err) {\r\n          ctrl.error(err);\r\n        }\r\n      },\r\n      async cancel() {\r\n        await iter.return?.();\r\n      },\r\n    });\r\n  }\r\n}\r\n\r\nclass SSEDecoder {\r\n  private data: string[];\r\n  private event: string | null;\r\n  private chunks: string[];\r\n\r\n  constructor() {\r\n    this.event = null;\r\n    this.data = [];\r\n    this.chunks = [];\r\n  }\r\n\r\n  decode(line: string) {\r\n    if (line.endsWith('\\r')) {\r\n      line = line.substring(0, line.length - 1);\r\n    }\r\n\r\n    if (!line) {\r\n      // empty line and we didn't previously encounter any messages\r\n      if (!this.event && !this.data.length) return null;\r\n\r\n      const sse: ServerSentEvent = {\r\n        event: this.event,\r\n        data: this.data.join('\\n'),\r\n        raw: this.chunks,\r\n      };\r\n\r\n      this.event = null;\r\n      this.data = [];\r\n      this.chunks = [];\r\n\r\n      return sse;\r\n    }\r\n\r\n    this.chunks.push(line);\r\n\r\n    if (line.startsWith(':')) {\r\n      return null;\r\n    }\r\n\r\n    let [fieldname, _, value] = partition(line, ':');\r\n\r\n    if (value.startsWith(' ')) {\r\n      value = value.substring(1);\r\n    }\r\n\r\n    if (fieldname === 'event') {\r\n      this.event = value;\r\n    } else if (fieldname === 'data') {\r\n      this.data.push(value);\r\n    }\r\n\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\r\n * reading lines from text.\r\n *\r\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\r\n */\r\nclass LineDecoder {\r\n  // prettier-ignore\r\n  static NEWLINE_CHARS = new Set(['\\n', '\\r', '\\x0b', '\\x0c', '\\x1c', '\\x1d', '\\x1e', '\\x85', '\\u2028', '\\u2029']);\r\n  static NEWLINE_REGEXP = /\\r\\n|[\\n\\r\\x0b\\x0c\\x1c\\x1d\\x1e\\x85\\u2028\\u2029]/g;\r\n\r\n  buffer: string[];\r\n  trailingCR: boolean;\r\n  textDecoder: any; // TextDecoder found in browsers; not typed to avoid pulling in either \"dom\" or \"node\" types.\r\n\r\n  constructor() {\r\n    this.buffer = [];\r\n    this.trailingCR = false;\r\n  }\r\n\r\n  decode(chunk: Bytes): string[] {\r\n    let text = this.decodeText(chunk);\r\n\r\n    if (this.trailingCR) {\r\n      text = '\\r' + text;\r\n      this.trailingCR = false;\r\n    }\r\n    if (text.endsWith('\\r')) {\r\n      this.trailingCR = true;\r\n      text = text.slice(0, -1);\r\n    }\r\n\r\n    if (!text) {\r\n      return [];\r\n    }\r\n\r\n    const trailingNewline = LineDecoder.NEWLINE_CHARS.has(text[text.length - 1] || '');\r\n    let lines = text.split(LineDecoder.NEWLINE_REGEXP);\r\n\r\n    if (lines.length === 1 && !trailingNewline) {\r\n      this.buffer.push(lines[0]!);\r\n      return [];\r\n    }\r\n\r\n    if (this.buffer.length > 0) {\r\n      lines = [this.buffer.join('') + lines[0], ...lines.slice(1)];\r\n      this.buffer = [];\r\n    }\r\n\r\n    if (!trailingNewline) {\r\n      this.buffer = [lines.pop() || ''];\r\n    }\r\n\r\n    return lines;\r\n  }\r\n\r\n  decodeText(bytes: Bytes): string {\r\n    if (bytes == null) return '';\r\n    if (typeof bytes === 'string') return bytes;\r\n\r\n    // Node:\r\n    if (typeof Buffer !== 'undefined') {\r\n      if (bytes instanceof Buffer) {\r\n        return bytes.toString();\r\n      }\r\n      if (bytes instanceof Uint8Array) {\r\n        return Buffer.from(bytes).toString();\r\n      }\r\n\r\n      throw new OpenAIError(\r\n        `Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global \"Buffer\" defined, which this library assumes to be Node. Please report this error.`,\r\n      );\r\n    }\r\n\r\n    // Browser\r\n    if (typeof TextDecoder !== 'undefined') {\r\n      if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {\r\n        this.textDecoder ??= new TextDecoder('utf8');\r\n        return this.textDecoder.decode(bytes);\r\n      }\r\n\r\n      throw new OpenAIError(\r\n        `Unexpected: received non-Uint8Array/ArrayBuffer (${\r\n          (bytes as any).constructor.name\r\n        }) in a web platform. Please report this error.`,\r\n      );\r\n    }\r\n\r\n    throw new OpenAIError(\r\n      `Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`,\r\n    );\r\n  }\r\n\r\n  flush(): string[] {\r\n    if (!this.buffer.length && !this.trailingCR) {\r\n      return [];\r\n    }\r\n\r\n    const lines = [this.buffer.join('')];\r\n    this.buffer = [];\r\n    this.trailingCR = false;\r\n    return lines;\r\n  }\r\n}\r\n\r\nfunction partition(str: string, delimiter: string): [string, string, string] {\r\n  const index = str.indexOf(delimiter);\r\n  if (index !== -1) {\r\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\r\n  }\r\n\r\n  return [str, '', ''];\r\n}\r\n\r\n/**\r\n * Most browsers don't yet have async iterable support for ReadableStream,\r\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\r\n *\r\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\r\n */\r\nexport function readableStreamAsyncIterable<T>(stream: any): AsyncIterableIterator<T> {\r\n  if (stream[Symbol.asyncIterator]) return stream;\r\n\r\n  const reader = stream.getReader();\r\n  return {\r\n    async next() {\r\n      try {\r\n        const result = await reader.read();\r\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\r\n        return result;\r\n      } catch (e) {\r\n        reader.releaseLock(); // release lock when stream becomes errored\r\n        throw e;\r\n      }\r\n    },\r\n    async return() {\r\n      const cancelPromise = reader.cancel();\r\n      reader.releaseLock();\r\n      await cancelPromise;\r\n      return { done: true, value: undefined };\r\n    },\r\n    [Symbol.asyncIterator]() {\r\n      return this;\r\n    },\r\n  };\r\n}\r\n", "import { type RequestOptions } from './core';\r\nimport {\r\n  FormData,\r\n  File,\r\n  type Blob,\r\n  type FilePropertyBag,\r\n  getMultipartRequestOptions,\r\n  type FsReadStream,\r\n  isFsReadStream,\r\n} from './_shims/index';\r\nimport { MultipartBody } from './_shims/MultipartBody';\r\nexport { fileFromPath } from './_shims/index';\r\n\r\ntype BlobLikePart = string | ArrayBuffer | ArrayBufferView | BlobLike | Uint8Array | DataView;\r\nexport type BlobPart = string | ArrayBuffer | ArrayBufferView | Blob | Uint8Array | DataView;\r\n\r\n/**\r\n * Typically, this is a native \"File\" class.\r\n *\r\n * We provide the {@link toFile} utility to convert a variety of objects\r\n * into the File class.\r\n *\r\n * For convenience, you can also pass a fetch Response, or in Node,\r\n * the result of fs.createReadStream().\r\n */\r\nexport type Uploadable = FileLike | ResponseLike | FsReadStream;\r\n\r\n/**\r\n * Intended to match web.Blob, node.Blob, node-fetch.Blob, etc.\r\n */\r\nexport interface BlobLike {\r\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */\r\n  readonly size: number;\r\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */\r\n  readonly type: string;\r\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */\r\n  text(): Promise<string>;\r\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */\r\n  slice(start?: number, end?: number): BlobLike;\r\n  // unfortunately @types/node-fetch@^2.6.4 doesn't type the arrayBuffer method\r\n}\r\n\r\n/**\r\n * Intended to match web.File, node.File, node-fetch.File, etc.\r\n */\r\nexport interface FileLike extends BlobLike {\r\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */\r\n  readonly lastModified: number;\r\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */\r\n  readonly name: string;\r\n}\r\n\r\n/**\r\n * Intended to match web.Response, node.Response, node-fetch.Response, etc.\r\n */\r\nexport interface ResponseLike {\r\n  url: string;\r\n  blob(): Promise<BlobLike>;\r\n}\r\n\r\nexport const isResponseLike = (value: any): value is ResponseLike =>\r\n  value != null &&\r\n  typeof value === 'object' &&\r\n  typeof value.url === 'string' &&\r\n  typeof value.blob === 'function';\r\n\r\nexport const isFileLike = (value: any): value is FileLike =>\r\n  value != null &&\r\n  typeof value === 'object' &&\r\n  typeof value.name === 'string' &&\r\n  typeof value.lastModified === 'number' &&\r\n  isBlobLike(value);\r\n\r\n/**\r\n * The BlobLike type omits arrayBuffer() because @types/node-fetch@^2.6.4 lacks it; but this check\r\n * adds the arrayBuffer() method type because it is available and used at runtime\r\n */\r\nexport const isBlobLike = (value: any): value is BlobLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\r\n  value != null &&\r\n  typeof value === 'object' &&\r\n  typeof value.size === 'number' &&\r\n  typeof value.type === 'string' &&\r\n  typeof value.text === 'function' &&\r\n  typeof value.slice === 'function' &&\r\n  typeof value.arrayBuffer === 'function';\r\n\r\nexport const isUploadable = (value: any): value is Uploadable => {\r\n  return isFileLike(value) || isResponseLike(value) || isFsReadStream(value);\r\n};\r\n\r\nexport type ToFileInput = Uploadable | Exclude<BlobLikePart, string> | AsyncIterable<BlobLikePart>;\r\n\r\n/**\r\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\r\n * @param value the raw content of the file.  Can be an {@link Uploadable}, {@link BlobLikePart}, or {@link AsyncIterable} of {@link BlobLikePart}s\r\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\r\n * @param {Object=} options additional properties\r\n * @param {string=} options.type the MIME type of the content\r\n * @param {number=} options.lastModified the last modified timestamp\r\n * @returns a {@link File} with the given properties\r\n */\r\nexport async function toFile(\r\n  value: ToFileInput | PromiseLike<ToFileInput>,\r\n  name?: string | null | undefined,\r\n  options: FilePropertyBag | undefined = {},\r\n): Promise<FileLike> {\r\n  // If it's a promise, resolve it.\r\n  value = await value;\r\n\r\n  if (isResponseLike(value)) {\r\n    const blob = await value.blob();\r\n    name ||= new URL(value.url).pathname.split(/[\\\\/]/).pop() ?? 'unknown_file';\r\n\r\n    return new File([blob as any], name, options);\r\n  }\r\n\r\n  const bits = await getBytes(value);\r\n\r\n  name ||= getName(value) ?? 'unknown_file';\r\n\r\n  if (!options.type) {\r\n    const type = (bits[0] as any)?.type;\r\n    if (typeof type === 'string') {\r\n      options = { ...options, type };\r\n    }\r\n  }\r\n\r\n  return new File(bits, name, options);\r\n}\r\n\r\nasync function getBytes(value: ToFileInput): Promise<Array<BlobPart>> {\r\n  let parts: Array<BlobPart> = [];\r\n  if (\r\n    typeof value === 'string' ||\r\n    ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\r\n    value instanceof ArrayBuffer\r\n  ) {\r\n    parts.push(value);\r\n  } else if (isBlobLike(value)) {\r\n    parts.push(await value.arrayBuffer());\r\n  } else if (\r\n    isAsyncIterableIterator(value) // includes Readable, ReadableStream, etc.\r\n  ) {\r\n    for await (const chunk of value) {\r\n      parts.push(chunk as BlobPart); // TODO, consider validating?\r\n    }\r\n  } else {\r\n    throw new Error(\r\n      `Unexpected data type: ${typeof value}; constructor: ${value?.constructor\r\n        ?.name}; props: ${propsForError(value)}`,\r\n    );\r\n  }\r\n\r\n  return parts;\r\n}\r\n\r\nfunction propsForError(value: any): string {\r\n  const props = Object.getOwnPropertyNames(value);\r\n  return `[${props.map((p) => `\"${p}\"`).join(', ')}]`;\r\n}\r\n\r\nfunction getName(value: any): string | undefined {\r\n  return (\r\n    getStringFromMaybeBuffer(value.name) ||\r\n    getStringFromMaybeBuffer(value.filename) ||\r\n    // For fs.ReadStream\r\n    getStringFromMaybeBuffer(value.path)?.split(/[\\\\/]/).pop()\r\n  );\r\n}\r\n\r\nconst getStringFromMaybeBuffer = (x: string | Buffer | unknown): string | undefined => {\r\n  if (typeof x === 'string') return x;\r\n  if (typeof Buffer !== 'undefined' && x instanceof Buffer) return String(x);\r\n  return undefined;\r\n};\r\n\r\nconst isAsyncIterableIterator = (value: any): value is AsyncIterableIterator<unknown> =>\r\n  value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\r\n\r\nexport const isMultipartBody = (body: any): body is MultipartBody =>\r\n  body && typeof body === 'object' && body.body && body[Symbol.toStringTag] === 'MultipartBody';\r\n\r\n/**\r\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\r\n * Otherwise returns the request as is.\r\n */\r\nexport const maybeMultipartFormRequestOptions = async <T = Record<string, unknown>>(\r\n  opts: RequestOptions<T>,\r\n): Promise<RequestOptions<T | MultipartBody>> => {\r\n  if (!hasUploadableValue(opts.body)) return opts;\r\n\r\n  const form = await createForm(opts.body);\r\n  return getMultipartRequestOptions(form, opts);\r\n};\r\n\r\nexport const multipartFormRequestOptions = async <T = Record<string, unknown>>(\r\n  opts: RequestOptions<T>,\r\n): Promise<RequestOptions<T | MultipartBody>> => {\r\n  const form = await createForm(opts.body);\r\n  return getMultipartRequestOptions(form, opts);\r\n};\r\n\r\nexport const createForm = async <T = Record<string, unknown>>(body: T | undefined): Promise<FormData> => {\r\n  const form = new FormData();\r\n  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\r\n  return form;\r\n};\r\n\r\nconst hasUploadableValue = (value: unknown): boolean => {\r\n  if (isUploadable(value)) return true;\r\n  if (Array.isArray(value)) return value.some(hasUploadableValue);\r\n  if (value && typeof value === 'object') {\r\n    for (const k in value) {\r\n      if (hasUploadableValue((value as any)[k])) return true;\r\n    }\r\n  }\r\n  return false;\r\n};\r\n\r\nconst addFormValue = async (form: FormData, key: string, value: unknown): Promise<void> => {\r\n  if (value === undefined) return;\r\n  if (value == null) {\r\n    throw new TypeError(\r\n      `Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`,\r\n    );\r\n  }\r\n\r\n  // TODO: make nested formats configurable\r\n  if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\r\n    form.append(key, String(value));\r\n  } else if (isUploadable(value)) {\r\n    const file = await toFile(value);\r\n    form.append(key, file as File);\r\n  } else if (Array.isArray(value)) {\r\n    await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\r\n  } else if (typeof value === 'object') {\r\n    await Promise.all(\r\n      Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)),\r\n    );\r\n  } else {\r\n    throw new TypeError(\r\n      `Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`,\r\n    );\r\n  }\r\n};\r\n", "import { VERSION } from './version';\r\nimport { Stream } from './streaming';\r\nimport {\r\n  OpenAIError,\r\n  APIError,\r\n  APIConnectionError,\r\n  APIConnectionTimeoutError,\r\n  APIUserAbortError,\r\n} from './error';\r\nimport {\r\n  kind as shimsKind,\r\n  type Readable,\r\n  getDefaultAgent,\r\n  type Agent,\r\n  fetch,\r\n  type RequestInfo,\r\n  type RequestInit,\r\n  type Response,\r\n  type HeadersInit,\r\n} from './_shims/index';\r\nexport { type Response };\r\nimport { isMultipartBody } from './uploads';\r\nexport {\r\n  maybeMultipartFormRequestOptions,\r\n  multipartFormRequestOptions,\r\n  createForm,\r\n  type Uploadable,\r\n} from './uploads';\r\n\r\nexport type Fetch = (url: RequestInfo, init?: RequestInit) => Promise<Response>;\r\n\r\ntype PromiseOrValue<T> = T | Promise<T>;\r\n\r\ntype APIResponseProps = {\r\n  response: Response;\r\n  options: FinalRequestOptions;\r\n  controller: AbortController;\r\n};\r\n\r\nasync function defaultParseResponse<T>(props: APIResponseProps): Promise<T> {\r\n  const { response } = props;\r\n  if (props.options.stream) {\r\n    debug('response', response.status, response.url, response.headers, response.body);\r\n\r\n    // Note: there is an invariant here that isn't represented in the type system\r\n    // that if you set `stream: true` the response type must also be `Stream<T>`\r\n\r\n    if (props.options.__streamClass) {\r\n      return props.options.__streamClass.fromSSEResponse(response, props.controller) as any;\r\n    }\r\n\r\n    return Stream.fromSSEResponse(response, props.controller) as any;\r\n  }\r\n\r\n  // fetch refuses to read the body when the status code is 204.\r\n  if (response.status === 204) {\r\n    return null as T;\r\n  }\r\n\r\n  if (props.options.__binaryResponse) {\r\n    return response as unknown as T;\r\n  }\r\n\r\n  const contentType = response.headers.get('content-type');\r\n  const isJSON =\r\n    contentType?.includes('application/json') || contentType?.includes('application/vnd.api+json');\r\n  if (isJSON) {\r\n    const json = await response.json();\r\n\r\n    debug('response', response.status, response.url, response.headers, json);\r\n\r\n    return json as T;\r\n  }\r\n\r\n  const text = await response.text();\r\n  debug('response', response.status, response.url, response.headers, text);\r\n\r\n  // TODO handle blob, arraybuffer, other content types, etc.\r\n  return text as unknown as T;\r\n}\r\n\r\n/**\r\n * A subclass of `Promise` providing additional helper methods\r\n * for interacting with the SDK.\r\n */\r\nexport class APIPromise<T> extends Promise<T> {\r\n  private parsedPromise: Promise<T> | undefined;\r\n\r\n  constructor(\r\n    private responsePromise: Promise<APIResponseProps>,\r\n    private parseResponse: (props: APIResponseProps) => PromiseOrValue<T> = defaultParseResponse,\r\n  ) {\r\n    super((resolve) => {\r\n      // this is maybe a bit weird but this has to be a no-op to not implicitly\r\n      // parse the response body; instead .then, .catch, .finally are overridden\r\n      // to parse the response\r\n      resolve(null as any);\r\n    });\r\n  }\r\n\r\n  _thenUnwrap<U>(transform: (data: T) => U): APIPromise<U> {\r\n    return new APIPromise(this.responsePromise, async (props) => transform(await this.parseResponse(props)));\r\n  }\r\n\r\n  /**\r\n   * Gets the raw `Response` instance instead of parsing the response\r\n   * data.\r\n   *\r\n   * If you want to parse the response body but still get the `Response`\r\n   * instance, you can use {@link withResponse()}.\r\n   *\r\n   * ðŸ‘‹ Getting the wrong TypeScript type for `Response`?\r\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\r\n   * or add one of these imports before your first `import â€¦ from 'openai'`:\r\n   * - `import 'openai/shims/node'` (if you're running on Node)\r\n   * - `import 'openai/shims/web'` (otherwise)\r\n   */\r\n  asResponse(): Promise<Response> {\r\n    return this.responsePromise.then((p) => p.response);\r\n  }\r\n  /**\r\n   * Gets the parsed response data and the raw `Response` instance.\r\n   *\r\n   * If you just want to get the raw `Response` instance without parsing it,\r\n   * you can use {@link asResponse()}.\r\n   *\r\n   *\r\n   * ðŸ‘‹ Getting the wrong TypeScript type for `Response`?\r\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\r\n   * or add one of these imports before your first `import â€¦ from 'openai'`:\r\n   * - `import 'openai/shims/node'` (if you're running on Node)\r\n   * - `import 'openai/shims/web'` (otherwise)\r\n   */\r\n  async withResponse(): Promise<{ data: T; response: Response }> {\r\n    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\r\n    return { data, response };\r\n  }\r\n\r\n  private parse(): Promise<T> {\r\n    if (!this.parsedPromise) {\r\n      this.parsedPromise = this.responsePromise.then(this.parseResponse);\r\n    }\r\n    return this.parsedPromise;\r\n  }\r\n\r\n  override then<TResult1 = T, TResult2 = never>(\r\n    onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null,\r\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null,\r\n  ): Promise<TResult1 | TResult2> {\r\n    return this.parse().then(onfulfilled, onrejected);\r\n  }\r\n\r\n  override catch<TResult = never>(\r\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null,\r\n  ): Promise<T | TResult> {\r\n    return this.parse().catch(onrejected);\r\n  }\r\n\r\n  override finally(onfinally?: (() => void) | undefined | null): Promise<T> {\r\n    return this.parse().finally(onfinally);\r\n  }\r\n}\r\n\r\nexport abstract class APIClient {\r\n  baseURL: string;\r\n  maxRetries: number;\r\n  timeout: number;\r\n  httpAgent: Agent | undefined;\r\n\r\n  private fetch: Fetch;\r\n  protected idempotencyHeader?: string;\r\n\r\n  constructor({\r\n    baseURL,\r\n    maxRetries = 2,\r\n    timeout = 600000, // 10 minutes\r\n    httpAgent,\r\n    fetch: overridenFetch,\r\n  }: {\r\n    baseURL: string;\r\n    maxRetries?: number | undefined;\r\n    timeout: number | undefined;\r\n    httpAgent: Agent | undefined;\r\n    fetch: Fetch | undefined;\r\n  }) {\r\n    this.baseURL = baseURL;\r\n    this.maxRetries = validatePositiveInteger('maxRetries', maxRetries);\r\n    this.timeout = validatePositiveInteger('timeout', timeout);\r\n    this.httpAgent = httpAgent;\r\n\r\n    this.fetch = overridenFetch ?? fetch;\r\n  }\r\n\r\n  protected authHeaders(opts: FinalRequestOptions): Headers {\r\n    return {};\r\n  }\r\n\r\n  /**\r\n   * Override this to add your own default headers, for example:\r\n   *\r\n   *  {\r\n   *    ...super.defaultHeaders(),\r\n   *    Authorization: 'Bearer 123',\r\n   *  }\r\n   */\r\n  protected defaultHeaders(opts: FinalRequestOptions): Headers {\r\n    return {\r\n      Accept: 'application/json',\r\n      'Content-Type': 'application/json',\r\n      'User-Agent': this.getUserAgent(),\r\n      ...getPlatformHeaders(),\r\n      ...this.authHeaders(opts),\r\n    };\r\n  }\r\n\r\n  protected abstract defaultQuery(): DefaultQuery | undefined;\r\n\r\n  /**\r\n   * Override this to add your own headers validation:\r\n   */\r\n  protected validateHeaders(headers: Headers, customHeaders: Headers) {}\r\n\r\n  protected defaultIdempotencyKey(): string {\r\n    return `stainless-node-retry-${uuid4()}`;\r\n  }\r\n\r\n  get<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\r\n    return this.methodRequest('get', path, opts);\r\n  }\r\n\r\n  post<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\r\n    return this.methodRequest('post', path, opts);\r\n  }\r\n\r\n  patch<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\r\n    return this.methodRequest('patch', path, opts);\r\n  }\r\n\r\n  put<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\r\n    return this.methodRequest('put', path, opts);\r\n  }\r\n\r\n  delete<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\r\n    return this.methodRequest('delete', path, opts);\r\n  }\r\n\r\n  private methodRequest<Req, Rsp>(\r\n    method: HTTPMethod,\r\n    path: string,\r\n    opts?: PromiseOrValue<RequestOptions<Req>>,\r\n  ): APIPromise<Rsp> {\r\n    return this.request(Promise.resolve(opts).then((opts) => ({ method, path, ...opts })));\r\n  }\r\n\r\n  getAPIList<Item, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\r\n    path: string,\r\n    Page: new (...args: any[]) => PageClass,\r\n    opts?: RequestOptions<any>,\r\n  ): PagePromise<PageClass, Item> {\r\n    return this.requestAPIList(Page, { method: 'get', path, ...opts });\r\n  }\r\n\r\n  private calculateContentLength(body: unknown): string | null {\r\n    if (typeof body === 'string') {\r\n      if (typeof Buffer !== 'undefined') {\r\n        return Buffer.byteLength(body, 'utf8').toString();\r\n      }\r\n\r\n      if (typeof TextEncoder !== 'undefined') {\r\n        const encoder = new TextEncoder();\r\n        const encoded = encoder.encode(body);\r\n        return encoded.length.toString();\r\n      }\r\n    }\r\n\r\n    return null;\r\n  }\r\n\r\n  buildRequest<Req>(options: FinalRequestOptions<Req>): { req: RequestInit; url: string; timeout: number } {\r\n    const { method, path, query, headers: headers = {} } = options;\r\n\r\n    const body =\r\n      isMultipartBody(options.body) ? options.body.body\r\n      : options.body ? JSON.stringify(options.body, null, 2)\r\n      : null;\r\n    const contentLength = this.calculateContentLength(body);\r\n\r\n    const url = this.buildURL(path!, query);\r\n    if ('timeout' in options) validatePositiveInteger('timeout', options.timeout);\r\n    const timeout = options.timeout ?? this.timeout;\r\n    const httpAgent = options.httpAgent ?? this.httpAgent ?? getDefaultAgent(url);\r\n    const minAgentTimeout = timeout + 1000;\r\n    if (\r\n      typeof (httpAgent as any)?.options?.timeout === 'number' &&\r\n      minAgentTimeout > ((httpAgent as any).options.timeout ?? 0)\r\n    ) {\r\n      // Allow any given request to bump our agent active socket timeout.\r\n      // This may seem strange, but leaking active sockets should be rare and not particularly problematic,\r\n      // and without mutating agent we would need to create more of them.\r\n      // This tradeoff optimizes for performance.\r\n      (httpAgent as any).options.timeout = minAgentTimeout;\r\n    }\r\n\r\n    if (this.idempotencyHeader && method !== 'get') {\r\n      if (!options.idempotencyKey) options.idempotencyKey = this.defaultIdempotencyKey();\r\n      headers[this.idempotencyHeader] = options.idempotencyKey;\r\n    }\r\n\r\n    const reqHeaders = this.buildHeaders({ options, headers, contentLength });\r\n\r\n    const req: RequestInit = {\r\n      method,\r\n      ...(body && { body: body as any }),\r\n      headers: reqHeaders,\r\n      ...(httpAgent && { agent: httpAgent }),\r\n      // @ts-ignore node-fetch uses a custom AbortSignal type that is\r\n      // not compatible with standard web types\r\n      signal: options.signal ?? null,\r\n    };\r\n\r\n    return { req, url, timeout };\r\n  }\r\n\r\n  private buildHeaders({\r\n    options,\r\n    headers,\r\n    contentLength,\r\n  }: {\r\n    options: FinalRequestOptions;\r\n    headers: Record<string, string | null | undefined>;\r\n    contentLength: string | null | undefined;\r\n  }): Record<string, string> {\r\n    const reqHeaders: Record<string, string> = {};\r\n    if (contentLength) {\r\n      reqHeaders['content-length'] = contentLength;\r\n    }\r\n\r\n    const defaultHeaders = this.defaultHeaders(options);\r\n    applyHeadersMut(reqHeaders, defaultHeaders);\r\n    applyHeadersMut(reqHeaders, headers);\r\n\r\n    // let builtin fetch set the Content-Type for multipart bodies\r\n    if (isMultipartBody(options.body) && shimsKind !== 'node') {\r\n      delete reqHeaders['content-type'];\r\n    }\r\n\r\n    this.validateHeaders(reqHeaders, headers);\r\n\r\n    return reqHeaders;\r\n  }\r\n\r\n  /**\r\n   * Used as a callback for mutating the given `FinalRequestOptions` object.\r\n   */\r\n  protected async prepareOptions(options: FinalRequestOptions): Promise<void> {}\r\n\r\n  /**\r\n   * Used as a callback for mutating the given `RequestInit` object.\r\n   *\r\n   * This is useful for cases where you want to add certain headers based off of\r\n   * the request properties, e.g. `method` or `url`.\r\n   */\r\n  protected async prepareRequest(\r\n    request: RequestInit,\r\n    { url, options }: { url: string; options: FinalRequestOptions },\r\n  ): Promise<void> {}\r\n\r\n  protected parseHeaders(headers: HeadersInit | null | undefined): Record<string, string> {\r\n    return (\r\n      !headers ? {}\r\n      : Symbol.iterator in headers ?\r\n        Object.fromEntries(Array.from(headers as Iterable<string[]>).map((header) => [...header]))\r\n      : { ...headers }\r\n    );\r\n  }\r\n\r\n  protected makeStatusError(\r\n    status: number | undefined,\r\n    error: Object | undefined,\r\n    message: string | undefined,\r\n    headers: Headers | undefined,\r\n  ) {\r\n    return APIError.generate(status, error, message, headers);\r\n  }\r\n\r\n  request<Req, Rsp>(\r\n    options: PromiseOrValue<FinalRequestOptions<Req>>,\r\n    remainingRetries: number | null = null,\r\n  ): APIPromise<Rsp> {\r\n    return new APIPromise(this.makeRequest(options, remainingRetries));\r\n  }\r\n\r\n  private async makeRequest<Req>(\r\n    optionsInput: PromiseOrValue<FinalRequestOptions<Req>>,\r\n    retriesRemaining: number | null,\r\n  ): Promise<APIResponseProps> {\r\n    const options = await optionsInput;\r\n    if (retriesRemaining == null) {\r\n      retriesRemaining = options.maxRetries ?? this.maxRetries;\r\n    }\r\n\r\n    await this.prepareOptions(options);\r\n\r\n    const { req, url, timeout } = this.buildRequest(options);\r\n\r\n    await this.prepareRequest(req, { url, options });\r\n\r\n    debug('request', url, options, req.headers);\r\n\r\n    if (options.signal?.aborted) {\r\n      throw new APIUserAbortError();\r\n    }\r\n\r\n    const controller = new AbortController();\r\n    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\r\n\r\n    if (response instanceof Error) {\r\n      if (options.signal?.aborted) {\r\n        throw new APIUserAbortError();\r\n      }\r\n      if (retriesRemaining) {\r\n        return this.retryRequest(options, retriesRemaining);\r\n      }\r\n      if (response.name === 'AbortError') {\r\n        throw new APIConnectionTimeoutError();\r\n      }\r\n      throw new APIConnectionError({ cause: response });\r\n    }\r\n\r\n    const responseHeaders = createResponseHeaders(response.headers);\r\n\r\n    if (!response.ok) {\r\n      if (retriesRemaining && this.shouldRetry(response)) {\r\n        const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\r\n        debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders);\r\n        return this.retryRequest(options, retriesRemaining, responseHeaders);\r\n      }\r\n\r\n      const errText = await response.text().catch((e) => castToError(e).message);\r\n      const errJSON = safeJSON(errText);\r\n      const errMessage = errJSON ? undefined : errText;\r\n      const retryMessage = retriesRemaining ? `(error; no more retries left)` : `(error; not retryable)`;\r\n\r\n      debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders, errMessage);\r\n\r\n      const err = this.makeStatusError(response.status, errJSON, errMessage, responseHeaders);\r\n      throw err;\r\n    }\r\n\r\n    return { response, options, controller };\r\n  }\r\n\r\n  requestAPIList<Item = unknown, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\r\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\r\n    options: FinalRequestOptions,\r\n  ): PagePromise<PageClass, Item> {\r\n    const request = this.makeRequest(options, null);\r\n    return new PagePromise<PageClass, Item>(this, request, Page);\r\n  }\r\n\r\n  buildURL<Req>(path: string, query: Req | null | undefined): string {\r\n    const url =\r\n      isAbsoluteURL(path) ?\r\n        new URL(path)\r\n      : new URL(this.baseURL + (this.baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\r\n\r\n    const defaultQuery = this.defaultQuery();\r\n    if (!isEmptyObj(defaultQuery)) {\r\n      query = { ...defaultQuery, ...query } as Req;\r\n    }\r\n\r\n    if (typeof query === 'object' && query && !Array.isArray(query)) {\r\n      url.search = this.stringifyQuery(query as Record<string, unknown>);\r\n    }\r\n\r\n    return url.toString();\r\n  }\r\n\r\n  protected stringifyQuery(query: Record<string, unknown>): string {\r\n    return Object.entries(query)\r\n      .filter(([_, value]) => typeof value !== 'undefined')\r\n      .map(([key, value]) => {\r\n        if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\r\n          return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;\r\n        }\r\n        if (value === null) {\r\n          return `${encodeURIComponent(key)}=`;\r\n        }\r\n        throw new OpenAIError(\r\n          `Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`,\r\n        );\r\n      })\r\n      .join('&');\r\n  }\r\n\r\n  async fetchWithTimeout(\r\n    url: RequestInfo,\r\n    init: RequestInit | undefined,\r\n    ms: number,\r\n    controller: AbortController,\r\n  ): Promise<Response> {\r\n    const { signal, ...options } = init || {};\r\n    if (signal) signal.addEventListener('abort', () => controller.abort());\r\n\r\n    const timeout = setTimeout(() => controller.abort(), ms);\r\n\r\n    return (\r\n      this.getRequestClient()\r\n        // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\r\n        .fetch.call(undefined, url, { signal: controller.signal as any, ...options })\r\n        .finally(() => {\r\n          clearTimeout(timeout);\r\n        })\r\n    );\r\n  }\r\n\r\n  protected getRequestClient(): RequestClient {\r\n    return { fetch: this.fetch };\r\n  }\r\n\r\n  private shouldRetry(response: Response): boolean {\r\n    // Note this is not a standard header.\r\n    const shouldRetryHeader = response.headers.get('x-should-retry');\r\n\r\n    // If the server explicitly says whether or not to retry, obey.\r\n    if (shouldRetryHeader === 'true') return true;\r\n    if (shouldRetryHeader === 'false') return false;\r\n\r\n    // Retry on request timeouts.\r\n    if (response.status === 408) return true;\r\n\r\n    // Retry on lock timeouts.\r\n    if (response.status === 409) return true;\r\n\r\n    // Retry on rate limits.\r\n    if (response.status === 429) return true;\r\n\r\n    // Retry internal errors.\r\n    if (response.status >= 500) return true;\r\n\r\n    return false;\r\n  }\r\n\r\n  private async retryRequest(\r\n    options: FinalRequestOptions,\r\n    retriesRemaining: number,\r\n    responseHeaders?: Headers | undefined,\r\n  ): Promise<APIResponseProps> {\r\n    let timeoutMillis: number | undefined;\r\n\r\n    // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\r\n    const retryAfterMillisHeader = responseHeaders?.['retry-after-ms'];\r\n    if (retryAfterMillisHeader) {\r\n      const timeoutMs = parseFloat(retryAfterMillisHeader);\r\n      if (!Number.isNaN(timeoutMs)) {\r\n        timeoutMillis = timeoutMs;\r\n      }\r\n    }\r\n\r\n    // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\r\n    const retryAfterHeader = responseHeaders?.['retry-after'];\r\n    if (retryAfterHeader && !timeoutMillis) {\r\n      const timeoutSeconds = parseFloat(retryAfterHeader);\r\n      if (!Number.isNaN(timeoutSeconds)) {\r\n        timeoutMillis = timeoutSeconds * 1000;\r\n      } else {\r\n        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\r\n      }\r\n    }\r\n\r\n    // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\r\n    // just do what it says, but otherwise calculate a default\r\n    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\r\n      const maxRetries = options.maxRetries ?? this.maxRetries;\r\n      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\r\n    }\r\n    await sleep(timeoutMillis);\r\n\r\n    return this.makeRequest(options, retriesRemaining - 1);\r\n  }\r\n\r\n  private calculateDefaultRetryTimeoutMillis(retriesRemaining: number, maxRetries: number): number {\r\n    const initialRetryDelay = 0.5;\r\n    const maxRetryDelay = 8.0;\r\n\r\n    const numRetries = maxRetries - retriesRemaining;\r\n\r\n    // Apply exponential backoff, but not more than the max.\r\n    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\r\n\r\n    // Apply some jitter, take up to at most 25 percent of the retry time.\r\n    const jitter = 1 - Math.random() * 0.25;\r\n\r\n    return sleepSeconds * jitter * 1000;\r\n  }\r\n\r\n  private getUserAgent(): string {\r\n    return `${this.constructor.name}/JS ${VERSION}`;\r\n  }\r\n}\r\n\r\nexport type PageInfo = { url: URL } | { params: Record<string, unknown> | null };\r\n\r\nexport abstract class AbstractPage<Item> implements AsyncIterable<Item> {\r\n  #client: APIClient;\r\n  protected options: FinalRequestOptions;\r\n\r\n  protected response: Response;\r\n  protected body: unknown;\r\n\r\n  constructor(client: APIClient, response: Response, body: unknown, options: FinalRequestOptions) {\r\n    this.#client = client;\r\n    this.options = options;\r\n    this.response = response;\r\n    this.body = body;\r\n  }\r\n\r\n  /**\r\n   * @deprecated Use nextPageInfo instead\r\n   */\r\n  abstract nextPageParams(): Partial<Record<string, unknown>> | null;\r\n  abstract nextPageInfo(): PageInfo | null;\r\n\r\n  abstract getPaginatedItems(): Item[];\r\n\r\n  hasNextPage(): boolean {\r\n    const items = this.getPaginatedItems();\r\n    if (!items.length) return false;\r\n    return this.nextPageInfo() != null;\r\n  }\r\n\r\n  async getNextPage(): Promise<this> {\r\n    const nextInfo = this.nextPageInfo();\r\n    if (!nextInfo) {\r\n      throw new OpenAIError(\r\n        'No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.',\r\n      );\r\n    }\r\n    const nextOptions = { ...this.options };\r\n    if ('params' in nextInfo && typeof nextOptions.query === 'object') {\r\n      nextOptions.query = { ...nextOptions.query, ...nextInfo.params };\r\n    } else if ('url' in nextInfo) {\r\n      const params = [...Object.entries(nextOptions.query || {}), ...nextInfo.url.searchParams.entries()];\r\n      for (const [key, value] of params) {\r\n        nextInfo.url.searchParams.set(key, value as any);\r\n      }\r\n      nextOptions.query = undefined;\r\n      nextOptions.path = nextInfo.url.toString();\r\n    }\r\n    return await this.#client.requestAPIList(this.constructor as any, nextOptions);\r\n  }\r\n\r\n  async *iterPages() {\r\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\r\n    let page: AbstractPage<Item> = this;\r\n    yield page;\r\n    while (page.hasNextPage()) {\r\n      page = await page.getNextPage();\r\n      yield page;\r\n    }\r\n  }\r\n\r\n  async *[Symbol.asyncIterator]() {\r\n    for await (const page of this.iterPages()) {\r\n      for (const item of page.getPaginatedItems()) {\r\n        yield item;\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\r\n *\r\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\r\n *\r\n *    for await (const item of client.items.list()) {\r\n *      console.log(item)\r\n *    }\r\n */\r\nexport class PagePromise<\r\n    PageClass extends AbstractPage<Item>,\r\n    Item = ReturnType<PageClass['getPaginatedItems']>[number],\r\n  >\r\n  extends APIPromise<PageClass>\r\n  implements AsyncIterable<Item>\r\n{\r\n  constructor(\r\n    client: APIClient,\r\n    request: Promise<APIResponseProps>,\r\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\r\n  ) {\r\n    super(\r\n      request,\r\n      async (props) => new Page(client, props.response, await defaultParseResponse(props), props.options),\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Allow auto-paginating iteration on an unawaited list call, eg:\r\n   *\r\n   *    for await (const item of client.items.list()) {\r\n   *      console.log(item)\r\n   *    }\r\n   */\r\n  async *[Symbol.asyncIterator]() {\r\n    const page = await this;\r\n    for await (const item of page) {\r\n      yield item;\r\n    }\r\n  }\r\n}\r\n\r\nexport const createResponseHeaders = (\r\n  headers: Awaited<ReturnType<Fetch>>['headers'],\r\n): Record<string, string> => {\r\n  return new Proxy(\r\n    Object.fromEntries(\r\n      // @ts-ignore\r\n      headers.entries(),\r\n    ),\r\n    {\r\n      get(target, name) {\r\n        const key = name.toString();\r\n        return target[key.toLowerCase()] || target[key];\r\n      },\r\n    },\r\n  );\r\n};\r\n\r\ntype HTTPMethod = 'get' | 'post' | 'put' | 'patch' | 'delete';\r\n\r\nexport type RequestClient = { fetch: Fetch };\r\nexport type Headers = Record<string, string | null | undefined>;\r\nexport type DefaultQuery = Record<string, string | undefined>;\r\nexport type KeysEnum<T> = { [P in keyof Required<T>]: true };\r\n\r\nexport type RequestOptions<Req = unknown | Record<string, unknown> | Readable> = {\r\n  method?: HTTPMethod;\r\n  path?: string;\r\n  query?: Req | undefined;\r\n  body?: Req | null | undefined;\r\n  headers?: Headers | undefined;\r\n\r\n  maxRetries?: number;\r\n  stream?: boolean | undefined;\r\n  timeout?: number;\r\n  httpAgent?: Agent;\r\n  signal?: AbortSignal | undefined | null;\r\n  idempotencyKey?: string;\r\n\r\n  __binaryResponse?: boolean | undefined;\r\n  __streamClass?: typeof Stream;\r\n};\r\n\r\n// This is required so that we can determine if a given object matches the RequestOptions\r\n// type at runtime. While this requires duplication, it is enforced by the TypeScript\r\n// compiler such that any missing / extraneous keys will cause an error.\r\nconst requestOptionsKeys: KeysEnum<RequestOptions> = {\r\n  method: true,\r\n  path: true,\r\n  query: true,\r\n  body: true,\r\n  headers: true,\r\n\r\n  maxRetries: true,\r\n  stream: true,\r\n  timeout: true,\r\n  httpAgent: true,\r\n  signal: true,\r\n  idempotencyKey: true,\r\n\r\n  __binaryResponse: true,\r\n  __streamClass: true,\r\n};\r\n\r\nexport const isRequestOptions = (obj: unknown): obj is RequestOptions => {\r\n  return (\r\n    typeof obj === 'object' &&\r\n    obj !== null &&\r\n    !isEmptyObj(obj) &&\r\n    Object.keys(obj).every((k) => hasOwn(requestOptionsKeys, k))\r\n  );\r\n};\r\n\r\nexport type FinalRequestOptions<Req = unknown | Record<string, unknown> | Readable> = RequestOptions<Req> & {\r\n  method: HTTPMethod;\r\n  path: string;\r\n};\r\n\r\ndeclare const Deno: any;\r\ndeclare const EdgeRuntime: any;\r\ntype Arch = 'x32' | 'x64' | 'arm' | 'arm64' | `other:${string}` | 'unknown';\r\ntype PlatformName =\r\n  | 'MacOS'\r\n  | 'Linux'\r\n  | 'Windows'\r\n  | 'FreeBSD'\r\n  | 'OpenBSD'\r\n  | 'iOS'\r\n  | 'Android'\r\n  | `Other:${string}`\r\n  | 'Unknown';\r\ntype Browser = 'ie' | 'edge' | 'chrome' | 'firefox' | 'safari';\r\ntype PlatformProperties = {\r\n  'X-Stainless-Lang': 'js';\r\n  'X-Stainless-Package-Version': string;\r\n  'X-Stainless-OS': PlatformName;\r\n  'X-Stainless-Arch': Arch;\r\n  'X-Stainless-Runtime': 'node' | 'deno' | 'edge' | `browser:${Browser}` | 'unknown';\r\n  'X-Stainless-Runtime-Version': string;\r\n};\r\nconst getPlatformProperties = (): PlatformProperties => {\r\n  if (typeof Deno !== 'undefined' && Deno.build != null) {\r\n    return {\r\n      'X-Stainless-Lang': 'js',\r\n      'X-Stainless-Package-Version': VERSION,\r\n      'X-Stainless-OS': normalizePlatform(Deno.build.os),\r\n      'X-Stainless-Arch': normalizeArch(Deno.build.arch),\r\n      'X-Stainless-Runtime': 'deno',\r\n      'X-Stainless-Runtime-Version': Deno.version,\r\n    };\r\n  }\r\n  if (typeof EdgeRuntime !== 'undefined') {\r\n    return {\r\n      'X-Stainless-Lang': 'js',\r\n      'X-Stainless-Package-Version': VERSION,\r\n      'X-Stainless-OS': 'Unknown',\r\n      'X-Stainless-Arch': `other:${EdgeRuntime}`,\r\n      'X-Stainless-Runtime': 'edge',\r\n      'X-Stainless-Runtime-Version': process.version,\r\n    };\r\n  }\r\n  // Check if Node.js\r\n  if (Object.prototype.toString.call(typeof process !== 'undefined' ? process : 0) === '[object process]') {\r\n    return {\r\n      'X-Stainless-Lang': 'js',\r\n      'X-Stainless-Package-Version': VERSION,\r\n      'X-Stainless-OS': normalizePlatform(process.platform),\r\n      'X-Stainless-Arch': normalizeArch(process.arch),\r\n      'X-Stainless-Runtime': 'node',\r\n      'X-Stainless-Runtime-Version': process.version,\r\n    };\r\n  }\r\n\r\n  const browserInfo = getBrowserInfo();\r\n  if (browserInfo) {\r\n    return {\r\n      'X-Stainless-Lang': 'js',\r\n      'X-Stainless-Package-Version': VERSION,\r\n      'X-Stainless-OS': 'Unknown',\r\n      'X-Stainless-Arch': 'unknown',\r\n      'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\r\n      'X-Stainless-Runtime-Version': browserInfo.version,\r\n    };\r\n  }\r\n\r\n  // TODO add support for Cloudflare workers, etc.\r\n  return {\r\n    'X-Stainless-Lang': 'js',\r\n    'X-Stainless-Package-Version': VERSION,\r\n    'X-Stainless-OS': 'Unknown',\r\n    'X-Stainless-Arch': 'unknown',\r\n    'X-Stainless-Runtime': 'unknown',\r\n    'X-Stainless-Runtime-Version': 'unknown',\r\n  };\r\n};\r\n\r\ntype BrowserInfo = {\r\n  browser: Browser;\r\n  version: string;\r\n};\r\n\r\ndeclare const navigator: { userAgent: string } | undefined;\r\n\r\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\r\nfunction getBrowserInfo(): BrowserInfo | null {\r\n  if (typeof navigator === 'undefined' || !navigator) {\r\n    return null;\r\n  }\r\n\r\n  // NOTE: The order matters here!\r\n  const browserPatterns = [\r\n    { key: 'edge' as const, pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\r\n    { key: 'ie' as const, pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\r\n    { key: 'ie' as const, pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\r\n    { key: 'chrome' as const, pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\r\n    { key: 'firefox' as const, pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\r\n    { key: 'safari' as const, pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\r\n  ];\r\n\r\n  // Find the FIRST matching browser\r\n  for (const { key, pattern } of browserPatterns) {\r\n    const match = pattern.exec(navigator.userAgent);\r\n    if (match) {\r\n      const major = match[1] || 0;\r\n      const minor = match[2] || 0;\r\n      const patch = match[3] || 0;\r\n\r\n      return { browser: key, version: `${major}.${minor}.${patch}` };\r\n    }\r\n  }\r\n\r\n  return null;\r\n}\r\n\r\nconst normalizeArch = (arch: string): Arch => {\r\n  // Node docs:\r\n  // - https://nodejs.org/api/process.html#processarch\r\n  // Deno docs:\r\n  // - https://doc.deno.land/deno/stable/~/Deno.build\r\n  if (arch === 'x32') return 'x32';\r\n  if (arch === 'x86_64' || arch === 'x64') return 'x64';\r\n  if (arch === 'arm') return 'arm';\r\n  if (arch === 'aarch64' || arch === 'arm64') return 'arm64';\r\n  if (arch) return `other:${arch}`;\r\n  return 'unknown';\r\n};\r\n\r\nconst normalizePlatform = (platform: string): PlatformName => {\r\n  // Node platforms:\r\n  // - https://nodejs.org/api/process.html#processplatform\r\n  // Deno platforms:\r\n  // - https://doc.deno.land/deno/stable/~/Deno.build\r\n  // - https://github.com/denoland/deno/issues/14799\r\n\r\n  platform = platform.toLowerCase();\r\n\r\n  // NOTE: this iOS check is untested and may not work\r\n  // Node does not work natively on IOS, there is a fork at\r\n  // https://github.com/nodejs-mobile/nodejs-mobile\r\n  // however it is unknown at the time of writing how to detect if it is running\r\n  if (platform.includes('ios')) return 'iOS';\r\n  if (platform === 'android') return 'Android';\r\n  if (platform === 'darwin') return 'MacOS';\r\n  if (platform === 'win32') return 'Windows';\r\n  if (platform === 'freebsd') return 'FreeBSD';\r\n  if (platform === 'openbsd') return 'OpenBSD';\r\n  if (platform === 'linux') return 'Linux';\r\n  if (platform) return `Other:${platform}`;\r\n  return 'Unknown';\r\n};\r\n\r\nlet _platformHeaders: PlatformProperties;\r\nconst getPlatformHeaders = () => {\r\n  return (_platformHeaders ??= getPlatformProperties());\r\n};\r\n\r\nexport const safeJSON = (text: string) => {\r\n  try {\r\n    return JSON.parse(text);\r\n  } catch (err) {\r\n    return undefined;\r\n  }\r\n};\r\n\r\n// https://stackoverflow.com/a/19709846\r\nconst startsWithSchemeRegexp = new RegExp('^(?:[a-z]+:)?//', 'i');\r\nconst isAbsoluteURL = (url: string): boolean => {\r\n  return startsWithSchemeRegexp.test(url);\r\n};\r\n\r\nexport const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));\r\n\r\nconst validatePositiveInteger = (name: string, n: unknown): number => {\r\n  if (typeof n !== 'number' || !Number.isInteger(n)) {\r\n    throw new OpenAIError(`${name} must be an integer`);\r\n  }\r\n  if (n < 0) {\r\n    throw new OpenAIError(`${name} must be a positive integer`);\r\n  }\r\n  return n;\r\n};\r\n\r\nexport const castToError = (err: any): Error => {\r\n  if (err instanceof Error) return err;\r\n  return new Error(err);\r\n};\r\n\r\nexport const ensurePresent = <T>(value: T | null | undefined): T => {\r\n  if (value == null) throw new OpenAIError(`Expected a value to be given but received ${value} instead.`);\r\n  return value;\r\n};\r\n\r\n/**\r\n * Read an environment variable.\r\n *\r\n * Trims beginning and trailing whitespace.\r\n *\r\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\r\n */\r\nexport const readEnv = (env: string): string | undefined => {\r\n  if (typeof process !== 'undefined') {\r\n    return process.env?.[env]?.trim() ?? undefined;\r\n  }\r\n  if (typeof Deno !== 'undefined') {\r\n    return Deno.env?.get?.(env)?.trim();\r\n  }\r\n  return undefined;\r\n};\r\n\r\nexport const coerceInteger = (value: unknown): number => {\r\n  if (typeof value === 'number') return Math.round(value);\r\n  if (typeof value === 'string') return parseInt(value, 10);\r\n\r\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\r\n};\r\n\r\nexport const coerceFloat = (value: unknown): number => {\r\n  if (typeof value === 'number') return value;\r\n  if (typeof value === 'string') return parseFloat(value);\r\n\r\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\r\n};\r\n\r\nexport const coerceBoolean = (value: unknown): boolean => {\r\n  if (typeof value === 'boolean') return value;\r\n  if (typeof value === 'string') return value === 'true';\r\n  return Boolean(value);\r\n};\r\n\r\nexport const maybeCoerceInteger = (value: unknown): number | undefined => {\r\n  if (value === undefined) {\r\n    return undefined;\r\n  }\r\n  return coerceInteger(value);\r\n};\r\n\r\nexport const maybeCoerceFloat = (value: unknown): number | undefined => {\r\n  if (value === undefined) {\r\n    return undefined;\r\n  }\r\n  return coerceFloat(value);\r\n};\r\n\r\nexport const maybeCoerceBoolean = (value: unknown): boolean | undefined => {\r\n  if (value === undefined) {\r\n    return undefined;\r\n  }\r\n  return coerceBoolean(value);\r\n};\r\n\r\n// https://stackoverflow.com/a/34491287\r\nexport function isEmptyObj(obj: Object | null | undefined): boolean {\r\n  if (!obj) return true;\r\n  for (const _k in obj) return false;\r\n  return true;\r\n}\r\n\r\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\r\nexport function hasOwn(obj: Object, key: string): boolean {\r\n  return Object.prototype.hasOwnProperty.call(obj, key);\r\n}\r\n\r\n/**\r\n * Copies headers from \"newHeaders\" onto \"targetHeaders\",\r\n * using lower-case for all properties,\r\n * ignoring any keys with undefined values,\r\n * and deleting any keys with null values.\r\n */\r\nfunction applyHeadersMut(targetHeaders: Headers, newHeaders: Headers): void {\r\n  for (const k in newHeaders) {\r\n    if (!hasOwn(newHeaders, k)) continue;\r\n    const lowerKey = k.toLowerCase();\r\n    if (!lowerKey) continue;\r\n\r\n    const val = newHeaders[k];\r\n\r\n    if (val === null) {\r\n      delete targetHeaders[lowerKey];\r\n    } else if (val !== undefined) {\r\n      targetHeaders[lowerKey] = val;\r\n    }\r\n  }\r\n}\r\n\r\nexport function debug(action: string, ...args: any[]) {\r\n  if (typeof process !== 'undefined' && process.env['DEBUG'] === 'true') {\r\n    console.log(`OpenAI:DEBUG:${action}`, ...args);\r\n  }\r\n}\r\n\r\n/**\r\n * https://stackoverflow.com/a/2117523\r\n */\r\nconst uuid4 = () => {\r\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {\r\n    const r = (Math.random() * 16) | 0;\r\n    const v = c === 'x' ? r : (r & 0x3) | 0x8;\r\n    return v.toString(16);\r\n  });\r\n};\r\n\r\nexport const isRunningInBrowser = () => {\r\n  return (\r\n    // @ts-ignore\r\n    typeof window !== 'undefined' &&\r\n    // @ts-ignore\r\n    typeof window.document !== 'undefined' &&\r\n    // @ts-ignore\r\n    typeof navigator !== 'undefined'\r\n  );\r\n};\r\n\r\nexport interface HeadersProtocol {\r\n  get: (header: string) => string | null | undefined;\r\n}\r\nexport type HeadersLike = Record<string, string | string[] | undefined> | HeadersProtocol;\r\n\r\nexport const isHeadersProtocol = (headers: any): headers is HeadersProtocol => {\r\n  return typeof headers?.get === 'function';\r\n};\r\n\r\nexport const getRequiredHeader = (headers: HeadersLike, header: string): string => {\r\n  const lowerCasedHeader = header.toLowerCase();\r\n  if (isHeadersProtocol(headers)) {\r\n    // to deal with the case where the header looks like Stainless-Event-Id\r\n    const intercapsHeader =\r\n      header[0]?.toUpperCase() +\r\n      header.substring(1).replace(/([^\\w])(\\w)/g, (_m, g1, g2) => g1 + g2.toUpperCase());\r\n    for (const key of [header, lowerCasedHeader, header.toUpperCase(), intercapsHeader]) {\r\n      const value = headers.get(key);\r\n      if (value) {\r\n        return value;\r\n      }\r\n    }\r\n  }\r\n\r\n  for (const [key, value] of Object.entries(headers)) {\r\n    if (key.toLowerCase() === lowerCasedHeader) {\r\n      if (Array.isArray(value)) {\r\n        if (value.length <= 1) return value[0];\r\n        console.warn(`Received ${value.length} entries for the ${header} header, using the first entry.`);\r\n        return value[0];\r\n      }\r\n      return value;\r\n    }\r\n  }\r\n\r\n  throw new Error(`Could not find ${header} header`);\r\n};\r\n\r\n/**\r\n * Encodes a string to Base64 format.\r\n */\r\nexport const toBase64 = (str: string | null | undefined): string => {\r\n  if (!str) return '';\r\n  if (typeof Buffer !== 'undefined') {\r\n    return Buffer.from(str).toString('base64');\r\n  }\r\n\r\n  if (typeof btoa !== 'undefined') {\r\n    return btoa(str);\r\n  }\r\n\r\n  throw new OpenAIError('Cannot generate b64 string; Expected `Buffer` or `btoa` to be defined');\r\n};\r\n\r\nexport function isObj(obj: unknown): obj is Record<string, unknown> {\r\n  return obj != null && typeof obj === 'object' && !Array.isArray(obj);\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport { AbstractPage, Response, APIClient, FinalRequestOptions, PageInfo } from './core';\r\n\r\nexport interface PageResponse<Item> {\r\n  data: Array<Item>;\r\n\r\n  object: string;\r\n}\r\n\r\n/**\r\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\r\n */\r\nexport class Page<Item> extends AbstractPage<Item> implements PageResponse<Item> {\r\n  data: Array<Item>;\r\n\r\n  object: string;\r\n\r\n  constructor(client: APIClient, response: Response, body: PageResponse<Item>, options: FinalRequestOptions) {\r\n    super(client, response, body, options);\r\n\r\n    this.data = body.data || [];\r\n    this.object = body.object;\r\n  }\r\n\r\n  getPaginatedItems(): Item[] {\r\n    return this.data ?? [];\r\n  }\r\n\r\n  // @deprecated Please use `nextPageInfo()` instead\r\n  /**\r\n   * This page represents a response that isn't actually paginated at the API level\r\n   * so there will never be any next page params.\r\n   */\r\n  nextPageParams(): null {\r\n    return null;\r\n  }\r\n\r\n  nextPageInfo(): null {\r\n    return null;\r\n  }\r\n}\r\n\r\nexport interface CursorPageResponse<Item> {\r\n  data: Array<Item>;\r\n}\r\n\r\nexport interface CursorPageParams {\r\n  after?: string;\r\n\r\n  limit?: number;\r\n}\r\n\r\nexport class CursorPage<Item extends { id: string }>\r\n  extends AbstractPage<Item>\r\n  implements CursorPageResponse<Item>\r\n{\r\n  data: Array<Item>;\r\n\r\n  constructor(\r\n    client: APIClient,\r\n    response: Response,\r\n    body: CursorPageResponse<Item>,\r\n    options: FinalRequestOptions,\r\n  ) {\r\n    super(client, response, body, options);\r\n\r\n    this.data = body.data || [];\r\n  }\r\n\r\n  getPaginatedItems(): Item[] {\r\n    return this.data ?? [];\r\n  }\r\n\r\n  // @deprecated Please use `nextPageInfo()` instead\r\n  nextPageParams(): Partial<CursorPageParams> | null {\r\n    const info = this.nextPageInfo();\r\n    if (!info) return null;\r\n    if ('params' in info) return info.params;\r\n    const params = Object.fromEntries(info.url.searchParams);\r\n    if (!Object.keys(params).length) return null;\r\n    return params;\r\n  }\r\n\r\n  nextPageInfo(): PageInfo | null {\r\n    const data = this.getPaginatedItems();\r\n    if (!data.length) {\r\n      return null;\r\n    }\r\n\r\n    const id = data[data.length - 1]?.id;\r\n    if (!id) {\r\n      return null;\r\n    }\r\n\r\n    return { params: { after: id } };\r\n  }\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport type { OpenAI } from './index';\r\n\r\nexport class APIResource {\r\n  protected _client: OpenAI;\r\n\r\n  constructor(client: OpenAI) {\r\n    this._client = client;\r\n  }\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../core\";\r\nimport { APIPromise } from \"../../core\";\r\nimport { APIResource } from \"../../resource\";\r\nimport * as ChatCompletionsAPI from \"./completions\";\r\nimport * as CompletionsAPI from \"../completions\";\r\nimport * as Shared from \"../shared\";\r\nimport { Stream } from \"../../streaming\";\r\n\r\nexport class Completions extends APIResource {\r\n  /**\r\n   * Creates a model response for the given chat conversation.\r\n   */\r\n  create(\r\n    body: ChatCompletionCreateParamsNonStreaming,\r\n    options?: Core.RequestOptions,\r\n  ): APIPromise<ChatCompletion>;\r\n  create(\r\n    body: ChatCompletionCreateParamsStreaming,\r\n    options?: Core.RequestOptions,\r\n  ): APIPromise<Stream<ChatCompletionChunk>>;\r\n  create(\r\n    body: ChatCompletionCreateParamsBase,\r\n    options?: Core.RequestOptions,\r\n  ): APIPromise<Stream<ChatCompletionChunk> | ChatCompletion>;\r\n  create(\r\n    body: ChatCompletionCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): APIPromise<ChatCompletion> | APIPromise<Stream<ChatCompletionChunk>> {\r\n    return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false }) as\r\n      | APIPromise<ChatCompletion>\r\n      | APIPromise<Stream<ChatCompletionChunk>>;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents a chat completion response returned by model, based on the provided\r\n * input.\r\n */\r\nexport interface ChatCompletion {\r\n  /**\r\n   * A unique identifier for the chat completion.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * A list of chat completion choices. Can be more than one if `n` is greater\r\n   * than 1.\r\n   */\r\n  choices: Array<ChatCompletion.Choice>;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) of when the chat completion was created.\r\n   */\r\n  created: number;\r\n\r\n  /**\r\n   * The model used for the chat completion.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always `chat.completion`.\r\n   */\r\n  object: 'chat.completion';\r\n\r\n  /**\r\n   * This fingerprint represents the backend configuration that the model runs with.\r\n   *\r\n   * Can be used in conjunction with the `seed` request parameter to understand when\r\n   * backend changes have been made that might impact determinism.\r\n   */\r\n  system_fingerprint?: string;\r\n\r\n  /**\r\n   * Usage statistics for the completion request.\r\n   */\r\n  usage?: CompletionsAPI.CompletionUsage;\r\n}\r\n\r\nexport namespace ChatCompletion {\r\n  export interface Choice {\r\n    /**\r\n     * The reason the model stopped generating tokens. This will be `stop` if the model\r\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\r\n     * number of tokens specified in the request was reached, `content_filter` if\r\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\r\n     * model called a tool, or `function_call` (deprecated) if the model called a\r\n     * function.\r\n     */\r\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';\r\n\r\n    /**\r\n     * The index of the choice in the list of choices.\r\n     */\r\n    index: number;\r\n\r\n    /**\r\n     * Log probability information for the choice.\r\n     */\r\n    logprobs: Choice.Logprobs | null;\r\n\r\n    /**\r\n     * A chat completion message generated by the model.\r\n     */\r\n    message: ChatCompletionsAPI.ChatCompletionMessage;\r\n  }\r\n\r\n  export namespace Choice {\r\n    /**\r\n     * Log probability information for the choice.\r\n     */\r\n    export interface Logprobs {\r\n      /**\r\n       * A list of message content tokens with log probability information.\r\n       */\r\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\r\n    }\r\n  }\r\n}\r\n\r\nexport interface ChatCompletionAssistantMessageParam {\r\n  /**\r\n   * The role of the messages author, in this case `assistant`.\r\n   */\r\n  role: 'assistant';\r\n\r\n  /**\r\n   * The contents of the assistant message. Required unless `tool_calls` or\r\n   * `function_call` is specified.\r\n   */\r\n  content?: string | null;\r\n\r\n  /**\r\n   * Deprecated and replaced by `tool_calls`. The name and arguments of a function\r\n   * that should be called, as generated by the model.\r\n   */\r\n  function_call?: ChatCompletionAssistantMessageParam.FunctionCall;\r\n\r\n  /**\r\n   * An optional name for the participant. Provides the model information to\r\n   * differentiate between participants of the same role.\r\n   */\r\n  name?: string;\r\n\r\n  /**\r\n   * The tool calls generated by the model, such as function calls.\r\n   */\r\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\r\n}\r\n\r\nexport namespace ChatCompletionAssistantMessageParam {\r\n  /**\r\n   * Deprecated and replaced by `tool_calls`. The name and arguments of a function\r\n   * that should be called, as generated by the model.\r\n   */\r\n  export interface FunctionCall {\r\n    /**\r\n     * The arguments to call the function with, as generated by the model in JSON\r\n     * format. Note that the model does not always generate valid JSON, and may\r\n     * hallucinate parameters not defined by your function schema. Validate the\r\n     * arguments in your code before calling your function.\r\n     */\r\n    arguments: string;\r\n\r\n    /**\r\n     * The name of the function to call.\r\n     */\r\n    name: string;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents a streamed chunk of a chat completion response returned by model,\r\n * based on the provided input.\r\n */\r\nexport interface ChatCompletionChunk {\r\n  /**\r\n   * A unique identifier for the chat completion. Each chunk has the same ID.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * A list of chat completion choices. Can be more than one if `n` is greater\r\n   * than 1.\r\n   */\r\n  choices: Array<ChatCompletionChunk.Choice>;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) of when the chat completion was created. Each\r\n   * chunk has the same timestamp.\r\n   */\r\n  created: number;\r\n\r\n  /**\r\n   * The model to generate the completion.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always `chat.completion.chunk`.\r\n   */\r\n  object: 'chat.completion.chunk';\r\n\r\n  /**\r\n   * This fingerprint represents the backend configuration that the model runs with.\r\n   * Can be used in conjunction with the `seed` request parameter to understand when\r\n   * backend changes have been made that might impact determinism.\r\n   */\r\n  system_fingerprint?: string;\r\n}\r\n\r\nexport namespace ChatCompletionChunk {\r\n  export interface Choice {\r\n    /**\r\n     * A chat completion delta generated by streamed model responses.\r\n     */\r\n    delta: Choice.Delta;\r\n\r\n    /**\r\n     * The reason the model stopped generating tokens. This will be `stop` if the model\r\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\r\n     * number of tokens specified in the request was reached, `content_filter` if\r\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\r\n     * model called a tool, or `function_call` (deprecated) if the model called a\r\n     * function.\r\n     */\r\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call' | null;\r\n\r\n    /**\r\n     * The index of the choice in the list of choices.\r\n     */\r\n    index: number;\r\n\r\n    /**\r\n     * Log probability information for the choice.\r\n     */\r\n    logprobs?: Choice.Logprobs | null;\r\n  }\r\n\r\n  export namespace Choice {\r\n    /**\r\n     * A chat completion delta generated by streamed model responses.\r\n     */\r\n    export interface Delta {\r\n      /**\r\n       * The contents of the chunk message.\r\n       */\r\n      content?: string | null;\r\n\r\n      /**\r\n       * Deprecated and replaced by `tool_calls`. The name and arguments of a function\r\n       * that should be called, as generated by the model.\r\n       */\r\n      function_call?: Delta.FunctionCall;\r\n\r\n      /**\r\n       * The role of the author of this message.\r\n       */\r\n      role?: 'system' | 'user' | 'assistant' | 'tool';\r\n\r\n      tool_calls?: Array<Delta.ToolCall>;\r\n    }\r\n\r\n    export namespace Delta {\r\n      /**\r\n       * Deprecated and replaced by `tool_calls`. The name and arguments of a function\r\n       * that should be called, as generated by the model.\r\n       */\r\n      export interface FunctionCall {\r\n        /**\r\n         * The arguments to call the function with, as generated by the model in JSON\r\n         * format. Note that the model does not always generate valid JSON, and may\r\n         * hallucinate parameters not defined by your function schema. Validate the\r\n         * arguments in your code before calling your function.\r\n         */\r\n        arguments?: string;\r\n\r\n        /**\r\n         * The name of the function to call.\r\n         */\r\n        name?: string;\r\n      }\r\n\r\n      export interface ToolCall {\r\n        index: number;\r\n\r\n        /**\r\n         * The ID of the tool call.\r\n         */\r\n        id?: string;\r\n\r\n        function?: ToolCall.Function;\r\n\r\n        /**\r\n         * The type of the tool. Currently, only `function` is supported.\r\n         */\r\n        type?: 'function';\r\n      }\r\n\r\n      export namespace ToolCall {\r\n        export interface Function {\r\n          /**\r\n           * The arguments to call the function with, as generated by the model in JSON\r\n           * format. Note that the model does not always generate valid JSON, and may\r\n           * hallucinate parameters not defined by your function schema. Validate the\r\n           * arguments in your code before calling your function.\r\n           */\r\n          arguments?: string;\r\n\r\n          /**\r\n           * The name of the function to call.\r\n           */\r\n          name?: string;\r\n        }\r\n      }\r\n    }\r\n\r\n    /**\r\n     * Log probability information for the choice.\r\n     */\r\n    export interface Logprobs {\r\n      /**\r\n       * A list of message content tokens with log probability information.\r\n       */\r\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\r\n    }\r\n  }\r\n}\r\n\r\nexport type ChatCompletionContentPart = ChatCompletionContentPartText | ChatCompletionContentPartImage;\r\n\r\nexport interface ChatCompletionContentPartImage {\r\n  image_url: ChatCompletionContentPartImage.ImageURL;\r\n\r\n  /**\r\n   * The type of the content part.\r\n   */\r\n  type: 'image_url';\r\n}\r\n\r\nexport namespace ChatCompletionContentPartImage {\r\n  export interface ImageURL {\r\n    /**\r\n     * Either a URL of the image or the base64 encoded image data.\r\n     */\r\n    url: string;\r\n\r\n    /**\r\n     * Specifies the detail level of the image. Learn more in the\r\n     * [Vision guide](https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding).\r\n     */\r\n    detail?: 'auto' | 'low' | 'high';\r\n  }\r\n}\r\n\r\nexport interface ChatCompletionContentPartText {\r\n  /**\r\n   * The text content.\r\n   */\r\n  text: string;\r\n\r\n  /**\r\n   * The type of the content part.\r\n   */\r\n  type: 'text';\r\n}\r\n\r\n/**\r\n * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\r\n * to call that function.\r\n */\r\nexport interface ChatCompletionFunctionCallOption {\r\n  /**\r\n   * The name of the function to call.\r\n   */\r\n  name: string;\r\n}\r\n\r\nexport interface ChatCompletionFunctionMessageParam {\r\n  /**\r\n   * The contents of the function message.\r\n   */\r\n  content: string | null;\r\n\r\n  /**\r\n   * The name of the function to call.\r\n   */\r\n  name: string;\r\n\r\n  /**\r\n   * The role of the messages author, in this case `function`.\r\n   */\r\n  role: 'function';\r\n}\r\n\r\n/**\r\n * A chat completion message generated by the model.\r\n */\r\nexport interface ChatCompletionMessage {\r\n  /**\r\n   * The contents of the message.\r\n   */\r\n  content: string | null;\r\n\r\n  /**\r\n   * The role of the author of this message.\r\n   */\r\n  role: 'assistant';\r\n\r\n  /**\r\n   * Deprecated and replaced by `tool_calls`. The name and arguments of a function\r\n   * that should be called, as generated by the model.\r\n   */\r\n  function_call?: ChatCompletionMessage.FunctionCall;\r\n\r\n  /**\r\n   * The tool calls generated by the model, such as function calls.\r\n   */\r\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\r\n}\r\n\r\nexport namespace ChatCompletionMessage {\r\n  /**\r\n   * Deprecated and replaced by `tool_calls`. The name and arguments of a function\r\n   * that should be called, as generated by the model.\r\n   */\r\n  export interface FunctionCall {\r\n    /**\r\n     * The arguments to call the function with, as generated by the model in JSON\r\n     * format. Note that the model does not always generate valid JSON, and may\r\n     * hallucinate parameters not defined by your function schema. Validate the\r\n     * arguments in your code before calling your function.\r\n     */\r\n    arguments: string;\r\n\r\n    /**\r\n     * The name of the function to call.\r\n     */\r\n    name: string;\r\n  }\r\n}\r\n\r\nexport type ChatCompletionMessageParam =\r\n  | ChatCompletionSystemMessageParam\r\n  | ChatCompletionUserMessageParam\r\n  | ChatCompletionAssistantMessageParam\r\n  | ChatCompletionToolMessageParam\r\n  | ChatCompletionFunctionMessageParam;\r\n\r\nexport interface ChatCompletionMessageToolCall {\r\n  /**\r\n   * The ID of the tool call.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The function that the model called.\r\n   */\r\n  function: ChatCompletionMessageToolCall.Function;\r\n\r\n  /**\r\n   * The type of the tool. Currently, only `function` is supported.\r\n   */\r\n  type: 'function';\r\n}\r\n\r\nexport namespace ChatCompletionMessageToolCall {\r\n  /**\r\n   * The function that the model called.\r\n   */\r\n  export interface Function {\r\n    /**\r\n     * The arguments to call the function with, as generated by the model in JSON\r\n     * format. Note that the model does not always generate valid JSON, and may\r\n     * hallucinate parameters not defined by your function schema. Validate the\r\n     * arguments in your code before calling your function.\r\n     */\r\n    arguments: string;\r\n\r\n    /**\r\n     * The name of the function to call.\r\n     */\r\n    name: string;\r\n  }\r\n}\r\n\r\n/**\r\n * Specifies a tool the model should use. Use to force the model to call a specific\r\n * function.\r\n */\r\nexport interface ChatCompletionNamedToolChoice {\r\n  function: ChatCompletionNamedToolChoice.Function;\r\n\r\n  /**\r\n   * The type of the tool. Currently, only `function` is supported.\r\n   */\r\n  type: 'function';\r\n}\r\n\r\nexport namespace ChatCompletionNamedToolChoice {\r\n  export interface Function {\r\n    /**\r\n     * The name of the function to call.\r\n     */\r\n    name: string;\r\n  }\r\n}\r\n\r\n/**\r\n * The role of the author of a message\r\n */\r\nexport type ChatCompletionRole = 'system' | 'user' | 'assistant' | 'tool' | 'function';\r\n\r\nexport interface ChatCompletionSystemMessageParam {\r\n  /**\r\n   * The contents of the system message.\r\n   */\r\n  content: string;\r\n\r\n  /**\r\n   * The role of the messages author, in this case `system`.\r\n   */\r\n  role: 'system';\r\n\r\n  /**\r\n   * An optional name for the participant. Provides the model information to\r\n   * differentiate between participants of the same role.\r\n   */\r\n  name?: string;\r\n}\r\n\r\nexport interface ChatCompletionTokenLogprob {\r\n  /**\r\n   * The token.\r\n   */\r\n  token: string;\r\n\r\n  /**\r\n   * A list of integers representing the UTF-8 bytes representation of the token.\r\n   * Useful in instances where characters are represented by multiple tokens and\r\n   * their byte representations must be combined to generate the correct text\r\n   * representation. Can be `null` if there is no bytes representation for the token.\r\n   */\r\n  bytes: Array<number> | null;\r\n\r\n  /**\r\n   * The log probability of this token.\r\n   */\r\n  logprob: number;\r\n\r\n  /**\r\n   * List of the most likely tokens and their log probability, at this token\r\n   * position. In rare cases, there may be fewer than the number of requested\r\n   * `top_logprobs` returned.\r\n   */\r\n  top_logprobs: Array<ChatCompletionTokenLogprob.TopLogprob>;\r\n}\r\n\r\nexport namespace ChatCompletionTokenLogprob {\r\n  export interface TopLogprob {\r\n    /**\r\n     * The token.\r\n     */\r\n    token: string;\r\n\r\n    /**\r\n     * A list of integers representing the UTF-8 bytes representation of the token.\r\n     * Useful in instances where characters are represented by multiple tokens and\r\n     * their byte representations must be combined to generate the correct text\r\n     * representation. Can be `null` if there is no bytes representation for the token.\r\n     */\r\n    bytes: Array<number> | null;\r\n\r\n    /**\r\n     * The log probability of this token.\r\n     */\r\n    logprob: number;\r\n  }\r\n}\r\n\r\nexport interface ChatCompletionTool {\r\n  function: Shared.FunctionDefinition;\r\n\r\n  /**\r\n   * The type of the tool. Currently, only `function` is supported.\r\n   */\r\n  type: 'function';\r\n}\r\n\r\n/**\r\n * Controls which (if any) function is called by the model. `none` means the model\r\n * will not call a function and instead generates a message. `auto` means the model\r\n * can pick between generating a message or calling a function. Specifying a\r\n * particular function via\r\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\r\n * call that function.\r\n *\r\n * `none` is the default when no functions are present. `auto` is the default if\r\n * functions are present.\r\n */\r\nexport type ChatCompletionToolChoiceOption = 'none' | 'auto' | ChatCompletionNamedToolChoice;\r\n\r\nexport interface ChatCompletionToolMessageParam {\r\n  /**\r\n   * The contents of the tool message.\r\n   */\r\n  content: string;\r\n\r\n  /**\r\n   * The role of the messages author, in this case `tool`.\r\n   */\r\n  role: 'tool';\r\n\r\n  /**\r\n   * Tool call that this message is responding to.\r\n   */\r\n  tool_call_id: string;\r\n}\r\n\r\nexport interface ChatCompletionUserMessageParam {\r\n  /**\r\n   * The contents of the user message.\r\n   */\r\n  content: string | Array<ChatCompletionContentPart>;\r\n\r\n  /**\r\n   * The role of the messages author, in this case `user`.\r\n   */\r\n  role: 'user';\r\n\r\n  /**\r\n   * An optional name for the participant. Provides the model information to\r\n   * differentiate between participants of the same role.\r\n   */\r\n  name?: string;\r\n}\r\n\r\n/**\r\n * @deprecated ChatCompletionMessageParam should be used instead\r\n */\r\nexport type CreateChatCompletionRequestMessage = ChatCompletionMessageParam;\r\n\r\nexport type ChatCompletionCreateParams =\r\n  | ChatCompletionCreateParamsNonStreaming\r\n  | ChatCompletionCreateParamsStreaming;\r\n\r\nexport interface ChatCompletionCreateParamsBase {\r\n  /**\r\n   * A list of messages comprising the conversation so far.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).\r\n   */\r\n  messages: Array<ChatCompletionMessageParam>;\r\n\r\n  /**\r\n   * ID of the model to use. See the\r\n   * [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility)\r\n   * table for details on which models work with the Chat API.\r\n   */\r\n  model:\r\n    | (string & {})\r\n    | 'gpt-4-0125-preview'\r\n    | 'gpt-4-turbo-preview'\r\n    | 'gpt-4-1106-preview'\r\n    | 'gpt-4-vision-preview'\r\n    | 'gpt-4'\r\n    | 'gpt-4-0314'\r\n    | 'gpt-4-0613'\r\n    | 'gpt-4-32k'\r\n    | 'gpt-4-32k-0314'\r\n    | 'gpt-4-32k-0613'\r\n    | 'gpt-3.5-turbo'\r\n    | 'gpt-3.5-turbo-16k'\r\n    | 'gpt-3.5-turbo-0301'\r\n    | 'gpt-3.5-turbo-0613'\r\n    | 'gpt-3.5-turbo-1106'\r\n    | 'gpt-3.5-turbo-0125'\r\n    | 'gpt-3.5-turbo-16k-0613';\r\n\r\n  /**\r\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\r\n   * existing frequency in the text so far, decreasing the model's likelihood to\r\n   * repeat the same line verbatim.\r\n   *\r\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\r\n   */\r\n  frequency_penalty?: number | null;\r\n\r\n  /**\r\n   * Deprecated in favor of `tool_choice`.\r\n   *\r\n   * Controls which (if any) function is called by the model. `none` means the model\r\n   * will not call a function and instead generates a message. `auto` means the model\r\n   * can pick between generating a message or calling a function. Specifying a\r\n   * particular function via `{\"name\": \"my_function\"}` forces the model to call that\r\n   * function.\r\n   *\r\n   * `none` is the default when no functions are present. `auto` is the default if\r\n   * functions are present.\r\n   */\r\n  function_call?: 'none' | 'auto' | ChatCompletionFunctionCallOption;\r\n\r\n  /**\r\n   * Deprecated in favor of `tools`.\r\n   *\r\n   * A list of functions the model may generate JSON inputs for.\r\n   */\r\n  functions?: Array<ChatCompletionCreateParams.Function>;\r\n\r\n  /**\r\n   * An unique identifier to a custom instance to execute the request. The requesting\r\n   * organization is required to have access to the instance.\r\n   */\r\n  instance_id?: string | null;\r\n\r\n  /**\r\n   * Modify the likelihood of specified tokens appearing in the completion.\r\n   *\r\n   * Accepts a JSON object that maps tokens (specified by their token ID in the\r\n   * tokenizer) to an associated bias value from -100 to 100. Mathematically, the\r\n   * bias is added to the logits generated by the model prior to sampling. The exact\r\n   * effect will vary per model, but values between -1 and 1 should decrease or\r\n   * increase likelihood of selection; values like -100 or 100 should result in a ban\r\n   * or exclusive selection of the relevant token.\r\n   */\r\n  logit_bias?: Record<string, number> | null;\r\n\r\n  /**\r\n   * Whether to return log probabilities of the output tokens or not. If true,\r\n   * returns the log probabilities of each output token returned in the `content` of\r\n   * `message`. This option is currently not available on the `gpt-4-vision-preview`\r\n   * model.\r\n   */\r\n  logprobs?: boolean | null;\r\n\r\n  /**\r\n   * The maximum number of [tokens](/tokenizer) that can be generated in the chat\r\n   * completion.\r\n   *\r\n   * The total length of input tokens and generated tokens is limited by the model's\r\n   * context length.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\r\n   * for counting tokens.\r\n   */\r\n  max_tokens?: number | null;\r\n\r\n  /**\r\n   * How many chat completion choices to generate for each input message. Note that\r\n   * you will be charged based on the number of generated tokens across all of the\r\n   * choices. Keep `n` as `1` to minimize costs.\r\n   */\r\n  n?: number | null;\r\n\r\n  /**\r\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\r\n   * whether they appear in the text so far, increasing the model's likelihood to\r\n   * talk about new topics.\r\n   *\r\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\r\n   */\r\n  presence_penalty?: number | null;\r\n\r\n  /**\r\n   * An object specifying the format that the model must output. Compatible with\r\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) and\r\n   * all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.\r\n   *\r\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\r\n   * message the model generates is valid JSON.\r\n   *\r\n   * **Important:** when using JSON mode, you **must** also instruct the model to\r\n   * produce JSON yourself via a system or user message. Without this, the model may\r\n   * generate an unending stream of whitespace until the generation reaches the token\r\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\r\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\r\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\r\n   * max context length.\r\n   */\r\n  response_format?: ChatCompletionCreateParams.ResponseFormat;\r\n\r\n  /**\r\n   * This feature is in Beta. If specified, our system will make a best effort to\r\n   * sample deterministically, such that repeated requests with the same `seed` and\r\n   * parameters should return the same result. Determinism is not guaranteed, and you\r\n   * should refer to the `system_fingerprint` response parameter to monitor changes\r\n   * in the backend.\r\n   */\r\n  seed?: number | null;\r\n\r\n  /**\r\n   * Up to 4 sequences where the API will stop generating further tokens.\r\n   */\r\n  stop?: string | null | Array<string>;\r\n\r\n  /**\r\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\r\n   * sent as data-only\r\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\r\n   * as they become available, with the stream terminated by a `data: [DONE]`\r\n   * message.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\r\n   */\r\n  stream?: boolean | null;\r\n\r\n  /**\r\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\r\n   * make the output more random, while lower values like 0.2 will make it more\r\n   * focused and deterministic.\r\n   *\r\n   * We generally recommend altering this or `top_p` but not both.\r\n   */\r\n  temperature?: number | null;\r\n\r\n  /**\r\n   * Controls which (if any) function is called by the model. `none` means the model\r\n   * will not call a function and instead generates a message. `auto` means the model\r\n   * can pick between generating a message or calling a function. Specifying a\r\n   * particular function via\r\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\r\n   * call that function.\r\n   *\r\n   * `none` is the default when no functions are present. `auto` is the default if\r\n   * functions are present.\r\n   */\r\n  tool_choice?: ChatCompletionToolChoiceOption;\r\n\r\n  /**\r\n   * A list of tools the model may call. Currently, only functions are supported as a\r\n   * tool. Use this to provide a list of functions the model may generate JSON inputs\r\n   * for.\r\n   */\r\n  tools?: Array<ChatCompletionTool>;\r\n\r\n  /**\r\n   * An integer between 0 and 5 specifying the number of most likely tokens to return\r\n   * at each token position, each with an associated log probability. `logprobs` must\r\n   * be set to `true` if this parameter is used.\r\n   */\r\n  top_logprobs?: number | null;\r\n\r\n  /**\r\n   * An alternative to sampling with temperature, called nucleus sampling, where the\r\n   * model considers the results of the tokens with top_p probability mass. So 0.1\r\n   * means only the tokens comprising the top 10% probability mass are considered.\r\n   *\r\n   * We generally recommend altering this or `temperature` but not both.\r\n   */\r\n  top_p?: number | null;\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport namespace ChatCompletionCreateParams {\r\n  export interface Function {\r\n    /**\r\n     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\r\n     * underscores and dashes, with a maximum length of 64.\r\n     */\r\n    name: string;\r\n\r\n    /**\r\n     * A description of what the function does, used by the model to choose when and\r\n     * how to call the function.\r\n     */\r\n    description?: string;\r\n\r\n    /**\r\n     * The parameters the functions accepts, described as a JSON Schema object. See the\r\n     * [guide](https://platform.openai.com/docs/guides/text-generation/function-calling)\r\n     * for examples, and the\r\n     * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\r\n     * documentation about the format.\r\n     *\r\n     * Omitting `parameters` defines a function with an empty parameter list.\r\n     */\r\n    parameters?: Shared.FunctionParameters;\r\n  }\r\n\r\n  /**\r\n   * An object specifying the format that the model must output. Compatible with\r\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) and\r\n   * all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.\r\n   *\r\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\r\n   * message the model generates is valid JSON.\r\n   *\r\n   * **Important:** when using JSON mode, you **must** also instruct the model to\r\n   * produce JSON yourself via a system or user message. Without this, the model may\r\n   * generate an unending stream of whitespace until the generation reaches the token\r\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\r\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\r\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\r\n   * max context length.\r\n   */\r\n  export interface ResponseFormat {\r\n    /**\r\n     * Must be one of `text` or `json_object`.\r\n     */\r\n    type?: 'text' | 'json_object';\r\n  }\r\n\r\n  export type ChatCompletionCreateParamsNonStreaming =\r\n    ChatCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\r\n  export type ChatCompletionCreateParamsStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsStreaming;\r\n}\r\n\r\n/**\r\n * @deprecated Use ChatCompletionCreateParams instead\r\n */\r\nexport type CompletionCreateParams = ChatCompletionCreateParams;\r\n\r\nexport interface ChatCompletionCreateParamsNonStreaming extends ChatCompletionCreateParamsBase {\r\n  /**\r\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\r\n   * sent as data-only\r\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\r\n   * as they become available, with the stream terminated by a `data: [DONE]`\r\n   * message.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\r\n   */\r\n  stream?: false | null;\r\n}\r\n\r\n/**\r\n * @deprecated Use ChatCompletionCreateParamsNonStreaming instead\r\n */\r\nexport type CompletionCreateParamsNonStreaming = ChatCompletionCreateParamsNonStreaming;\r\n\r\nexport interface ChatCompletionCreateParamsStreaming extends ChatCompletionCreateParamsBase {\r\n  /**\r\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\r\n   * sent as data-only\r\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\r\n   * as they become available, with the stream terminated by a `data: [DONE]`\r\n   * message.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\r\n   */\r\n  stream: true;\r\n}\r\n\r\n/**\r\n * @deprecated Use ChatCompletionCreateParamsStreaming instead\r\n */\r\nexport type CompletionCreateParamsStreaming = ChatCompletionCreateParamsStreaming;\r\n\r\nexport namespace Completions {\r\n  export import ChatCompletion = ChatCompletionsAPI.ChatCompletion;\r\n  export import ChatCompletionAssistantMessageParam = ChatCompletionsAPI.ChatCompletionAssistantMessageParam;\r\n  export import ChatCompletionChunk = ChatCompletionsAPI.ChatCompletionChunk;\r\n  export import ChatCompletionContentPart = ChatCompletionsAPI.ChatCompletionContentPart;\r\n  export import ChatCompletionContentPartImage = ChatCompletionsAPI.ChatCompletionContentPartImage;\r\n  export import ChatCompletionContentPartText = ChatCompletionsAPI.ChatCompletionContentPartText;\r\n  export import ChatCompletionFunctionCallOption = ChatCompletionsAPI.ChatCompletionFunctionCallOption;\r\n  export import ChatCompletionFunctionMessageParam = ChatCompletionsAPI.ChatCompletionFunctionMessageParam;\r\n  export import ChatCompletionMessage = ChatCompletionsAPI.ChatCompletionMessage;\r\n  export import ChatCompletionMessageParam = ChatCompletionsAPI.ChatCompletionMessageParam;\r\n  export import ChatCompletionMessageToolCall = ChatCompletionsAPI.ChatCompletionMessageToolCall;\r\n  export import ChatCompletionNamedToolChoice = ChatCompletionsAPI.ChatCompletionNamedToolChoice;\r\n  export import ChatCompletionRole = ChatCompletionsAPI.ChatCompletionRole;\r\n  export import ChatCompletionSystemMessageParam = ChatCompletionsAPI.ChatCompletionSystemMessageParam;\r\n  export import ChatCompletionTokenLogprob = ChatCompletionsAPI.ChatCompletionTokenLogprob;\r\n  export import ChatCompletionTool = ChatCompletionsAPI.ChatCompletionTool;\r\n  export import ChatCompletionToolChoiceOption = ChatCompletionsAPI.ChatCompletionToolChoiceOption;\r\n  export import ChatCompletionToolMessageParam = ChatCompletionsAPI.ChatCompletionToolMessageParam;\r\n  export import ChatCompletionUserMessageParam = ChatCompletionsAPI.ChatCompletionUserMessageParam;\r\n  /**\r\n   * @deprecated ChatCompletionMessageParam should be used instead\r\n   */\r\n  export import CreateChatCompletionRequestMessage = ChatCompletionsAPI.CreateChatCompletionRequestMessage;\r\n  export import ChatCompletionCreateParams = ChatCompletionsAPI.ChatCompletionCreateParams;\r\n  export import CompletionCreateParams = ChatCompletionsAPI.CompletionCreateParams;\r\n  export import ChatCompletionCreateParamsNonStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\r\n  export import CompletionCreateParamsNonStreaming = ChatCompletionsAPI.CompletionCreateParamsNonStreaming;\r\n  export import ChatCompletionCreateParamsStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsStreaming;\r\n  export import CompletionCreateParamsStreaming = ChatCompletionsAPI.CompletionCreateParamsStreaming;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport { APIResource } from \"../../resource\";\r\nimport * as CompletionsAPI from \"./completions\";\r\n\r\nexport class Chat extends APIResource {\r\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\r\n}\r\n\r\nexport namespace Chat {\r\n  export import Completions = CompletionsAPI.Completions;\r\n  export import ChatCompletion = CompletionsAPI.ChatCompletion;\r\n  export import ChatCompletionAssistantMessageParam = CompletionsAPI.ChatCompletionAssistantMessageParam;\r\n  export import ChatCompletionChunk = CompletionsAPI.ChatCompletionChunk;\r\n  export import ChatCompletionContentPart = CompletionsAPI.ChatCompletionContentPart;\r\n  export import ChatCompletionContentPartImage = CompletionsAPI.ChatCompletionContentPartImage;\r\n  export import ChatCompletionContentPartText = CompletionsAPI.ChatCompletionContentPartText;\r\n  export import ChatCompletionFunctionCallOption = CompletionsAPI.ChatCompletionFunctionCallOption;\r\n  export import ChatCompletionFunctionMessageParam = CompletionsAPI.ChatCompletionFunctionMessageParam;\r\n  export import ChatCompletionMessage = CompletionsAPI.ChatCompletionMessage;\r\n  export import ChatCompletionMessageParam = CompletionsAPI.ChatCompletionMessageParam;\r\n  export import ChatCompletionMessageToolCall = CompletionsAPI.ChatCompletionMessageToolCall;\r\n  export import ChatCompletionNamedToolChoice = CompletionsAPI.ChatCompletionNamedToolChoice;\r\n  export import ChatCompletionRole = CompletionsAPI.ChatCompletionRole;\r\n  export import ChatCompletionSystemMessageParam = CompletionsAPI.ChatCompletionSystemMessageParam;\r\n  export import ChatCompletionTokenLogprob = CompletionsAPI.ChatCompletionTokenLogprob;\r\n  export import ChatCompletionTool = CompletionsAPI.ChatCompletionTool;\r\n  export import ChatCompletionToolChoiceOption = CompletionsAPI.ChatCompletionToolChoiceOption;\r\n  export import ChatCompletionToolMessageParam = CompletionsAPI.ChatCompletionToolMessageParam;\r\n  export import ChatCompletionUserMessageParam = CompletionsAPI.ChatCompletionUserMessageParam;\r\n  /**\r\n   * @deprecated ChatCompletionMessageParam should be used instead\r\n   */\r\n  export import CreateChatCompletionRequestMessage = CompletionsAPI.CreateChatCompletionRequestMessage;\r\n  export import ChatCompletionCreateParams = CompletionsAPI.ChatCompletionCreateParams;\r\n  export import CompletionCreateParams = CompletionsAPI.CompletionCreateParams;\r\n  export import ChatCompletionCreateParamsNonStreaming = CompletionsAPI.ChatCompletionCreateParamsNonStreaming;\r\n  export import CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\r\n  export import ChatCompletionCreateParamsStreaming = CompletionsAPI.ChatCompletionCreateParamsStreaming;\r\n  export import CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../core\";\r\nimport { APIResource } from \"../../resource\";\r\nimport { type Response } from \"../../_shims/index\";\r\nimport * as SpeechAPI from \"./speech\";\r\n\r\nexport class Speech extends APIResource {\r\n  /**\r\n   * Generates audio from the input text.\r\n   */\r\n  create(body: SpeechCreateParams, options?: Core.RequestOptions): Core.APIPromise<Response> {\r\n    return this._client.post('/audio/speech', { body, ...options, __binaryResponse: true });\r\n  }\r\n}\r\n\r\nexport interface SpeechCreateParams {\r\n  /**\r\n   * The text to generate audio for. The maximum length is 4096 characters.\r\n   */\r\n  input: string;\r\n\r\n  /**\r\n   * One of the available [TTS models](https://platform.openai.com/docs/models/tts):\r\n   * `tts-1` or `tts-1-hd`\r\n   */\r\n  model: (string & {}) | 'tts-1' | 'tts-1-hd';\r\n\r\n  /**\r\n   * The voice to use when generating the audio. Supported voices are `alloy`,\r\n   * `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are\r\n   * available in the\r\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech/voice-options).\r\n   */\r\n  voice: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';\r\n\r\n  /**\r\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, and `flac`.\r\n   */\r\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac';\r\n\r\n  /**\r\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\r\n   * the default.\r\n   */\r\n  speed?: number;\r\n}\r\n\r\nexport namespace Speech {\r\n  export import SpeechCreateParams = SpeechAPI.SpeechCreateParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../core\";\r\nimport { APIResource } from \"../../resource\";\r\nimport * as TranscriptionsAPI from \"./transcriptions\";\r\nimport { type Uploadable, multipartFormRequestOptions } from \"../../core\";\r\n\r\nexport class Transcriptions extends APIResource {\r\n  /**\r\n   * Transcribes audio into the input language.\r\n   */\r\n  create(body: TranscriptionCreateParams, options?: Core.RequestOptions): Core.APIPromise<Transcription> {\r\n    return this._client.post('/audio/transcriptions', multipartFormRequestOptions({ body, ...options }));\r\n  }\r\n}\r\n\r\nexport interface Transcription {\r\n  text: string;\r\n}\r\n\r\nexport interface TranscriptionCreateParams {\r\n  /**\r\n   * The audio file object (not file name) to transcribe, in one of these formats:\r\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\r\n   */\r\n  file: Uploadable;\r\n\r\n  /**\r\n   * ID of the model to use. Only `whisper-1` is currently available.\r\n   */\r\n  model: (string & {}) | 'whisper-1';\r\n\r\n  /**\r\n   * The language of the input audio. Supplying the input language in\r\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will\r\n   * improve accuracy and latency.\r\n   */\r\n  language?: string;\r\n\r\n  /**\r\n   * An optional text to guide the model's style or continue a previous audio\r\n   * segment. The\r\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting)\r\n   * should match the audio language.\r\n   */\r\n  prompt?: string;\r\n\r\n  /**\r\n   * The format of the transcript output, in one of these options: `json`, `text`,\r\n   * `srt`, `verbose_json`, or `vtt`.\r\n   */\r\n  response_format?: 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\r\n\r\n  /**\r\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\r\n   * output more random, while lower values like 0.2 will make it more focused and\r\n   * deterministic. If set to 0, the model will use\r\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\r\n   * automatically increase the temperature until certain thresholds are hit.\r\n   */\r\n  temperature?: number;\r\n\r\n  /**\r\n   * The timestamp granularities to populate for this transcription. Any of these\r\n   * options: `word`, or `segment`. Note: There is no additional latency for segment\r\n   * timestamps, but generating word timestamps incurs additional latency.\r\n   */\r\n  timestamp_granularities?: Array<'word' | 'segment'>;\r\n}\r\n\r\nexport namespace Transcriptions {\r\n  export import Transcription = TranscriptionsAPI.Transcription;\r\n  export import TranscriptionCreateParams = TranscriptionsAPI.TranscriptionCreateParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../core\";\r\nimport { APIResource } from \"../../resource\";\r\nimport * as TranslationsAPI from \"./translations\";\r\nimport { type Uploadable, multipartFormRequestOptions } from \"../../core\";\r\n\r\nexport class Translations extends APIResource {\r\n  /**\r\n   * Translates audio into English.\r\n   */\r\n  create(body: TranslationCreateParams, options?: Core.RequestOptions): Core.APIPromise<Translation> {\r\n    return this._client.post('/audio/translations', multipartFormRequestOptions({ body, ...options }));\r\n  }\r\n}\r\n\r\nexport interface Translation {\r\n  text: string;\r\n}\r\n\r\nexport interface TranslationCreateParams {\r\n  /**\r\n   * The audio file object (not file name) translate, in one of these formats: flac,\r\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\r\n   */\r\n  file: Uploadable;\r\n\r\n  /**\r\n   * ID of the model to use. Only `whisper-1` is currently available.\r\n   */\r\n  model: (string & {}) | 'whisper-1';\r\n\r\n  /**\r\n   * An optional text to guide the model's style or continue a previous audio\r\n   * segment. The\r\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting)\r\n   * should be in English.\r\n   */\r\n  prompt?: string;\r\n\r\n  /**\r\n   * The format of the transcript output, in one of these options: `json`, `text`,\r\n   * `srt`, `verbose_json`, or `vtt`.\r\n   */\r\n  response_format?: string;\r\n\r\n  /**\r\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\r\n   * output more random, while lower values like 0.2 will make it more focused and\r\n   * deterministic. If set to 0, the model will use\r\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\r\n   * automatically increase the temperature until certain thresholds are hit.\r\n   */\r\n  temperature?: number;\r\n}\r\n\r\nexport namespace Translations {\r\n  export import Translation = TranslationsAPI.Translation;\r\n  export import TranslationCreateParams = TranslationsAPI.TranslationCreateParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport { APIResource } from \"../../resource\";\r\nimport * as SpeechAPI from \"./speech\";\r\nimport * as TranscriptionsAPI from \"./transcriptions\";\r\nimport * as TranslationsAPI from \"./translations\";\r\n\r\nexport class Audio extends APIResource {\r\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\r\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\r\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\r\n}\r\n\r\nexport namespace Audio {\r\n  export import Transcriptions = TranscriptionsAPI.Transcriptions;\r\n  export import Transcription = TranscriptionsAPI.Transcription;\r\n  export import TranscriptionCreateParams = TranscriptionsAPI.TranscriptionCreateParams;\r\n  export import Translations = TranslationsAPI.Translations;\r\n  export import Translation = TranslationsAPI.Translation;\r\n  export import TranslationCreateParams = TranslationsAPI.TranslationCreateParams;\r\n  export import Speech = SpeechAPI.Speech;\r\n  export import SpeechCreateParams = SpeechAPI.SpeechCreateParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../core\";\r\nimport { APIResource } from \"../../../resource\";\r\nimport { isRequestOptions } from \"../../../core\";\r\nimport * as FilesAPI from \"./files\";\r\nimport { CursorPage, type CursorPageParams } from \"../../../pagination\";\r\n\r\nexport class Files extends APIResource {\r\n  /**\r\n   * Create an assistant file by attaching a\r\n   * [File](https://platform.openai.com/docs/api-reference/files) to an\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants).\r\n   */\r\n  create(\r\n    assistantId: string,\r\n    body: FileCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<AssistantFile> {\r\n    return this._client.post(`/assistants/${assistantId}/files`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Retrieves an AssistantFile.\r\n   */\r\n  retrieve(\r\n    assistantId: string,\r\n    fileId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<AssistantFile> {\r\n    return this._client.get(`/assistants/${assistantId}/files/${fileId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Returns a list of assistant files.\r\n   */\r\n  list(\r\n    assistantId: string,\r\n    query?: FileListParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<AssistantFilesPage, AssistantFile>;\r\n  list(\r\n    assistantId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<AssistantFilesPage, AssistantFile>;\r\n  list(\r\n    assistantId: string,\r\n    query: FileListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<AssistantFilesPage, AssistantFile> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list(assistantId, {}, query);\r\n    }\r\n    return this._client.getAPIList(`/assistants/${assistantId}/files`, AssistantFilesPage, {\r\n      query,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Delete an assistant file.\r\n   */\r\n  del(\r\n    assistantId: string,\r\n    fileId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<FileDeleteResponse> {\r\n    return this._client.delete(`/assistants/${assistantId}/files/${fileId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n}\r\n\r\nexport class AssistantFilesPage extends CursorPage<AssistantFile> {}\r\n\r\n/**\r\n * A list of [Files](https://platform.openai.com/docs/api-reference/files) attached\r\n * to an `assistant`.\r\n */\r\nexport interface AssistantFile {\r\n  /**\r\n   * The identifier, which can be referenced in API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The assistant ID that the file is attached to.\r\n   */\r\n  assistant_id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the assistant file was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * The object type, which is always `assistant.file`.\r\n   */\r\n  object: 'assistant.file';\r\n}\r\n\r\n/**\r\n * Deletes the association between the assistant and the file, but does not delete\r\n * the [File](https://platform.openai.com/docs/api-reference/files) object itself.\r\n */\r\nexport interface FileDeleteResponse {\r\n  id: string;\r\n\r\n  deleted: boolean;\r\n\r\n  object: 'assistant.file.deleted';\r\n}\r\n\r\nexport interface FileCreateParams {\r\n  /**\r\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID (with\r\n   * `purpose=\"assistants\"`) that the assistant should use. Useful for tools like\r\n   * `retrieval` and `code_interpreter` that can access files.\r\n   */\r\n  file_id: string;\r\n}\r\n\r\nexport interface FileListParams extends CursorPageParams {\r\n  /**\r\n   * A cursor for use in pagination. `before` is an object ID that defines your place\r\n   * in the list. For instance, if you make a list request and receive 100 objects,\r\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\r\n   * fetch the previous page of the list.\r\n   */\r\n  before?: string;\r\n\r\n  /**\r\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\r\n   * order and `desc` for descending order.\r\n   */\r\n  order?: 'asc' | 'desc';\r\n}\r\n\r\nexport namespace Files {\r\n  export import AssistantFile = FilesAPI.AssistantFile;\r\n  export import FileDeleteResponse = FilesAPI.FileDeleteResponse;\r\n  export import AssistantFilesPage = FilesAPI.AssistantFilesPage;\r\n  export import FileCreateParams = FilesAPI.FileCreateParams;\r\n  export import FileListParams = FilesAPI.FileListParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../core\";\r\nimport { APIResource } from \"../../../resource\";\r\nimport { isRequestOptions } from \"../../../core\";\r\nimport * as AssistantsAPI from \"./assistants\";\r\nimport * as Shared from \"../../shared\";\r\nimport * as FilesAPI from \"./files\";\r\nimport { CursorPage, type CursorPageParams } from \"../../../pagination\";\r\n\r\nexport class Assistants extends APIResource {\r\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\r\n\r\n  /**\r\n   * Create an assistant with a model and instructions.\r\n   */\r\n  create(body: AssistantCreateParams, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\r\n    return this._client.post('/assistants', {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Retrieves an assistant.\r\n   */\r\n  retrieve(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\r\n    return this._client.get(`/assistants/${assistantId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Modifies an assistant.\r\n   */\r\n  update(\r\n    assistantId: string,\r\n    body: AssistantUpdateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<Assistant> {\r\n    return this._client.post(`/assistants/${assistantId}`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Returns a list of assistants.\r\n   */\r\n  list(\r\n    query?: AssistantListParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<AssistantsPage, Assistant>;\r\n  list(options?: Core.RequestOptions): Core.PagePromise<AssistantsPage, Assistant>;\r\n  list(\r\n    query: AssistantListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<AssistantsPage, Assistant> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list({}, query);\r\n    }\r\n    return this._client.getAPIList('/assistants', AssistantsPage, {\r\n      query,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Delete an assistant.\r\n   */\r\n  del(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<AssistantDeleted> {\r\n    return this._client.delete(`/assistants/${assistantId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n}\r\n\r\nexport class AssistantsPage extends CursorPage<Assistant> {}\r\n\r\n/**\r\n * Represents an `assistant` that can call the model and use tools.\r\n */\r\nexport interface Assistant {\r\n  /**\r\n   * The identifier, which can be referenced in API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the assistant was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * The description of the assistant. The maximum length is 512 characters.\r\n   */\r\n  description: string | null;\r\n\r\n  /**\r\n   * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs\r\n   * attached to this assistant. There can be a maximum of 20 files attached to the\r\n   * assistant. Files are ordered by their creation date in ascending order.\r\n   */\r\n  file_ids: Array<string>;\r\n\r\n  /**\r\n   * The system instructions that the assistant uses. The maximum length is 32768\r\n   * characters.\r\n   */\r\n  instructions: string | null;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata: unknown | null;\r\n\r\n  /**\r\n   * ID of the model to use. You can use the\r\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\r\n   * see all of your available models, or see our\r\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\r\n   * descriptions of them.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The name of the assistant. The maximum length is 256 characters.\r\n   */\r\n  name: string | null;\r\n\r\n  /**\r\n   * The object type, which is always `assistant`.\r\n   */\r\n  object: 'assistant';\r\n\r\n  /**\r\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\r\n   * assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.\r\n   */\r\n  tools: Array<Assistant.CodeInterpreter | Assistant.Retrieval | Assistant.Function>;\r\n}\r\n\r\nexport namespace Assistant {\r\n  export interface CodeInterpreter {\r\n    /**\r\n     * The type of tool being defined: `code_interpreter`\r\n     */\r\n    type: 'code_interpreter';\r\n  }\r\n\r\n  export interface Retrieval {\r\n    /**\r\n     * The type of tool being defined: `retrieval`\r\n     */\r\n    type: 'retrieval';\r\n  }\r\n\r\n  export interface Function {\r\n    function: Shared.FunctionDefinition;\r\n\r\n    /**\r\n     * The type of tool being defined: `function`\r\n     */\r\n    type: 'function';\r\n  }\r\n}\r\n\r\nexport interface AssistantDeleted {\r\n  id: string;\r\n\r\n  deleted: boolean;\r\n\r\n  object: 'assistant.deleted';\r\n}\r\n\r\nexport interface AssistantCreateParams {\r\n  /**\r\n   * ID of the model to use. You can use the\r\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\r\n   * see all of your available models, or see our\r\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\r\n   * descriptions of them.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The description of the assistant. The maximum length is 512 characters.\r\n   */\r\n  description?: string | null;\r\n\r\n  /**\r\n   * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs\r\n   * attached to this assistant. There can be a maximum of 20 files attached to the\r\n   * assistant. Files are ordered by their creation date in ascending order.\r\n   */\r\n  file_ids?: Array<string>;\r\n\r\n  /**\r\n   * The system instructions that the assistant uses. The maximum length is 32768\r\n   * characters.\r\n   */\r\n  instructions?: string | null;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n\r\n  /**\r\n   * The name of the assistant. The maximum length is 256 characters.\r\n   */\r\n  name?: string | null;\r\n\r\n  /**\r\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\r\n   * assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.\r\n   */\r\n  tools?: Array<\r\n    | AssistantCreateParams.AssistantToolsCode\r\n    | AssistantCreateParams.AssistantToolsRetrieval\r\n    | AssistantCreateParams.AssistantToolsFunction\r\n  >;\r\n}\r\n\r\nexport namespace AssistantCreateParams {\r\n  export interface AssistantToolsCode {\r\n    /**\r\n     * The type of tool being defined: `code_interpreter`\r\n     */\r\n    type: 'code_interpreter';\r\n  }\r\n\r\n  export interface AssistantToolsRetrieval {\r\n    /**\r\n     * The type of tool being defined: `retrieval`\r\n     */\r\n    type: 'retrieval';\r\n  }\r\n\r\n  export interface AssistantToolsFunction {\r\n    function: Shared.FunctionDefinition;\r\n\r\n    /**\r\n     * The type of tool being defined: `function`\r\n     */\r\n    type: 'function';\r\n  }\r\n}\r\n\r\nexport interface AssistantUpdateParams {\r\n  /**\r\n   * The description of the assistant. The maximum length is 512 characters.\r\n   */\r\n  description?: string | null;\r\n\r\n  /**\r\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs\r\n   * attached to this assistant. There can be a maximum of 20 files attached to the\r\n   * assistant. Files are ordered by their creation date in ascending order. If a\r\n   * file was previously attached to the list but does not show up in the list, it\r\n   * will be deleted from the assistant.\r\n   */\r\n  file_ids?: Array<string>;\r\n\r\n  /**\r\n   * The system instructions that the assistant uses. The maximum length is 32768\r\n   * characters.\r\n   */\r\n  instructions?: string | null;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n\r\n  /**\r\n   * ID of the model to use. You can use the\r\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\r\n   * see all of your available models, or see our\r\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\r\n   * descriptions of them.\r\n   */\r\n  model?: string;\r\n\r\n  /**\r\n   * The name of the assistant. The maximum length is 256 characters.\r\n   */\r\n  name?: string | null;\r\n\r\n  /**\r\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\r\n   * assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.\r\n   */\r\n  tools?: Array<\r\n    | AssistantUpdateParams.AssistantToolsCode\r\n    | AssistantUpdateParams.AssistantToolsRetrieval\r\n    | AssistantUpdateParams.AssistantToolsFunction\r\n  >;\r\n}\r\n\r\nexport namespace AssistantUpdateParams {\r\n  export interface AssistantToolsCode {\r\n    /**\r\n     * The type of tool being defined: `code_interpreter`\r\n     */\r\n    type: 'code_interpreter';\r\n  }\r\n\r\n  export interface AssistantToolsRetrieval {\r\n    /**\r\n     * The type of tool being defined: `retrieval`\r\n     */\r\n    type: 'retrieval';\r\n  }\r\n\r\n  export interface AssistantToolsFunction {\r\n    function: Shared.FunctionDefinition;\r\n\r\n    /**\r\n     * The type of tool being defined: `function`\r\n     */\r\n    type: 'function';\r\n  }\r\n}\r\n\r\nexport interface AssistantListParams extends CursorPageParams {\r\n  /**\r\n   * A cursor for use in pagination. `before` is an object ID that defines your place\r\n   * in the list. For instance, if you make a list request and receive 100 objects,\r\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\r\n   * fetch the previous page of the list.\r\n   */\r\n  before?: string;\r\n\r\n  /**\r\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\r\n   * order and `desc` for descending order.\r\n   */\r\n  order?: 'asc' | 'desc';\r\n}\r\n\r\nexport namespace Assistants {\r\n  export import Assistant = AssistantsAPI.Assistant;\r\n  export import AssistantDeleted = AssistantsAPI.AssistantDeleted;\r\n  export import AssistantsPage = AssistantsAPI.AssistantsPage;\r\n  export import AssistantCreateParams = AssistantsAPI.AssistantCreateParams;\r\n  export import AssistantUpdateParams = AssistantsAPI.AssistantUpdateParams;\r\n  export import AssistantListParams = AssistantsAPI.AssistantListParams;\r\n  export import Files = FilesAPI.Files;\r\n  export import AssistantFile = FilesAPI.AssistantFile;\r\n  export import FileDeleteResponse = FilesAPI.FileDeleteResponse;\r\n  export import AssistantFilesPage = FilesAPI.AssistantFilesPage;\r\n  export import FileCreateParams = FilesAPI.FileCreateParams;\r\n  export import FileListParams = FilesAPI.FileListParams;\r\n}\r\n", "import { type ChatCompletionRunner } from './ChatCompletionRunner';\r\nimport { type ChatCompletionStreamingRunner } from './ChatCompletionStreamingRunner';\r\nimport { JSONSchema } from './jsonschema';\r\n\r\ntype PromiseOrValue<T> = T | Promise<T>;\r\n\r\nexport type RunnableFunctionWithParse<Args extends object> = {\r\n  /**\r\n   * @param args the return value from `parse`.\r\n   * @param runner the runner evaluating this callback.\r\n   * @returns a string to send back to OpenAI.\r\n   */\r\n  function: (\r\n    args: Args,\r\n    runner: ChatCompletionRunner | ChatCompletionStreamingRunner,\r\n  ) => PromiseOrValue<unknown>;\r\n  /**\r\n   * @param input the raw args from the OpenAI function call.\r\n   * @returns the parsed arguments to pass to `function`\r\n   */\r\n  parse: (input: string) => PromiseOrValue<Args>;\r\n  /**\r\n   * The parameters the function accepts, describes as a JSON Schema object.\r\n   */\r\n  parameters: JSONSchema;\r\n  /**\r\n   * A description of what the function does, used by the model to choose when and how to call the function.\r\n   */\r\n  description: string;\r\n  /**\r\n   * The name of the function to be called. Will default to function.name if omitted.\r\n   */\r\n  name?: string | undefined;\r\n};\r\n\r\nexport type RunnableFunctionWithoutParse = {\r\n  /**\r\n   * @param args the raw args from the OpenAI function call.\r\n   * @returns a string to send back to OpenAI\r\n   */\r\n  function: (\r\n    args: string,\r\n    runner: ChatCompletionRunner | ChatCompletionStreamingRunner,\r\n  ) => PromiseOrValue<unknown>;\r\n  /**\r\n   * The parameters the function accepts, describes as a JSON Schema object.\r\n   */\r\n  parameters: JSONSchema;\r\n  /**\r\n   * A description of what the function does, used by the model to choose when and how to call the function.\r\n   */\r\n  description: string;\r\n  /**\r\n   * The name of the function to be called. Will default to function.name if omitted.\r\n   */\r\n  name?: string | undefined;\r\n};\r\n\r\nexport type RunnableFunction<Args extends object | string> =\r\n  Args extends string ? RunnableFunctionWithoutParse\r\n  : Args extends object ? RunnableFunctionWithParse<Args>\r\n  : never;\r\n\r\nexport type RunnableToolFunction<Args extends object | string> =\r\n  Args extends string ? RunnableToolFunctionWithoutParse\r\n  : Args extends object ? RunnableToolFunctionWithParse<Args>\r\n  : never;\r\n\r\nexport type RunnableToolFunctionWithoutParse = {\r\n  type: 'function';\r\n  function: RunnableFunctionWithoutParse;\r\n};\r\nexport type RunnableToolFunctionWithParse<Args extends object> = {\r\n  type: 'function';\r\n  function: RunnableFunctionWithParse<Args>;\r\n};\r\n\r\nexport function isRunnableFunctionWithParse<Args extends object>(\r\n  fn: any,\r\n): fn is RunnableFunctionWithParse<Args> {\r\n  return typeof (fn as any).parse === 'function';\r\n}\r\n\r\nexport type BaseFunctionsArgs = readonly (object | string)[];\r\n\r\nexport type RunnableFunctions<FunctionsArgs extends BaseFunctionsArgs> =\r\n  [any[]] extends [FunctionsArgs] ? readonly RunnableFunction<any>[]\r\n  : {\r\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableFunction<FunctionsArgs[Index]>\r\n      : FunctionsArgs[Index];\r\n    };\r\n\r\nexport type RunnableTools<FunctionsArgs extends BaseFunctionsArgs> =\r\n  [any[]] extends [FunctionsArgs] ? readonly RunnableToolFunction<any>[]\r\n  : {\r\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableToolFunction<FunctionsArgs[Index]>\r\n      : FunctionsArgs[Index];\r\n    };\r\n\r\n/**\r\n * This is helper class for passing a `function` and `parse` where the `function`\r\n * argument type matches the `parse` return type.\r\n *\r\n * @deprecated - please use ParsingToolFunction instead.\r\n */\r\nexport class ParsingFunction<Args extends object> {\r\n  function: RunnableFunctionWithParse<Args>['function'];\r\n  parse: RunnableFunctionWithParse<Args>['parse'];\r\n  parameters: RunnableFunctionWithParse<Args>['parameters'];\r\n  description: RunnableFunctionWithParse<Args>['description'];\r\n  name?: RunnableFunctionWithParse<Args>['name'];\r\n\r\n  constructor(input: RunnableFunctionWithParse<Args>) {\r\n    this.function = input.function;\r\n    this.parse = input.parse;\r\n    this.parameters = input.parameters;\r\n    this.description = input.description;\r\n    this.name = input.name;\r\n  }\r\n}\r\n\r\n/**\r\n * This is helper class for passing a `function` and `parse` where the `function`\r\n * argument type matches the `parse` return type.\r\n */\r\nexport class ParsingToolFunction<Args extends object> {\r\n  type: 'function';\r\n  function: RunnableFunctionWithParse<Args>;\r\n\r\n  constructor(input: RunnableFunctionWithParse<Args>) {\r\n    this.type = 'function';\r\n    this.function = input;\r\n  }\r\n}\r\n", "import {\r\n  type ChatCompletionAssistantMessageParam,\r\n  type ChatCompletionFunctionMessageParam,\r\n  type ChatCompletionMessageParam,\r\n  type ChatCompletionToolMessageParam,\r\n} from \"../resources\";\r\n\r\nexport const isAssistantMessage = (\r\n  message: ChatCompletionMessageParam | null | undefined,\r\n): message is ChatCompletionAssistantMessageParam => {\r\n  return message?.role === 'assistant';\r\n};\r\n\r\nexport const isFunctionMessage = (\r\n  message: ChatCompletionMessageParam | null | undefined,\r\n): message is ChatCompletionFunctionMessageParam => {\r\n  return message?.role === 'function';\r\n};\r\n\r\nexport const isToolMessage = (\r\n  message: ChatCompletionMessageParam | null | undefined,\r\n): message is ChatCompletionToolMessageParam => {\r\n  return message?.role === 'tool';\r\n};\r\n\r\nexport function isPresent<T>(obj: T | null | undefined): obj is T {\r\n  return obj != null;\r\n}\r\n", "import * as Core from \"../core\";\r\nimport { type CompletionUsage } from \"../resources/completions\";\r\nimport {\r\n  type Completions,\r\n  type ChatCompletion,\r\n  type ChatCompletionMessage,\r\n  type ChatCompletionMessageParam,\r\n  type ChatCompletionCreateParams,\r\n  type ChatCompletionTool,\r\n} from \"../resources/chat/completions\";\r\nimport { APIUserAbortError, OpenAIError } from \"../error\";\r\nimport {\r\n  type RunnableFunction,\r\n  isRunnableFunctionWithParse,\r\n  type BaseFunctionsArgs,\r\n} from './RunnableFunction';\r\nimport { ChatCompletionFunctionRunnerParams, ChatCompletionToolRunnerParams } from './ChatCompletionRunner';\r\nimport {\r\n  ChatCompletionStreamingFunctionRunnerParams,\r\n  ChatCompletionStreamingToolRunnerParams,\r\n} from './ChatCompletionStreamingRunner';\r\nimport { isAssistantMessage, isFunctionMessage, isToolMessage } from './chatCompletionUtils';\r\n\r\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\r\nexport interface RunnerOptions extends Core.RequestOptions {\r\n  /** How many requests to make before canceling. Default 10. */\r\n  maxChatCompletions?: number;\r\n}\r\n\r\nexport abstract class AbstractChatCompletionRunner<\r\n  Events extends CustomEvents<any> = AbstractChatCompletionRunnerEvents,\r\n> {\r\n  controller: AbortController = new AbortController();\r\n\r\n  #connectedPromise: Promise<void>;\r\n  #resolveConnectedPromise: () => void = () => {};\r\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\r\n\r\n  #endPromise: Promise<void>;\r\n  #resolveEndPromise: () => void = () => {};\r\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\r\n\r\n  #listeners: { [Event in keyof Events]?: ListenersForEvent<Events, Event> } = {};\r\n\r\n  protected _chatCompletions: ChatCompletion[] = [];\r\n  messages: ChatCompletionMessageParam[] = [];\r\n\r\n  #ended = false;\r\n  #errored = false;\r\n  #aborted = false;\r\n  #catchingPromiseCreated = false;\r\n\r\n  constructor() {\r\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\r\n      this.#resolveConnectedPromise = resolve;\r\n      this.#rejectConnectedPromise = reject;\r\n    });\r\n\r\n    this.#endPromise = new Promise<void>((resolve, reject) => {\r\n      this.#resolveEndPromise = resolve;\r\n      this.#rejectEndPromise = reject;\r\n    });\r\n\r\n    // Don't let these promises cause unhandled rejection errors.\r\n    // we will manually cause an unhandled rejection error later\r\n    // if the user hasn't registered any error listener or called\r\n    // any promise-returning method.\r\n    this.#connectedPromise.catch(() => {});\r\n    this.#endPromise.catch(() => {});\r\n  }\r\n\r\n  protected _run(executor: () => Promise<any>) {\r\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\r\n    // references to `this` before the `super()` constructor call returns.\r\n    setTimeout(() => {\r\n      executor().then(() => {\r\n        this._emitFinal();\r\n        this._emit('end');\r\n      }, this.#handleError);\r\n    }, 0);\r\n  }\r\n\r\n  protected _addChatCompletion(chatCompletion: ChatCompletion): ChatCompletion {\r\n    this._chatCompletions.push(chatCompletion);\r\n    this._emit('chatCompletion', chatCompletion);\r\n    const message = chatCompletion.choices[0]?.message;\r\n    if (message) this._addMessage(message as ChatCompletionMessageParam);\r\n    return chatCompletion;\r\n  }\r\n\r\n  protected _addMessage(message: ChatCompletionMessageParam, emit = true) {\r\n    if (!('content' in message)) message.content = null;\r\n\r\n    this.messages.push(message);\r\n\r\n    if (emit) {\r\n      this._emit('message', message);\r\n      if ((isFunctionMessage(message) || isToolMessage(message)) && message.content) {\r\n        // Note, this assumes that {role: 'tool', content: â€¦} is always the result of a call of tool of type=function.\r\n        this._emit('functionCallResult', message.content as string);\r\n      } else if (isAssistantMessage(message) && message.function_call) {\r\n        this._emit('functionCall', message.function_call);\r\n      } else if (isAssistantMessage(message) && message.tool_calls) {\r\n        for (const tool_call of message.tool_calls) {\r\n          if (tool_call.type === 'function') {\r\n            this._emit('functionCall', tool_call.function);\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  protected _connected() {\r\n    if (this.ended) return;\r\n    this.#resolveConnectedPromise();\r\n    this._emit('connect');\r\n  }\r\n\r\n  get ended(): boolean {\r\n    return this.#ended;\r\n  }\r\n\r\n  get errored(): boolean {\r\n    return this.#errored;\r\n  }\r\n\r\n  get aborted(): boolean {\r\n    return this.#aborted;\r\n  }\r\n\r\n  abort() {\r\n    this.controller.abort();\r\n  }\r\n\r\n  /**\r\n   * Adds the listener function to the end of the listeners array for the event.\r\n   * No checks are made to see if the listener has already been added. Multiple calls passing\r\n   * the same combination of event and listener will result in the listener being added, and\r\n   * called, multiple times.\r\n   * @returns this ChatCompletionStream, so that calls can be chained\r\n   */\r\n  on<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\r\n    const listeners: ListenersForEvent<Events, Event> =\r\n      this.#listeners[event] || (this.#listeners[event] = []);\r\n    listeners.push({ listener });\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Removes the specified listener from the listener array for the event.\r\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\r\n   * listener has been added multiple times to the listener array for the specified event, then\r\n   * off() must be called multiple times to remove each instance.\r\n   * @returns this ChatCompletionStream, so that calls can be chained\r\n   */\r\n  off<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\r\n    const listeners = this.#listeners[event];\r\n    if (!listeners) return this;\r\n    const index = listeners.findIndex((l) => l.listener === listener);\r\n    if (index >= 0) listeners.splice(index, 1);\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * Adds a one-time listener function for the event. The next time the event is triggered,\r\n   * this listener is removed and then invoked.\r\n   * @returns this ChatCompletionStream, so that calls can be chained\r\n   */\r\n  once<Event extends keyof Events>(event: Event, listener: ListenerForEvent<Events, Event>): this {\r\n    const listeners: ListenersForEvent<Events, Event> =\r\n      this.#listeners[event] || (this.#listeners[event] = []);\r\n    listeners.push({ listener, once: true });\r\n    return this;\r\n  }\r\n\r\n  /**\r\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\r\n   * the event is triggered, instead of calling a listener callback.\r\n   * @returns a Promise that resolves the next time given event is triggered,\r\n   * or rejects if an error is emitted.  (If you request the 'error' event,\r\n   * returns a promise that resolves with the error).\r\n   *\r\n   * Example:\r\n   *\r\n   *   const message = await stream.emitted('message') // rejects if the stream errors\r\n   */\r\n  emitted<Event extends keyof Events>(\r\n    event: Event,\r\n  ): Promise<\r\n    EventParameters<Events, Event> extends [infer Param] ? Param\r\n    : EventParameters<Events, Event> extends [] ? void\r\n    : EventParameters<Events, Event>\r\n  > {\r\n    return new Promise((resolve, reject) => {\r\n      this.#catchingPromiseCreated = true;\r\n      if (event !== 'error') this.once('error', reject);\r\n      this.once(event, resolve as any);\r\n    });\r\n  }\r\n\r\n  async done(): Promise<void> {\r\n    this.#catchingPromiseCreated = true;\r\n    await this.#endPromise;\r\n  }\r\n\r\n  /**\r\n   * @returns a promise that resolves with the final ChatCompletion, or rejects\r\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\r\n   */\r\n  async finalChatCompletion(): Promise<ChatCompletion> {\r\n    await this.done();\r\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\r\n    if (!completion) throw new OpenAIError('stream ended without producing a ChatCompletion');\r\n    return completion;\r\n  }\r\n\r\n  #getFinalContent(): string | null {\r\n    return this.#getFinalMessage().content ?? null;\r\n  }\r\n\r\n  /**\r\n   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\r\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\r\n   */\r\n  async finalContent(): Promise<string | null> {\r\n    await this.done();\r\n    return this.#getFinalContent();\r\n  }\r\n\r\n  #getFinalMessage(): ChatCompletionMessage {\r\n    let i = this.messages.length;\r\n    while (i-- > 0) {\r\n      const message = this.messages[i];\r\n      if (isAssistantMessage(message)) {\r\n        return { ...message, content: message.content ?? null };\r\n      }\r\n    }\r\n    throw new OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\r\n  }\r\n\r\n  /**\r\n   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\r\n   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\r\n   */\r\n  async finalMessage(): Promise<ChatCompletionMessage> {\r\n    await this.done();\r\n    return this.#getFinalMessage();\r\n  }\r\n\r\n  #getFinalFunctionCall(): ChatCompletionMessage.FunctionCall | undefined {\r\n    for (let i = this.messages.length - 1; i >= 0; i--) {\r\n      const message = this.messages[i];\r\n      if (isAssistantMessage(message) && message?.function_call) {\r\n        return message.function_call;\r\n      }\r\n      if (isAssistantMessage(message) && message?.tool_calls?.length) {\r\n        return message.tool_calls.at(-1)?.function;\r\n      }\r\n    }\r\n\r\n    return;\r\n  }\r\n\r\n  /**\r\n   * @returns a promise that resolves with the content of the final FunctionCall, or rejects\r\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\r\n   */\r\n  async finalFunctionCall(): Promise<ChatCompletionMessage.FunctionCall | undefined> {\r\n    await this.done();\r\n    return this.#getFinalFunctionCall();\r\n  }\r\n\r\n  #getFinalFunctionCallResult(): string | undefined {\r\n    for (let i = this.messages.length - 1; i >= 0; i--) {\r\n      const message = this.messages[i];\r\n      if (isFunctionMessage(message) && message.content != null) {\r\n        return message.content;\r\n      }\r\n      if (\r\n        isToolMessage(message) &&\r\n        message.content != null &&\r\n        this.messages.some(\r\n          (x) =>\r\n            x.role === 'assistant' &&\r\n            x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id),\r\n        )\r\n      ) {\r\n        return message.content;\r\n      }\r\n    }\r\n\r\n    return;\r\n  }\r\n\r\n  async finalFunctionCallResult(): Promise<string | undefined> {\r\n    await this.done();\r\n    return this.#getFinalFunctionCallResult();\r\n  }\r\n\r\n  #calculateTotalUsage(): CompletionUsage {\r\n    const total: CompletionUsage = {\r\n      completion_tokens: 0,\r\n      prompt_tokens: 0,\r\n      total_tokens: 0,\r\n    };\r\n    for (const { usage } of this._chatCompletions) {\r\n      if (usage) {\r\n        total.completion_tokens += usage.completion_tokens;\r\n        total.prompt_tokens += usage.prompt_tokens;\r\n        total.total_tokens += usage.total_tokens;\r\n      }\r\n    }\r\n    return total;\r\n  }\r\n\r\n  async totalUsage(): Promise<CompletionUsage> {\r\n    await this.done();\r\n    return this.#calculateTotalUsage();\r\n  }\r\n\r\n  allChatCompletions(): ChatCompletion[] {\r\n    return [...this._chatCompletions];\r\n  }\r\n\r\n  #handleError = (error: unknown) => {\r\n    this.#errored = true;\r\n    if (error instanceof Error && error.name === 'AbortError') {\r\n      error = new APIUserAbortError();\r\n    }\r\n    if (error instanceof APIUserAbortError) {\r\n      this.#aborted = true;\r\n      return this._emit('abort', error);\r\n    }\r\n    if (error instanceof OpenAIError) {\r\n      return this._emit('error', error);\r\n    }\r\n    if (error instanceof Error) {\r\n      const openAIError: OpenAIError = new OpenAIError(error.message);\r\n      // @ts-ignore\r\n      openAIError.cause = error;\r\n      return this._emit('error', openAIError);\r\n    }\r\n    return this._emit('error', new OpenAIError(String(error)));\r\n  };\r\n\r\n  protected _emit<Event extends keyof Events>(event: Event, ...args: EventParameters<Events, Event>) {\r\n    // make sure we don't emit any events after end\r\n    if (this.#ended) {\r\n      return;\r\n    }\r\n\r\n    if (event === 'end') {\r\n      this.#ended = true;\r\n      this.#resolveEndPromise();\r\n    }\r\n\r\n    const listeners: ListenersForEvent<Events, Event> | undefined = this.#listeners[event];\r\n    if (listeners) {\r\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\r\n      listeners.forEach(({ listener }: any) => listener(...args));\r\n    }\r\n\r\n    if (event === 'abort') {\r\n      const error = args[0] as APIUserAbortError;\r\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\r\n        Promise.reject(error);\r\n      }\r\n      this.#rejectConnectedPromise(error);\r\n      this.#rejectEndPromise(error);\r\n      this._emit('end');\r\n      return;\r\n    }\r\n\r\n    if (event === 'error') {\r\n      // NOTE: _emit('error', error) should only be called from #handleError().\r\n\r\n      const error = args[0] as OpenAIError;\r\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\r\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\r\n        // If you are seeing stack traces here, make sure to handle errors via either:\r\n        // - runner.on('error', () => ...)\r\n        // - await runner.done()\r\n        // - await runner.finalChatCompletion()\r\n        // - etc.\r\n        Promise.reject(error);\r\n      }\r\n      this.#rejectConnectedPromise(error);\r\n      this.#rejectEndPromise(error);\r\n      this._emit('end');\r\n    }\r\n  }\r\n\r\n  protected _emitFinal() {\r\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\r\n    if (completion) this._emit('finalChatCompletion', completion);\r\n    const finalMessage = this.#getFinalMessage();\r\n    if (finalMessage) this._emit('finalMessage', finalMessage);\r\n    const finalContent = this.#getFinalContent();\r\n    if (finalContent) this._emit('finalContent', finalContent);\r\n\r\n    const finalFunctionCall = this.#getFinalFunctionCall();\r\n    if (finalFunctionCall) this._emit('finalFunctionCall', finalFunctionCall);\r\n\r\n    const finalFunctionCallResult = this.#getFinalFunctionCallResult();\r\n    if (finalFunctionCallResult != null) this._emit('finalFunctionCallResult', finalFunctionCallResult);\r\n\r\n    if (this._chatCompletions.some((c) => c.usage)) {\r\n      this._emit('totalUsage', this.#calculateTotalUsage());\r\n    }\r\n  }\r\n\r\n  #validateParams(params: ChatCompletionCreateParams): void {\r\n    if (params.n != null && params.n > 1) {\r\n      throw new OpenAIError(\r\n        'ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.',\r\n      );\r\n    }\r\n  }\r\n\r\n  protected async _createChatCompletion(\r\n    completions: Completions,\r\n    params: ChatCompletionCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Promise<ChatCompletion> {\r\n    const signal = options?.signal;\r\n    if (signal) {\r\n      if (signal.aborted) this.controller.abort();\r\n      signal.addEventListener('abort', () => this.controller.abort());\r\n    }\r\n    this.#validateParams(params);\r\n\r\n    const chatCompletion = await completions.create(\r\n      { ...params, stream: false },\r\n      { ...options, signal: this.controller.signal },\r\n    );\r\n    this._connected();\r\n    return this._addChatCompletion(chatCompletion);\r\n  }\r\n\r\n  protected async _runChatCompletion(\r\n    completions: Completions,\r\n    params: ChatCompletionCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Promise<ChatCompletion> {\r\n    for (const message of params.messages) {\r\n      this._addMessage(message, false);\r\n    }\r\n    return await this._createChatCompletion(completions, params, options);\r\n  }\r\n\r\n  protected async _runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\r\n    completions: Completions,\r\n    params:\r\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\r\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\r\n    options?: RunnerOptions,\r\n  ) {\r\n    const role = 'function' as const;\r\n    const { function_call = 'auto', stream, ...restParams } = params;\r\n    const singleFunctionToCall = typeof function_call !== 'string' && function_call?.name;\r\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\r\n\r\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\r\n    for (const f of params.functions) {\r\n      functionsByName[f.name || f.function.name] = f;\r\n    }\r\n\r\n    const functions: ChatCompletionCreateParams.Function[] = params.functions.map(\r\n      (f): ChatCompletionCreateParams.Function => ({\r\n        name: f.name || f.function.name,\r\n        parameters: f.parameters as Record<string, unknown>,\r\n        description: f.description,\r\n      }),\r\n    );\r\n\r\n    for (const message of params.messages) {\r\n      this._addMessage(message, false);\r\n    }\r\n\r\n    for (let i = 0; i < maxChatCompletions; ++i) {\r\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\r\n        completions,\r\n        {\r\n          ...restParams,\r\n          function_call,\r\n          functions,\r\n          messages: [...this.messages],\r\n        },\r\n        options,\r\n      );\r\n      const message = chatCompletion.choices[0]?.message;\r\n      if (!message) {\r\n        throw new OpenAIError(`missing message in ChatCompletion response`);\r\n      }\r\n      if (!message.function_call) return;\r\n      const { name, arguments: args } = message.function_call;\r\n      const fn = functionsByName[name];\r\n      if (!fn) {\r\n        const content = `Invalid function_call: ${JSON.stringify(name)}. Available options are: ${functions\r\n          .map((f) => JSON.stringify(f.name))\r\n          .join(', ')}. Please try again`;\r\n\r\n        this._addMessage({ role, name, content });\r\n        continue;\r\n      } else if (singleFunctionToCall && singleFunctionToCall !== name) {\r\n        const content = `Invalid function_call: ${JSON.stringify(name)}. ${JSON.stringify(\r\n          singleFunctionToCall,\r\n        )} requested. Please try again`;\r\n\r\n        this._addMessage({ role, name, content });\r\n        continue;\r\n      }\r\n\r\n      let parsed;\r\n      try {\r\n        parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\r\n      } catch (error) {\r\n        this._addMessage({\r\n          role,\r\n          name,\r\n          content: error instanceof Error ? error.message : String(error),\r\n        });\r\n        continue;\r\n      }\r\n\r\n      // @ts-expect-error it can't rule out `never` type.\r\n      const rawContent = await fn.function(parsed, this);\r\n      const content = this.#stringifyFunctionCallResult(rawContent);\r\n\r\n      this._addMessage({ role, name, content });\r\n\r\n      if (singleFunctionToCall) return;\r\n    }\r\n  }\r\n\r\n  protected async _runTools<FunctionsArgs extends BaseFunctionsArgs>(\r\n    completions: Completions,\r\n    params:\r\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\r\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\r\n    options?: RunnerOptions,\r\n  ) {\r\n    const role = 'tool' as const;\r\n    const { tool_choice = 'auto', stream, ...restParams } = params;\r\n    const singleFunctionToCall = typeof tool_choice !== 'string' && tool_choice?.function?.name;\r\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\r\n\r\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\r\n    for (const f of params.tools) {\r\n      if (f.type === 'function') {\r\n        functionsByName[f.function.name || f.function.function.name] = f.function;\r\n      }\r\n    }\r\n\r\n    const tools: ChatCompletionTool[] =\r\n      'tools' in params ?\r\n        params.tools.map((t) =>\r\n          t.type === 'function' ?\r\n            {\r\n              type: 'function',\r\n              function: {\r\n                name: t.function.name || t.function.function.name,\r\n                parameters: t.function.parameters as Record<string, unknown>,\r\n                description: t.function.description,\r\n              },\r\n            }\r\n          : (t as unknown as ChatCompletionTool),\r\n        )\r\n      : (undefined as any);\r\n\r\n    for (const message of params.messages) {\r\n      this._addMessage(message, false);\r\n    }\r\n\r\n    for (let i = 0; i < maxChatCompletions; ++i) {\r\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\r\n        completions,\r\n        {\r\n          ...restParams,\r\n          tool_choice,\r\n          tools,\r\n          messages: [...this.messages],\r\n        },\r\n        options,\r\n      );\r\n      const message = chatCompletion.choices[0]?.message;\r\n      if (!message) {\r\n        throw new OpenAIError(`missing message in ChatCompletion response`);\r\n      }\r\n      if (!message.tool_calls) {\r\n        return;\r\n      }\r\n\r\n      for (const tool_call of message.tool_calls) {\r\n        if (tool_call.type !== 'function') continue;\r\n        const tool_call_id = tool_call.id;\r\n        const { name, arguments: args } = tool_call.function;\r\n        const fn = functionsByName[name];\r\n\r\n        if (!fn) {\r\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${tools\r\n            .map((f) => JSON.stringify(f.function.name))\r\n            .join(', ')}. Please try again`;\r\n\r\n          this._addMessage({ role, tool_call_id, content });\r\n          continue;\r\n        } else if (singleFunctionToCall && singleFunctionToCall !== name) {\r\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(\r\n            singleFunctionToCall,\r\n          )} requested. Please try again`;\r\n\r\n          this._addMessage({ role, tool_call_id, content });\r\n          continue;\r\n        }\r\n\r\n        let parsed;\r\n        try {\r\n          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\r\n        } catch (error) {\r\n          const content = error instanceof Error ? error.message : String(error);\r\n          this._addMessage({ role, tool_call_id, content });\r\n          continue;\r\n        }\r\n\r\n        // @ts-expect-error it can't rule out `never` type.\r\n        const rawContent = await fn.function(parsed, this);\r\n        const content = this.#stringifyFunctionCallResult(rawContent);\r\n        this._addMessage({ role, tool_call_id, content });\r\n\r\n        if (singleFunctionToCall) {\r\n          return;\r\n        }\r\n      }\r\n    }\r\n\r\n    return;\r\n  }\r\n\r\n  #stringifyFunctionCallResult(rawContent: unknown): string {\r\n    return (\r\n      typeof rawContent === 'string' ? rawContent\r\n      : rawContent === undefined ? 'undefined'\r\n      : JSON.stringify(rawContent)\r\n    );\r\n  }\r\n}\r\n\r\ntype CustomEvents<Event extends string> = {\r\n  [k in Event]: k extends keyof AbstractChatCompletionRunnerEvents ? AbstractChatCompletionRunnerEvents[k]\r\n  : (...args: any[]) => void;\r\n};\r\n\r\ntype ListenerForEvent<Events extends CustomEvents<any>, Event extends keyof Events> = Event extends (\r\n  keyof AbstractChatCompletionRunnerEvents\r\n) ?\r\n  AbstractChatCompletionRunnerEvents[Event]\r\n: Events[Event];\r\n\r\ntype ListenersForEvent<Events extends CustomEvents<any>, Event extends keyof Events> = Array<{\r\n  listener: ListenerForEvent<Events, Event>;\r\n  once?: boolean;\r\n}>;\r\ntype EventParameters<Events extends CustomEvents<any>, Event extends keyof Events> = Parameters<\r\n  ListenerForEvent<Events, Event>\r\n>;\r\n\r\nexport interface AbstractChatCompletionRunnerEvents {\r\n  connect: () => void;\r\n  functionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\r\n  message: (message: ChatCompletionMessageParam) => void;\r\n  chatCompletion: (completion: ChatCompletion) => void;\r\n  finalContent: (contentSnapshot: string) => void;\r\n  finalMessage: (message: ChatCompletionMessageParam) => void;\r\n  finalChatCompletion: (completion: ChatCompletion) => void;\r\n  finalFunctionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\r\n  functionCallResult: (content: string) => void;\r\n  finalFunctionCallResult: (content: string) => void;\r\n  error: (error: OpenAIError) => void;\r\n  abort: (error: APIUserAbortError) => void;\r\n  end: () => void;\r\n  totalUsage: (usage: CompletionUsage) => void;\r\n}\r\n", "import {\r\n  type Completions,\r\n  type ChatCompletionMessageParam,\r\n  type ChatCompletionCreateParamsNonStreaming,\r\n} from \"../resources/chat/completions\";\r\nimport { type RunnableFunctions, type BaseFunctionsArgs, RunnableTools } from './RunnableFunction';\r\nimport {\r\n  AbstractChatCompletionRunner,\r\n  AbstractChatCompletionRunnerEvents,\r\n  RunnerOptions,\r\n} from './AbstractChatCompletionRunner';\r\nimport { isAssistantMessage } from './chatCompletionUtils';\r\n\r\nexport interface ChatCompletionRunnerEvents extends AbstractChatCompletionRunnerEvents {\r\n  content: (content: string) => void;\r\n}\r\n\r\nexport type ChatCompletionFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\r\n  ChatCompletionCreateParamsNonStreaming,\r\n  'functions'\r\n> & {\r\n  functions: RunnableFunctions<FunctionsArgs>;\r\n};\r\n\r\nexport type ChatCompletionToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\r\n  ChatCompletionCreateParamsNonStreaming,\r\n  'tools'\r\n> & {\r\n  tools: RunnableTools<FunctionsArgs>;\r\n};\r\n\r\nexport class ChatCompletionRunner extends AbstractChatCompletionRunner<ChatCompletionRunnerEvents> {\r\n  /** @deprecated - please use `runTools` instead. */\r\n  static runFunctions(\r\n    completions: Completions,\r\n    params: ChatCompletionFunctionRunnerParams<any[]>,\r\n    options?: RunnerOptions,\r\n  ): ChatCompletionRunner {\r\n    const runner = new ChatCompletionRunner();\r\n    const opts = {\r\n      ...options,\r\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\r\n    };\r\n    runner._run(() => runner._runFunctions(completions, params, opts));\r\n    return runner;\r\n  }\r\n\r\n  static runTools(\r\n    completions: Completions,\r\n    params: ChatCompletionToolRunnerParams<any[]>,\r\n    options?: RunnerOptions,\r\n  ): ChatCompletionRunner {\r\n    const runner = new ChatCompletionRunner();\r\n    const opts = {\r\n      ...options,\r\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\r\n    };\r\n    runner._run(() => runner._runTools(completions, params, opts));\r\n    return runner;\r\n  }\r\n\r\n  override _addMessage(message: ChatCompletionMessageParam) {\r\n    super._addMessage(message);\r\n    if (isAssistantMessage(message) && message.content) {\r\n      this._emit('content', message.content as string);\r\n    }\r\n  }\r\n}\r\n", "import * as Core from \"../core\";\r\nimport { OpenAIError, APIUserAbortError } from \"../error\";\r\nimport {\r\n  Completions,\r\n  type ChatCompletion,\r\n  type ChatCompletionChunk,\r\n  type ChatCompletionCreateParams,\r\n  type ChatCompletionCreateParamsBase,\r\n} from \"../resources/chat/completions\";\r\nimport {\r\n  AbstractChatCompletionRunner,\r\n  type AbstractChatCompletionRunnerEvents,\r\n} from './AbstractChatCompletionRunner';\r\nimport { type ReadableStream } from \"../_shims/index\";\r\nimport { Stream } from \"../streaming\";\r\n\r\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\r\n  content: (contentDelta: string, contentSnapshot: string) => void;\r\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\r\n}\r\n\r\nexport type ChatCompletionStreamParams = Omit<ChatCompletionCreateParamsBase, 'stream'> & {\r\n  stream?: true;\r\n};\r\n\r\nexport class ChatCompletionStream\r\n  extends AbstractChatCompletionRunner<ChatCompletionStreamEvents>\r\n  implements AsyncIterable<ChatCompletionChunk>\r\n{\r\n  #currentChatCompletionSnapshot: ChatCompletionSnapshot | undefined;\r\n\r\n  get currentChatCompletionSnapshot(): ChatCompletionSnapshot | undefined {\r\n    return this.#currentChatCompletionSnapshot;\r\n  }\r\n\r\n  /**\r\n   * Intended for use on the frontend, consuming a stream produced with\r\n   * `.toReadableStream()` on the backend.\r\n   *\r\n   * Note that messages sent to the model do not appear in `.on('message')`\r\n   * in this context.\r\n   */\r\n  static fromReadableStream(stream: ReadableStream): ChatCompletionStream {\r\n    const runner = new ChatCompletionStream();\r\n    runner._run(() => runner._fromReadableStream(stream));\r\n    return runner;\r\n  }\r\n\r\n  static createChatCompletion(\r\n    completions: Completions,\r\n    params: ChatCompletionStreamParams,\r\n    options?: Core.RequestOptions,\r\n  ): ChatCompletionStream {\r\n    const runner = new ChatCompletionStream();\r\n    runner._run(() =>\r\n      runner._runChatCompletion(\r\n        completions,\r\n        { ...params, stream: true },\r\n        { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } },\r\n      ),\r\n    );\r\n    return runner;\r\n  }\r\n\r\n  #beginRequest() {\r\n    if (this.ended) return;\r\n    this.#currentChatCompletionSnapshot = undefined;\r\n  }\r\n  #addChunk(chunk: ChatCompletionChunk) {\r\n    if (this.ended) return;\r\n    const completion = this.#accumulateChatCompletion(chunk);\r\n    this._emit('chunk', chunk, completion);\r\n    const delta = chunk.choices[0]?.delta?.content;\r\n    const snapshot = completion.choices[0]?.message;\r\n    if (delta != null && snapshot?.role === 'assistant' && snapshot?.content) {\r\n      this._emit('content', delta, snapshot.content);\r\n    }\r\n  }\r\n  #endRequest(): ChatCompletion {\r\n    if (this.ended) {\r\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\r\n    }\r\n    const snapshot = this.#currentChatCompletionSnapshot;\r\n    if (!snapshot) {\r\n      throw new OpenAIError(`request ended without sending any chunks`);\r\n    }\r\n    this.#currentChatCompletionSnapshot = undefined;\r\n    return finalizeChatCompletion(snapshot);\r\n  }\r\n\r\n  protected override async _createChatCompletion(\r\n    completions: Completions,\r\n    params: ChatCompletionCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Promise<ChatCompletion> {\r\n    const signal = options?.signal;\r\n    if (signal) {\r\n      if (signal.aborted) this.controller.abort();\r\n      signal.addEventListener('abort', () => this.controller.abort());\r\n    }\r\n    this.#beginRequest();\r\n    const stream = await completions.create(\r\n      { ...params, stream: true },\r\n      { ...options, signal: this.controller.signal },\r\n    );\r\n    this._connected();\r\n    for await (const chunk of stream) {\r\n      this.#addChunk(chunk);\r\n    }\r\n    if (stream.controller.signal?.aborted) {\r\n      throw new APIUserAbortError();\r\n    }\r\n    return this._addChatCompletion(this.#endRequest());\r\n  }\r\n\r\n  protected async _fromReadableStream(\r\n    readableStream: ReadableStream,\r\n    options?: Core.RequestOptions,\r\n  ): Promise<ChatCompletion> {\r\n    const signal = options?.signal;\r\n    if (signal) {\r\n      if (signal.aborted) this.controller.abort();\r\n      signal.addEventListener('abort', () => this.controller.abort());\r\n    }\r\n    this.#beginRequest();\r\n    this._connected();\r\n    const stream = Stream.fromReadableStream<ChatCompletionChunk>(readableStream, this.controller);\r\n    let chatId;\r\n    for await (const chunk of stream) {\r\n      if (chatId && chatId !== chunk.id) {\r\n        // A new request has been made.\r\n        this._addChatCompletion(this.#endRequest());\r\n      }\r\n\r\n      this.#addChunk(chunk);\r\n      chatId = chunk.id;\r\n    }\r\n    if (stream.controller.signal?.aborted) {\r\n      throw new APIUserAbortError();\r\n    }\r\n    return this._addChatCompletion(this.#endRequest());\r\n  }\r\n\r\n  #accumulateChatCompletion(chunk: ChatCompletionChunk): ChatCompletionSnapshot {\r\n    let snapshot = this.#currentChatCompletionSnapshot;\r\n    const { choices, ...rest } = chunk;\r\n    if (!snapshot) {\r\n      snapshot = this.#currentChatCompletionSnapshot = {\r\n        ...rest,\r\n        choices: [],\r\n      };\r\n    } else {\r\n      Object.assign(snapshot, rest);\r\n    }\r\n\r\n    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\r\n      let choice = snapshot.choices[index];\r\n      if (!choice) {\r\n        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\r\n      }\r\n\r\n      if (logprobs) {\r\n        if (!choice.logprobs) {\r\n          choice.logprobs = Object.assign({}, logprobs);\r\n        } else {\r\n          const { content, ...rest } = logprobs;\r\n          Object.assign(choice.logprobs, rest);\r\n          if (content) {\r\n            choice.logprobs.content ??= [];\r\n            choice.logprobs.content.push(...content);\r\n          }\r\n        }\r\n      }\r\n\r\n      if (finish_reason) choice.finish_reason = finish_reason;\r\n      Object.assign(choice, other);\r\n\r\n      if (!delta) continue; // Shouldn't happen; just in case.\r\n      const { content, function_call, role, tool_calls, ...rest } = delta;\r\n      Object.assign(choice.message, rest);\r\n\r\n      if (content) choice.message.content = (choice.message.content || '') + content;\r\n      if (role) choice.message.role = role;\r\n      if (function_call) {\r\n        if (!choice.message.function_call) {\r\n          choice.message.function_call = function_call;\r\n        } else {\r\n          if (function_call.name) choice.message.function_call.name = function_call.name;\r\n          if (function_call.arguments) {\r\n            choice.message.function_call.arguments ??= '';\r\n            choice.message.function_call.arguments += function_call.arguments;\r\n          }\r\n        }\r\n      }\r\n      if (tool_calls) {\r\n        if (!choice.message.tool_calls) choice.message.tool_calls = [];\r\n        for (const { index, id, type, function: fn, ...rest } of tool_calls) {\r\n          const tool_call = (choice.message.tool_calls[index] ??= {});\r\n          Object.assign(tool_call, rest);\r\n          if (id) tool_call.id = id;\r\n          if (type) tool_call.type = type;\r\n          if (fn) tool_call.function ??= { arguments: '' };\r\n          if (fn?.name) tool_call.function!.name = fn.name;\r\n          if (fn?.arguments) tool_call.function!.arguments += fn.arguments;\r\n        }\r\n      }\r\n    }\r\n    return snapshot;\r\n  }\r\n\r\n  [Symbol.asyncIterator](): AsyncIterator<ChatCompletionChunk> {\r\n    const pushQueue: ChatCompletionChunk[] = [];\r\n    const readQueue: ((chunk: ChatCompletionChunk | undefined) => void)[] = [];\r\n    let done = false;\r\n\r\n    this.on('chunk', (chunk) => {\r\n      const reader = readQueue.shift();\r\n      if (reader) {\r\n        reader(chunk);\r\n      } else {\r\n        pushQueue.push(chunk);\r\n      }\r\n    });\r\n\r\n    this.on('end', () => {\r\n      done = true;\r\n      for (const reader of readQueue) {\r\n        reader(undefined);\r\n      }\r\n      readQueue.length = 0;\r\n    });\r\n\r\n    return {\r\n      next: async (): Promise<IteratorResult<ChatCompletionChunk>> => {\r\n        if (!pushQueue.length) {\r\n          if (done) {\r\n            return { value: undefined, done: true };\r\n          }\r\n          return new Promise<ChatCompletionChunk | undefined>((resolve) => readQueue.push(resolve)).then(\r\n            (chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }),\r\n          );\r\n        }\r\n        const chunk = pushQueue.shift()!;\r\n        return { value: chunk, done: false };\r\n      },\r\n    };\r\n  }\r\n\r\n  toReadableStream(): ReadableStream {\r\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\r\n    return stream.toReadableStream();\r\n  }\r\n}\r\n\r\nfunction finalizeChatCompletion(snapshot: ChatCompletionSnapshot): ChatCompletion {\r\n  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\r\n  return {\r\n    ...rest,\r\n    id,\r\n    choices: choices.map(\r\n      ({ message, finish_reason, index, logprobs, ...choiceRest }): ChatCompletion.Choice => {\r\n        if (!finish_reason) throw new OpenAIError(`missing finish_reason for choice ${index}`);\r\n        const { content = null, function_call, tool_calls, ...messageRest } = message;\r\n        const role = message.role as 'assistant'; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\r\n        if (!role) throw new OpenAIError(`missing role for choice ${index}`);\r\n        if (function_call) {\r\n          const { arguments: args, name } = function_call;\r\n          if (args == null) throw new OpenAIError(`missing function_call.arguments for choice ${index}`);\r\n          if (!name) throw new OpenAIError(`missing function_call.name for choice ${index}`);\r\n          return {\r\n            ...choiceRest,\r\n            message: { content, function_call: { arguments: args, name }, role },\r\n            finish_reason,\r\n            index,\r\n            logprobs,\r\n          };\r\n        }\r\n        if (tool_calls) {\r\n          return {\r\n            ...choiceRest,\r\n            index,\r\n            finish_reason,\r\n            logprobs,\r\n            message: {\r\n              ...messageRest,\r\n              role,\r\n              content,\r\n              tool_calls: tool_calls.map((tool_call, i) => {\r\n                const { function: fn, type, id, ...toolRest } = tool_call;\r\n                const { arguments: args, name, ...fnRest } = fn || {};\r\n                if (id == null)\r\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\r\n                if (type == null)\r\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\r\n                if (name == null)\r\n                  throw new OpenAIError(\r\n                    `missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`,\r\n                  );\r\n                if (args == null)\r\n                  throw new OpenAIError(\r\n                    `missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`,\r\n                  );\r\n\r\n                return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\r\n              }),\r\n            },\r\n          };\r\n        }\r\n        return {\r\n          ...choiceRest,\r\n          message: { ...messageRest, content, role },\r\n          finish_reason,\r\n          index,\r\n          logprobs,\r\n        };\r\n      },\r\n    ),\r\n    created,\r\n    model,\r\n    object: 'chat.completion',\r\n    ...(system_fingerprint ? { system_fingerprint } : {}),\r\n  };\r\n}\r\n\r\nfunction str(x: unknown) {\r\n  return JSON.stringify(x);\r\n}\r\n\r\n/**\r\n * Represents a streamed chunk of a chat completion response returned by model,\r\n * based on the provided input.\r\n */\r\nexport interface ChatCompletionSnapshot {\r\n  /**\r\n   * A unique identifier for the chat completion.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * A list of chat completion choices. Can be more than one if `n` is greater\r\n   * than 1.\r\n   */\r\n  choices: Array<ChatCompletionSnapshot.Choice>;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) of when the chat completion was created.\r\n   */\r\n  created: number;\r\n\r\n  /**\r\n   * The model to generate the completion.\r\n   */\r\n  model: string;\r\n\r\n  // Note we do not include an \"object\" type on the snapshot,\r\n  // because the object is not a valid \"chat.completion\" until finalized.\r\n  // object: 'chat.completion';\r\n\r\n  /**\r\n   * This fingerprint represents the backend configuration that the model runs with.\r\n   *\r\n   * Can be used in conjunction with the `seed` request parameter to understand when\r\n   * backend changes have been made that might impact determinism.\r\n   */\r\n  system_fingerprint?: string;\r\n}\r\n\r\nexport namespace ChatCompletionSnapshot {\r\n  export interface Choice {\r\n    /**\r\n     * A chat completion delta generated by streamed model responses.\r\n     */\r\n    message: Choice.Message;\r\n\r\n    /**\r\n     * The reason the model stopped generating tokens. This will be `stop` if the model\r\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\r\n     * number of tokens specified in the request was reached, `content_filter` if\r\n     * content was omitted due to a flag from our content filters, or `function_call`\r\n     * if the model called a function.\r\n     */\r\n    finish_reason: ChatCompletion.Choice['finish_reason'] | null;\r\n\r\n    /**\r\n     * Log probability information for the choice.\r\n     */\r\n    logprobs: ChatCompletion.Choice.Logprobs | null;\r\n\r\n    /**\r\n     * The index of the choice in the list of choices.\r\n     */\r\n    index: number;\r\n  }\r\n\r\n  export namespace Choice {\r\n    /**\r\n     * A chat completion delta generated by streamed model responses.\r\n     */\r\n    export interface Message {\r\n      /**\r\n       * The contents of the chunk message.\r\n       */\r\n      content?: string | null;\r\n\r\n      /**\r\n       * The name and arguments of a function that should be called, as generated by the\r\n       * model.\r\n       */\r\n      function_call?: Message.FunctionCall;\r\n\r\n      tool_calls?: Array<Message.ToolCall>;\r\n\r\n      /**\r\n       * The role of the author of this message.\r\n       */\r\n      role?: 'system' | 'user' | 'assistant' | 'function' | 'tool';\r\n    }\r\n\r\n    export namespace Message {\r\n      export interface ToolCall {\r\n        /**\r\n         * The ID of the tool call.\r\n         */\r\n        id?: string;\r\n\r\n        function?: ToolCall.Function;\r\n\r\n        /**\r\n         * The type of the tool.\r\n         */\r\n        type?: 'function';\r\n      }\r\n\r\n      export namespace ToolCall {\r\n        export interface Function {\r\n          /**\r\n           * The arguments to call the function with, as generated by the model in JSON\r\n           * format. Note that the model does not always generate valid JSON, and may\r\n           * hallucinate parameters not defined by your function schema. Validate the\r\n           * arguments in your code before calling your function.\r\n           */\r\n          arguments?: string;\r\n\r\n          /**\r\n           * The name of the function to call.\r\n           */\r\n          name?: string;\r\n        }\r\n      }\r\n\r\n      /**\r\n       * The name and arguments of a function that should be called, as generated by the\r\n       * model.\r\n       */\r\n      export interface FunctionCall {\r\n        /**\r\n         * The arguments to call the function with, as generated by the model in JSON\r\n         * format. Note that the model does not always generate valid JSON, and may\r\n         * hallucinate parameters not defined by your function schema. Validate the\r\n         * arguments in your code before calling your function.\r\n         */\r\n        arguments?: string;\r\n\r\n        /**\r\n         * The name of the function to call.\r\n         */\r\n        name?: string;\r\n      }\r\n    }\r\n  }\r\n}\r\n", "import {\r\n  Completions,\r\n  type ChatCompletionChunk,\r\n  type ChatCompletionCreateParamsStreaming,\r\n} from \"../resources/chat/completions\";\r\nimport { RunnerOptions, type AbstractChatCompletionRunnerEvents } from './AbstractChatCompletionRunner';\r\nimport { type ReadableStream } from \"../_shims/index\";\r\nimport { RunnableTools, type BaseFunctionsArgs, type RunnableFunctions } from './RunnableFunction';\r\nimport { ChatCompletionSnapshot, ChatCompletionStream } from './ChatCompletionStream';\r\n\r\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\r\n  content: (contentDelta: string, contentSnapshot: string) => void;\r\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\r\n}\r\n\r\nexport type ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\r\n  ChatCompletionCreateParamsStreaming,\r\n  'functions'\r\n> & {\r\n  functions: RunnableFunctions<FunctionsArgs>;\r\n};\r\n\r\nexport type ChatCompletionStreamingToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\r\n  ChatCompletionCreateParamsStreaming,\r\n  'tools'\r\n> & {\r\n  tools: RunnableTools<FunctionsArgs>;\r\n};\r\n\r\nexport class ChatCompletionStreamingRunner\r\n  extends ChatCompletionStream\r\n  implements AsyncIterable<ChatCompletionChunk>\r\n{\r\n  static override fromReadableStream(stream: ReadableStream): ChatCompletionStreamingRunner {\r\n    const runner = new ChatCompletionStreamingRunner();\r\n    runner._run(() => runner._fromReadableStream(stream));\r\n    return runner;\r\n  }\r\n\r\n  /** @deprecated - please use `runTools` instead. */\r\n  static runFunctions<T extends (string | object)[]>(\r\n    completions: Completions,\r\n    params: ChatCompletionStreamingFunctionRunnerParams<T>,\r\n    options?: RunnerOptions,\r\n  ): ChatCompletionStreamingRunner {\r\n    const runner = new ChatCompletionStreamingRunner();\r\n    const opts = {\r\n      ...options,\r\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\r\n    };\r\n    runner._run(() => runner._runFunctions(completions, params, opts));\r\n    return runner;\r\n  }\r\n\r\n  static runTools<T extends (string | object)[]>(\r\n    completions: Completions,\r\n    params: ChatCompletionStreamingToolRunnerParams<T>,\r\n    options?: RunnerOptions,\r\n  ): ChatCompletionStreamingRunner {\r\n    const runner = new ChatCompletionStreamingRunner();\r\n    const opts = {\r\n      ...options,\r\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\r\n    };\r\n    runner._run(() => runner._runTools(completions, params, opts));\r\n    return runner;\r\n  }\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../core\";\r\nimport { APIResource } from \"../../../resource\";\r\nimport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from \"../../../lib/ChatCompletionRunner\";\r\nexport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from \"../../../lib/ChatCompletionRunner\";\r\nimport {\r\n  ChatCompletionStreamingRunner,\r\n  ChatCompletionStreamingFunctionRunnerParams,\r\n} from \"../../../lib/ChatCompletionStreamingRunner\";\r\nexport {\r\n  ChatCompletionStreamingRunner,\r\n  ChatCompletionStreamingFunctionRunnerParams,\r\n} from \"../../../lib/ChatCompletionStreamingRunner\";\r\nimport { BaseFunctionsArgs } from \"../../../lib/RunnableFunction\";\r\nexport {\r\n  RunnableFunction,\r\n  RunnableFunctions,\r\n  RunnableFunctionWithParse,\r\n  RunnableFunctionWithoutParse,\r\n  ParsingFunction,\r\n  ParsingToolFunction,\r\n} from \"../../../lib/RunnableFunction\";\r\nimport { ChatCompletionToolRunnerParams } from \"../../../lib/ChatCompletionRunner\";\r\nexport { ChatCompletionToolRunnerParams } from \"../../../lib/ChatCompletionRunner\";\r\nimport { ChatCompletionStreamingToolRunnerParams } from \"../../../lib/ChatCompletionStreamingRunner\";\r\nexport { ChatCompletionStreamingToolRunnerParams } from \"../../../lib/ChatCompletionStreamingRunner\";\r\nimport { ChatCompletionStream, type ChatCompletionStreamParams } from \"../../../lib/ChatCompletionStream\";\r\nexport { ChatCompletionStream, type ChatCompletionStreamParams } from \"../../../lib/ChatCompletionStream\";\r\n\r\nexport class Completions extends APIResource {\r\n  /**\r\n   * @deprecated - use `runTools` instead.\r\n   */\r\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\r\n    body: ChatCompletionFunctionRunnerParams<FunctionsArgs>,\r\n    options?: Core.RequestOptions,\r\n  ): ChatCompletionRunner;\r\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\r\n    body: ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\r\n    options?: Core.RequestOptions,\r\n  ): ChatCompletionStreamingRunner;\r\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\r\n    body:\r\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\r\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\r\n    options?: Core.RequestOptions,\r\n  ): ChatCompletionRunner | ChatCompletionStreamingRunner {\r\n    if (body.stream) {\r\n      return ChatCompletionStreamingRunner.runFunctions(\r\n        this._client.chat.completions,\r\n        body as ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\r\n        options,\r\n      );\r\n    }\r\n    return ChatCompletionRunner.runFunctions(\r\n      this._client.chat.completions,\r\n      body as ChatCompletionFunctionRunnerParams<FunctionsArgs>,\r\n      options,\r\n    );\r\n  }\r\n\r\n  /**\r\n   * A convenience helper for using tool calls with the /chat/completions endpoint\r\n   * which automatically calls the JavaScript functions you provide and sends their\r\n   * results back to the /chat/completions endpoint, looping as long as the model\r\n   * requests function calls.\r\n   *\r\n   * For more details and examples, see\r\n   * [the docs](https://github.com/openai/openai-node#automated-function-calls)\r\n   */\r\n  runTools<FunctionsArgs extends BaseFunctionsArgs>(\r\n    body: ChatCompletionToolRunnerParams<FunctionsArgs>,\r\n    options?: Core.RequestOptions,\r\n  ): ChatCompletionRunner;\r\n  runTools<FunctionsArgs extends BaseFunctionsArgs>(\r\n    body: ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\r\n    options?: Core.RequestOptions,\r\n  ): ChatCompletionStreamingRunner;\r\n  runTools<FunctionsArgs extends BaseFunctionsArgs>(\r\n    body:\r\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\r\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\r\n    options?: Core.RequestOptions,\r\n  ): ChatCompletionRunner | ChatCompletionStreamingRunner {\r\n    if (body.stream) {\r\n      return ChatCompletionStreamingRunner.runTools(\r\n        this._client.chat.completions,\r\n        body as ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\r\n        options,\r\n      );\r\n    }\r\n    return ChatCompletionRunner.runTools(\r\n      this._client.chat.completions,\r\n      body as ChatCompletionToolRunnerParams<FunctionsArgs>,\r\n      options,\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Creates a chat completion stream\r\n   */\r\n  stream(body: ChatCompletionStreamParams, options?: Core.RequestOptions): ChatCompletionStream {\r\n    return ChatCompletionStream.createChatCompletion(this._client.chat.completions, body, options);\r\n  }\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport { APIResource } from \"../../../resource\";\r\nimport * as CompletionsAPI from \"./completions\";\r\n\r\nexport class Chat extends APIResource {\r\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\r\n}\r\n\r\nexport namespace Chat {\r\n  export import Completions = CompletionsAPI.Completions;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../../core\";\r\nimport { APIResource } from \"../../../../resource\";\r\nimport { isRequestOptions } from \"../../../../core\";\r\nimport * as FilesAPI from \"./files\";\r\nimport { CursorPage, type CursorPageParams } from \"../../../../pagination\";\r\n\r\nexport class Files extends APIResource {\r\n  /**\r\n   * Retrieves a message file.\r\n   */\r\n  retrieve(\r\n    threadId: string,\r\n    messageId: string,\r\n    fileId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<MessageFile> {\r\n    return this._client.get(`/threads/${threadId}/messages/${messageId}/files/${fileId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Returns a list of message files.\r\n   */\r\n  list(\r\n    threadId: string,\r\n    messageId: string,\r\n    query?: FileListParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<MessageFilesPage, MessageFile>;\r\n  list(\r\n    threadId: string,\r\n    messageId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<MessageFilesPage, MessageFile>;\r\n  list(\r\n    threadId: string,\r\n    messageId: string,\r\n    query: FileListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<MessageFilesPage, MessageFile> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list(threadId, messageId, {}, query);\r\n    }\r\n    return this._client.getAPIList(`/threads/${threadId}/messages/${messageId}/files`, MessageFilesPage, {\r\n      query,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n}\r\n\r\nexport class MessageFilesPage extends CursorPage<MessageFile> {}\r\n\r\n/**\r\n * A list of files attached to a `message`.\r\n */\r\nexport interface MessageFile {\r\n  /**\r\n   * The identifier, which can be referenced in API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the message file was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * The ID of the [message](https://platform.openai.com/docs/api-reference/messages)\r\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\r\n   * attached to.\r\n   */\r\n  message_id: string;\r\n\r\n  /**\r\n   * The object type, which is always `thread.message.file`.\r\n   */\r\n  object: 'thread.message.file';\r\n}\r\n\r\nexport interface FileListParams extends CursorPageParams {\r\n  /**\r\n   * A cursor for use in pagination. `before` is an object ID that defines your place\r\n   * in the list. For instance, if you make a list request and receive 100 objects,\r\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\r\n   * fetch the previous page of the list.\r\n   */\r\n  before?: string;\r\n\r\n  /**\r\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\r\n   * order and `desc` for descending order.\r\n   */\r\n  order?: 'asc' | 'desc';\r\n}\r\n\r\nexport namespace Files {\r\n  export import MessageFile = FilesAPI.MessageFile;\r\n  export import MessageFilesPage = FilesAPI.MessageFilesPage;\r\n  export import FileListParams = FilesAPI.FileListParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../../core\";\r\nimport { APIResource } from \"../../../../resource\";\r\nimport { isRequestOptions } from \"../../../../core\";\r\nimport * as MessagesAPI from \"./messages\";\r\nimport * as FilesAPI from \"./files\";\r\nimport { CursorPage, type CursorPageParams } from \"../../../../pagination\";\r\n\r\nexport class Messages extends APIResource {\r\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\r\n\r\n  /**\r\n   * Create a message.\r\n   */\r\n  create(\r\n    threadId: string,\r\n    body: MessageCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<ThreadMessage> {\r\n    return this._client.post(`/threads/${threadId}/messages`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Retrieve a message.\r\n   */\r\n  retrieve(\r\n    threadId: string,\r\n    messageId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<ThreadMessage> {\r\n    return this._client.get(`/threads/${threadId}/messages/${messageId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Modifies a message.\r\n   */\r\n  update(\r\n    threadId: string,\r\n    messageId: string,\r\n    body: MessageUpdateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<ThreadMessage> {\r\n    return this._client.post(`/threads/${threadId}/messages/${messageId}`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Returns a list of messages for a given thread.\r\n   */\r\n  list(\r\n    threadId: string,\r\n    query?: MessageListParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<ThreadMessagesPage, ThreadMessage>;\r\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<ThreadMessagesPage, ThreadMessage>;\r\n  list(\r\n    threadId: string,\r\n    query: MessageListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<ThreadMessagesPage, ThreadMessage> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list(threadId, {}, query);\r\n    }\r\n    return this._client.getAPIList(`/threads/${threadId}/messages`, ThreadMessagesPage, {\r\n      query,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n}\r\n\r\nexport class ThreadMessagesPage extends CursorPage<ThreadMessage> {}\r\n\r\n/**\r\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\r\n * in the content of a message.\r\n */\r\nexport interface MessageContentImageFile {\r\n  image_file: MessageContentImageFile.ImageFile;\r\n\r\n  /**\r\n   * Always `image_file`.\r\n   */\r\n  type: 'image_file';\r\n}\r\n\r\nexport namespace MessageContentImageFile {\r\n  export interface ImageFile {\r\n    /**\r\n     * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\r\n     * in the message content.\r\n     */\r\n    file_id: string;\r\n  }\r\n}\r\n\r\n/**\r\n * The text content that is part of a message.\r\n */\r\nexport interface MessageContentText {\r\n  text: MessageContentText.Text;\r\n\r\n  /**\r\n   * Always `text`.\r\n   */\r\n  type: 'text';\r\n}\r\n\r\nexport namespace MessageContentText {\r\n  export interface Text {\r\n    annotations: Array<Text.FileCitation | Text.FilePath>;\r\n\r\n    /**\r\n     * The data that makes up the text.\r\n     */\r\n    value: string;\r\n  }\r\n\r\n  export namespace Text {\r\n    /**\r\n     * A citation within the message that points to a specific quote from a specific\r\n     * File associated with the assistant or the message. Generated when the assistant\r\n     * uses the \"retrieval\" tool to search files.\r\n     */\r\n    export interface FileCitation {\r\n      end_index: number;\r\n\r\n      file_citation: FileCitation.FileCitation;\r\n\r\n      start_index: number;\r\n\r\n      /**\r\n       * The text in the message content that needs to be replaced.\r\n       */\r\n      text: string;\r\n\r\n      /**\r\n       * Always `file_citation`.\r\n       */\r\n      type: 'file_citation';\r\n    }\r\n\r\n    export namespace FileCitation {\r\n      export interface FileCitation {\r\n        /**\r\n         * The ID of the specific File the citation is from.\r\n         */\r\n        file_id: string;\r\n\r\n        /**\r\n         * The specific quote in the file.\r\n         */\r\n        quote: string;\r\n      }\r\n    }\r\n\r\n    /**\r\n     * A URL for the file that's generated when the assistant used the\r\n     * `code_interpreter` tool to generate a file.\r\n     */\r\n    export interface FilePath {\r\n      end_index: number;\r\n\r\n      file_path: FilePath.FilePath;\r\n\r\n      start_index: number;\r\n\r\n      /**\r\n       * The text in the message content that needs to be replaced.\r\n       */\r\n      text: string;\r\n\r\n      /**\r\n       * Always `file_path`.\r\n       */\r\n      type: 'file_path';\r\n    }\r\n\r\n    export namespace FilePath {\r\n      export interface FilePath {\r\n        /**\r\n         * The ID of the file that was generated.\r\n         */\r\n        file_id: string;\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * Represents a message within a\r\n * [thread](https://platform.openai.com/docs/api-reference/threads).\r\n */\r\nexport interface ThreadMessage {\r\n  /**\r\n   * The identifier, which can be referenced in API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * If applicable, the ID of the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) that\r\n   * authored this message.\r\n   */\r\n  assistant_id: string | null;\r\n\r\n  /**\r\n   * The content of the message in array of text and/or images.\r\n   */\r\n  content: Array<MessageContentImageFile | MessageContentText>;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the message was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs that\r\n   * the assistant should use. Useful for tools like retrieval and code_interpreter\r\n   * that can access files. A maximum of 10 files can be attached to a message.\r\n   */\r\n  file_ids: Array<string>;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata: unknown | null;\r\n\r\n  /**\r\n   * The object type, which is always `thread.message`.\r\n   */\r\n  object: 'thread.message';\r\n\r\n  /**\r\n   * The entity that produced the message. One of `user` or `assistant`.\r\n   */\r\n  role: 'user' | 'assistant';\r\n\r\n  /**\r\n   * If applicable, the ID of the\r\n   * [run](https://platform.openai.com/docs/api-reference/runs) associated with the\r\n   * authoring of this message.\r\n   */\r\n  run_id: string | null;\r\n\r\n  /**\r\n   * The [thread](https://platform.openai.com/docs/api-reference/threads) ID that\r\n   * this message belongs to.\r\n   */\r\n  thread_id: string;\r\n}\r\n\r\nexport interface ThreadMessageDeleted {\r\n  id: string;\r\n\r\n  deleted: boolean;\r\n\r\n  object: 'thread.message.deleted';\r\n}\r\n\r\nexport interface MessageCreateParams {\r\n  /**\r\n   * The content of the message.\r\n   */\r\n  content: string;\r\n\r\n  /**\r\n   * The role of the entity that is creating the message. Currently only `user` is\r\n   * supported.\r\n   */\r\n  role: 'user';\r\n\r\n  /**\r\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\r\n   * the message should use. There can be a maximum of 10 files attached to a\r\n   * message. Useful for tools like `retrieval` and `code_interpreter` that can\r\n   * access and use files.\r\n   */\r\n  file_ids?: Array<string>;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n}\r\n\r\nexport interface MessageUpdateParams {\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n}\r\n\r\nexport interface MessageListParams extends CursorPageParams {\r\n  /**\r\n   * A cursor for use in pagination. `before` is an object ID that defines your place\r\n   * in the list. For instance, if you make a list request and receive 100 objects,\r\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\r\n   * fetch the previous page of the list.\r\n   */\r\n  before?: string;\r\n\r\n  /**\r\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\r\n   * order and `desc` for descending order.\r\n   */\r\n  order?: 'asc' | 'desc';\r\n}\r\n\r\nexport namespace Messages {\r\n  export import MessageContentImageFile = MessagesAPI.MessageContentImageFile;\r\n  export import MessageContentText = MessagesAPI.MessageContentText;\r\n  export import ThreadMessage = MessagesAPI.ThreadMessage;\r\n  export import ThreadMessageDeleted = MessagesAPI.ThreadMessageDeleted;\r\n  export import ThreadMessagesPage = MessagesAPI.ThreadMessagesPage;\r\n  export import MessageCreateParams = MessagesAPI.MessageCreateParams;\r\n  export import MessageUpdateParams = MessagesAPI.MessageUpdateParams;\r\n  export import MessageListParams = MessagesAPI.MessageListParams;\r\n  export import Files = FilesAPI.Files;\r\n  export import MessageFile = FilesAPI.MessageFile;\r\n  export import MessageFilesPage = FilesAPI.MessageFilesPage;\r\n  export import FileListParams = FilesAPI.FileListParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../../core\";\r\nimport { APIResource } from \"../../../../resource\";\r\nimport { isRequestOptions } from \"../../../../core\";\r\nimport * as StepsAPI from \"./steps\";\r\nimport { CursorPage, type CursorPageParams } from \"../../../../pagination\";\r\n\r\nexport class Steps extends APIResource {\r\n  /**\r\n   * Retrieves a run step.\r\n   */\r\n  retrieve(\r\n    threadId: string,\r\n    runId: string,\r\n    stepId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<RunStep> {\r\n    return this._client.get(`/threads/${threadId}/runs/${runId}/steps/${stepId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Returns a list of run steps belonging to a run.\r\n   */\r\n  list(\r\n    threadId: string,\r\n    runId: string,\r\n    query?: StepListParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<RunStepsPage, RunStep>;\r\n  list(\r\n    threadId: string,\r\n    runId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<RunStepsPage, RunStep>;\r\n  list(\r\n    threadId: string,\r\n    runId: string,\r\n    query: StepListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<RunStepsPage, RunStep> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list(threadId, runId, {}, query);\r\n    }\r\n    return this._client.getAPIList(`/threads/${threadId}/runs/${runId}/steps`, RunStepsPage, {\r\n      query,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n}\r\n\r\nexport class RunStepsPage extends CursorPage<RunStep> {}\r\n\r\n/**\r\n * Details of the Code Interpreter tool call the run step was involved in.\r\n */\r\nexport interface CodeToolCall {\r\n  /**\r\n   * The ID of the tool call.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The Code Interpreter tool call definition.\r\n   */\r\n  code_interpreter: CodeToolCall.CodeInterpreter;\r\n\r\n  /**\r\n   * The type of tool call. This is always going to be `code_interpreter` for this\r\n   * type of tool call.\r\n   */\r\n  type: 'code_interpreter';\r\n}\r\n\r\nexport namespace CodeToolCall {\r\n  /**\r\n   * The Code Interpreter tool call definition.\r\n   */\r\n  export interface CodeInterpreter {\r\n    /**\r\n     * The input to the Code Interpreter tool call.\r\n     */\r\n    input: string;\r\n\r\n    /**\r\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\r\n     * or more items, including text (`logs`) or images (`image`). Each of these are\r\n     * represented by a different object type.\r\n     */\r\n    outputs: Array<CodeInterpreter.Logs | CodeInterpreter.Image>;\r\n  }\r\n\r\n  export namespace CodeInterpreter {\r\n    /**\r\n     * Text output from the Code Interpreter tool call as part of a run step.\r\n     */\r\n    export interface Logs {\r\n      /**\r\n       * The text output from the Code Interpreter tool call.\r\n       */\r\n      logs: string;\r\n\r\n      /**\r\n       * Always `logs`.\r\n       */\r\n      type: 'logs';\r\n    }\r\n\r\n    export interface Image {\r\n      image: Image.Image;\r\n\r\n      /**\r\n       * Always `image`.\r\n       */\r\n      type: 'image';\r\n    }\r\n\r\n    export namespace Image {\r\n      export interface Image {\r\n        /**\r\n         * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\r\n         * image.\r\n         */\r\n        file_id: string;\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nexport interface FunctionToolCall {\r\n  /**\r\n   * The ID of the tool call object.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The definition of the function that was called.\r\n   */\r\n  function: FunctionToolCall.Function;\r\n\r\n  /**\r\n   * The type of tool call. This is always going to be `function` for this type of\r\n   * tool call.\r\n   */\r\n  type: 'function';\r\n}\r\n\r\nexport namespace FunctionToolCall {\r\n  /**\r\n   * The definition of the function that was called.\r\n   */\r\n  export interface Function {\r\n    /**\r\n     * The arguments passed to the function.\r\n     */\r\n    arguments: string;\r\n\r\n    /**\r\n     * The name of the function.\r\n     */\r\n    name: string;\r\n\r\n    /**\r\n     * The output of the function. This will be `null` if the outputs have not been\r\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\r\n     * yet.\r\n     */\r\n    output: string | null;\r\n  }\r\n}\r\n\r\n/**\r\n * Details of the message creation by the run step.\r\n */\r\nexport interface MessageCreationStepDetails {\r\n  message_creation: MessageCreationStepDetails.MessageCreation;\r\n\r\n  /**\r\n   * Always `message_creation`.\r\n   */\r\n  type: 'message_creation';\r\n}\r\n\r\nexport namespace MessageCreationStepDetails {\r\n  export interface MessageCreation {\r\n    /**\r\n     * The ID of the message that was created by this run step.\r\n     */\r\n    message_id: string;\r\n  }\r\n}\r\n\r\nexport interface RetrievalToolCall {\r\n  /**\r\n   * The ID of the tool call object.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * For now, this is always going to be an empty object.\r\n   */\r\n  retrieval: unknown;\r\n\r\n  /**\r\n   * The type of tool call. This is always going to be `retrieval` for this type of\r\n   * tool call.\r\n   */\r\n  type: 'retrieval';\r\n}\r\n\r\n/**\r\n * Represents a step in execution of a run.\r\n */\r\nexport interface RunStep {\r\n  /**\r\n   * The identifier of the run step, which can be referenced in API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The ID of the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants)\r\n   * associated with the run step.\r\n   */\r\n  assistant_id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run step was cancelled.\r\n   */\r\n  cancelled_at: number | null;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run step completed.\r\n   */\r\n  completed_at: number | null;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run step was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run step expired. A step is\r\n   * considered expired if the parent run is expired.\r\n   */\r\n  expired_at: number | null;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run step failed.\r\n   */\r\n  failed_at: number | null;\r\n\r\n  /**\r\n   * The last error associated with this run step. Will be `null` if there are no\r\n   * errors.\r\n   */\r\n  last_error: RunStep.LastError | null;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata: unknown | null;\r\n\r\n  /**\r\n   * The object type, which is always `thread.run.step`.\r\n   */\r\n  object: 'thread.run.step';\r\n\r\n  /**\r\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that\r\n   * this run step is a part of.\r\n   */\r\n  run_id: string;\r\n\r\n  /**\r\n   * The status of the run step, which can be either `in_progress`, `cancelled`,\r\n   * `failed`, `completed`, or `expired`.\r\n   */\r\n  status: 'in_progress' | 'cancelled' | 'failed' | 'completed' | 'expired';\r\n\r\n  /**\r\n   * The details of the run step.\r\n   */\r\n  step_details: MessageCreationStepDetails | ToolCallsStepDetails;\r\n\r\n  /**\r\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\r\n   * that was run.\r\n   */\r\n  thread_id: string;\r\n\r\n  /**\r\n   * The type of run step, which can be either `message_creation` or `tool_calls`.\r\n   */\r\n  type: 'message_creation' | 'tool_calls';\r\n\r\n  /**\r\n   * Usage statistics related to the run step. This value will be `null` while the\r\n   * run step's status is `in_progress`.\r\n   */\r\n  usage: RunStep.Usage | null;\r\n}\r\n\r\nexport namespace RunStep {\r\n  /**\r\n   * The last error associated with this run step. Will be `null` if there are no\r\n   * errors.\r\n   */\r\n  export interface LastError {\r\n    /**\r\n     * One of `server_error` or `rate_limit_exceeded`.\r\n     */\r\n    code: 'server_error' | 'rate_limit_exceeded';\r\n\r\n    /**\r\n     * A human-readable description of the error.\r\n     */\r\n    message: string;\r\n  }\r\n\r\n  /**\r\n   * Usage statistics related to the run step. This value will be `null` while the\r\n   * run step's status is `in_progress`.\r\n   */\r\n  export interface Usage {\r\n    /**\r\n     * Number of completion tokens used over the course of the run step.\r\n     */\r\n    completion_tokens: number;\r\n\r\n    /**\r\n     * Number of prompt tokens used over the course of the run step.\r\n     */\r\n    prompt_tokens: number;\r\n\r\n    /**\r\n     * Total number of tokens used (prompt + completion).\r\n     */\r\n    total_tokens: number;\r\n  }\r\n}\r\n\r\n/**\r\n * Details of the tool call.\r\n */\r\nexport interface ToolCallsStepDetails {\r\n  /**\r\n   * An array of tool calls the run step was involved in. These can be associated\r\n   * with one of three types of tools: `code_interpreter`, `retrieval`, or\r\n   * `function`.\r\n   */\r\n  tool_calls: Array<CodeToolCall | RetrievalToolCall | FunctionToolCall>;\r\n\r\n  /**\r\n   * Always `tool_calls`.\r\n   */\r\n  type: 'tool_calls';\r\n}\r\n\r\nexport interface StepListParams extends CursorPageParams {\r\n  /**\r\n   * A cursor for use in pagination. `before` is an object ID that defines your place\r\n   * in the list. For instance, if you make a list request and receive 100 objects,\r\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\r\n   * fetch the previous page of the list.\r\n   */\r\n  before?: string;\r\n\r\n  /**\r\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\r\n   * order and `desc` for descending order.\r\n   */\r\n  order?: 'asc' | 'desc';\r\n}\r\n\r\nexport namespace Steps {\r\n  export import CodeToolCall = StepsAPI.CodeToolCall;\r\n  export import FunctionToolCall = StepsAPI.FunctionToolCall;\r\n  export import MessageCreationStepDetails = StepsAPI.MessageCreationStepDetails;\r\n  export import RetrievalToolCall = StepsAPI.RetrievalToolCall;\r\n  export import RunStep = StepsAPI.RunStep;\r\n  export import ToolCallsStepDetails = StepsAPI.ToolCallsStepDetails;\r\n  export import RunStepsPage = StepsAPI.RunStepsPage;\r\n  export import StepListParams = StepsAPI.StepListParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../../core\";\r\nimport { APIResource } from \"../../../../resource\";\r\nimport { isRequestOptions } from \"../../../../core\";\r\nimport * as RunsAPI from \"./runs\";\r\nimport * as Shared from \"../../../shared\";\r\nimport * as StepsAPI from \"./steps\";\r\nimport { CursorPage, type CursorPageParams } from \"../../../../pagination\";\r\n\r\nexport class Runs extends APIResource {\r\n  steps: StepsAPI.Steps = new StepsAPI.Steps(this._client);\r\n\r\n  /**\r\n   * Create a run.\r\n   */\r\n  create(threadId: string, body: RunCreateParams, options?: Core.RequestOptions): Core.APIPromise<Run> {\r\n    return this._client.post(`/threads/${threadId}/runs`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Retrieves a run.\r\n   */\r\n  retrieve(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\r\n    return this._client.get(`/threads/${threadId}/runs/${runId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Modifies a run.\r\n   */\r\n  update(\r\n    threadId: string,\r\n    runId: string,\r\n    body: RunUpdateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<Run> {\r\n    return this._client.post(`/threads/${threadId}/runs/${runId}`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Returns a list of runs belonging to a thread.\r\n   */\r\n  list(\r\n    threadId: string,\r\n    query?: RunListParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<RunsPage, Run>;\r\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<RunsPage, Run>;\r\n  list(\r\n    threadId: string,\r\n    query: RunListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<RunsPage, Run> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list(threadId, {}, query);\r\n    }\r\n    return this._client.getAPIList(`/threads/${threadId}/runs`, RunsPage, {\r\n      query,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Cancels a run that is `in_progress`.\r\n   */\r\n  cancel(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\r\n    return this._client.post(`/threads/${threadId}/runs/${runId}/cancel`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * When a run has the `status: \"requires_action\"` and `required_action.type` is\r\n   * `submit_tool_outputs`, this endpoint can be used to submit the outputs from the\r\n   * tool calls once they're all completed. All outputs must be submitted in a single\r\n   * request.\r\n   */\r\n  submitToolOutputs(\r\n    threadId: string,\r\n    runId: string,\r\n    body: RunSubmitToolOutputsParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<Run> {\r\n    return this._client.post(`/threads/${threadId}/runs/${runId}/submit_tool_outputs`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n}\r\n\r\nexport class RunsPage extends CursorPage<Run> {}\r\n\r\n/**\r\n * Tool call objects\r\n */\r\nexport interface RequiredActionFunctionToolCall {\r\n  /**\r\n   * The ID of the tool call. This ID must be referenced when you submit the tool\r\n   * outputs in using the\r\n   * [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\r\n   * endpoint.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The function definition.\r\n   */\r\n  function: RequiredActionFunctionToolCall.Function;\r\n\r\n  /**\r\n   * The type of tool call the output is required for. For now, this is always\r\n   * `function`.\r\n   */\r\n  type: 'function';\r\n}\r\n\r\nexport namespace RequiredActionFunctionToolCall {\r\n  /**\r\n   * The function definition.\r\n   */\r\n  export interface Function {\r\n    /**\r\n     * The arguments that the model expects you to pass to the function.\r\n     */\r\n    arguments: string;\r\n\r\n    /**\r\n     * The name of the function.\r\n     */\r\n    name: string;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents an execution run on a\r\n * [thread](https://platform.openai.com/docs/api-reference/threads).\r\n */\r\nexport interface Run {\r\n  /**\r\n   * The identifier, which can be referenced in API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The ID of the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\r\n   * execution of this run.\r\n   */\r\n  assistant_id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run was cancelled.\r\n   */\r\n  cancelled_at: number | null;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run was completed.\r\n   */\r\n  completed_at: number | null;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run will expire.\r\n   */\r\n  expires_at: number;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run failed.\r\n   */\r\n  failed_at: number | null;\r\n\r\n  /**\r\n   * The list of [File](https://platform.openai.com/docs/api-reference/files) IDs the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\r\n   * this run.\r\n   */\r\n  file_ids: Array<string>;\r\n\r\n  /**\r\n   * The instructions that the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\r\n   * this run.\r\n   */\r\n  instructions: string;\r\n\r\n  /**\r\n   * The last error associated with this run. Will be `null` if there are no errors.\r\n   */\r\n  last_error: Run.LastError | null;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata: unknown | null;\r\n\r\n  /**\r\n   * The model that the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\r\n   * this run.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always `thread.run`.\r\n   */\r\n  object: 'thread.run';\r\n\r\n  /**\r\n   * Details on the action required to continue the run. Will be `null` if no action\r\n   * is required.\r\n   */\r\n  required_action: Run.RequiredAction | null;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the run was started.\r\n   */\r\n  started_at: number | null;\r\n\r\n  /**\r\n   * The status of the run, which can be either `queued`, `in_progress`,\r\n   * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or\r\n   * `expired`.\r\n   */\r\n  status:\r\n    | 'queued'\r\n    | 'in_progress'\r\n    | 'requires_action'\r\n    | 'cancelling'\r\n    | 'cancelled'\r\n    | 'failed'\r\n    | 'completed'\r\n    | 'expired';\r\n\r\n  /**\r\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\r\n   * that was executed on as a part of this run.\r\n   */\r\n  thread_id: string;\r\n\r\n  /**\r\n   * The list of tools that the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\r\n   * this run.\r\n   */\r\n  tools: Array<Run.AssistantToolsCode | Run.AssistantToolsRetrieval | Run.AssistantToolsFunction>;\r\n\r\n  /**\r\n   * Usage statistics related to the run. This value will be `null` if the run is not\r\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\r\n   */\r\n  usage: Run.Usage | null;\r\n}\r\n\r\nexport namespace Run {\r\n  /**\r\n   * The last error associated with this run. Will be `null` if there are no errors.\r\n   */\r\n  export interface LastError {\r\n    /**\r\n     * One of `server_error` or `rate_limit_exceeded`.\r\n     */\r\n    code: 'server_error' | 'rate_limit_exceeded';\r\n\r\n    /**\r\n     * A human-readable description of the error.\r\n     */\r\n    message: string;\r\n  }\r\n\r\n  /**\r\n   * Details on the action required to continue the run. Will be `null` if no action\r\n   * is required.\r\n   */\r\n  export interface RequiredAction {\r\n    /**\r\n     * Details on the tool outputs needed for this run to continue.\r\n     */\r\n    submit_tool_outputs: RequiredAction.SubmitToolOutputs;\r\n\r\n    /**\r\n     * For now, this is always `submit_tool_outputs`.\r\n     */\r\n    type: 'submit_tool_outputs';\r\n  }\r\n\r\n  export namespace RequiredAction {\r\n    /**\r\n     * Details on the tool outputs needed for this run to continue.\r\n     */\r\n    export interface SubmitToolOutputs {\r\n      /**\r\n       * A list of the relevant tool calls.\r\n       */\r\n      tool_calls: Array<RunsAPI.RequiredActionFunctionToolCall>;\r\n    }\r\n  }\r\n\r\n  export interface AssistantToolsCode {\r\n    /**\r\n     * The type of tool being defined: `code_interpreter`\r\n     */\r\n    type: 'code_interpreter';\r\n  }\r\n\r\n  export interface AssistantToolsRetrieval {\r\n    /**\r\n     * The type of tool being defined: `retrieval`\r\n     */\r\n    type: 'retrieval';\r\n  }\r\n\r\n  export interface AssistantToolsFunction {\r\n    function: Shared.FunctionDefinition;\r\n\r\n    /**\r\n     * The type of tool being defined: `function`\r\n     */\r\n    type: 'function';\r\n  }\r\n\r\n  /**\r\n   * Usage statistics related to the run. This value will be `null` if the run is not\r\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\r\n   */\r\n  export interface Usage {\r\n    /**\r\n     * Number of completion tokens used over the course of the run.\r\n     */\r\n    completion_tokens: number;\r\n\r\n    /**\r\n     * Number of prompt tokens used over the course of the run.\r\n     */\r\n    prompt_tokens: number;\r\n\r\n    /**\r\n     * Total number of tokens used (prompt + completion).\r\n     */\r\n    total_tokens: number;\r\n  }\r\n}\r\n\r\nexport interface RunCreateParams {\r\n  /**\r\n   * The ID of the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\r\n   * execute this run.\r\n   */\r\n  assistant_id: string;\r\n\r\n  /**\r\n   * Appends additional instructions at the end of the instructions for the run. This\r\n   * is useful for modifying the behavior on a per-run basis without overriding other\r\n   * instructions.\r\n   */\r\n  additional_instructions?: string | null;\r\n\r\n  /**\r\n   * Overrides the\r\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\r\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\r\n   */\r\n  instructions?: string | null;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n\r\n  /**\r\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\r\n   * be used to execute this run. If a value is provided here, it will override the\r\n   * model associated with the assistant. If not, the model associated with the\r\n   * assistant will be used.\r\n   */\r\n  model?: string | null;\r\n\r\n  /**\r\n   * Override the tools the assistant can use for this run. This is useful for\r\n   * modifying the behavior on a per-run basis.\r\n   */\r\n  tools?: Array<\r\n    | RunCreateParams.AssistantToolsCode\r\n    | RunCreateParams.AssistantToolsRetrieval\r\n    | RunCreateParams.AssistantToolsFunction\r\n  > | null;\r\n}\r\n\r\nexport namespace RunCreateParams {\r\n  export interface AssistantToolsCode {\r\n    /**\r\n     * The type of tool being defined: `code_interpreter`\r\n     */\r\n    type: 'code_interpreter';\r\n  }\r\n\r\n  export interface AssistantToolsRetrieval {\r\n    /**\r\n     * The type of tool being defined: `retrieval`\r\n     */\r\n    type: 'retrieval';\r\n  }\r\n\r\n  export interface AssistantToolsFunction {\r\n    function: Shared.FunctionDefinition;\r\n\r\n    /**\r\n     * The type of tool being defined: `function`\r\n     */\r\n    type: 'function';\r\n  }\r\n}\r\n\r\nexport interface RunUpdateParams {\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n}\r\n\r\nexport interface RunListParams extends CursorPageParams {\r\n  /**\r\n   * A cursor for use in pagination. `before` is an object ID that defines your place\r\n   * in the list. For instance, if you make a list request and receive 100 objects,\r\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\r\n   * fetch the previous page of the list.\r\n   */\r\n  before?: string;\r\n\r\n  /**\r\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\r\n   * order and `desc` for descending order.\r\n   */\r\n  order?: 'asc' | 'desc';\r\n}\r\n\r\nexport interface RunSubmitToolOutputsParams {\r\n  /**\r\n   * A list of tools for which the outputs are being submitted.\r\n   */\r\n  tool_outputs: Array<RunSubmitToolOutputsParams.ToolOutput>;\r\n}\r\n\r\nexport namespace RunSubmitToolOutputsParams {\r\n  export interface ToolOutput {\r\n    /**\r\n     * The output of the tool call to be submitted to continue the run.\r\n     */\r\n    output?: string;\r\n\r\n    /**\r\n     * The ID of the tool call in the `required_action` object within the run object\r\n     * the output is being submitted for.\r\n     */\r\n    tool_call_id?: string;\r\n  }\r\n}\r\n\r\nexport namespace Runs {\r\n  export import RequiredActionFunctionToolCall = RunsAPI.RequiredActionFunctionToolCall;\r\n  export import Run = RunsAPI.Run;\r\n  export import RunsPage = RunsAPI.RunsPage;\r\n  export import RunCreateParams = RunsAPI.RunCreateParams;\r\n  export import RunUpdateParams = RunsAPI.RunUpdateParams;\r\n  export import RunListParams = RunsAPI.RunListParams;\r\n  export import RunSubmitToolOutputsParams = RunsAPI.RunSubmitToolOutputsParams;\r\n  export import Steps = StepsAPI.Steps;\r\n  export import CodeToolCall = StepsAPI.CodeToolCall;\r\n  export import FunctionToolCall = StepsAPI.FunctionToolCall;\r\n  export import MessageCreationStepDetails = StepsAPI.MessageCreationStepDetails;\r\n  export import RetrievalToolCall = StepsAPI.RetrievalToolCall;\r\n  export import RunStep = StepsAPI.RunStep;\r\n  export import ToolCallsStepDetails = StepsAPI.ToolCallsStepDetails;\r\n  export import RunStepsPage = StepsAPI.RunStepsPage;\r\n  export import StepListParams = StepsAPI.StepListParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../../core\";\r\nimport { APIResource } from \"../../../resource\";\r\nimport { isRequestOptions } from \"../../../core\";\r\nimport * as ThreadsAPI from \"./threads\";\r\nimport * as Shared from \"../../shared\";\r\nimport * as MessagesAPI from \"./messages/messages\";\r\nimport * as RunsAPI from \"./runs/runs\";\r\n\r\nexport class Threads extends APIResource {\r\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\r\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\r\n\r\n  /**\r\n   * Create a thread.\r\n   */\r\n  create(body?: ThreadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Thread>;\r\n  create(options?: Core.RequestOptions): Core.APIPromise<Thread>;\r\n  create(\r\n    body: ThreadCreateParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<Thread> {\r\n    if (isRequestOptions(body)) {\r\n      return this.create({}, body);\r\n    }\r\n    return this._client.post('/threads', {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Retrieves a thread.\r\n   */\r\n  retrieve(threadId: string, options?: Core.RequestOptions): Core.APIPromise<Thread> {\r\n    return this._client.get(`/threads/${threadId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Modifies a thread.\r\n   */\r\n  update(threadId: string, body: ThreadUpdateParams, options?: Core.RequestOptions): Core.APIPromise<Thread> {\r\n    return this._client.post(`/threads/${threadId}`, {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Delete a thread.\r\n   */\r\n  del(threadId: string, options?: Core.RequestOptions): Core.APIPromise<ThreadDeleted> {\r\n    return this._client.delete(`/threads/${threadId}`, {\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Create a thread and run it in one request.\r\n   */\r\n  createAndRun(body: ThreadCreateAndRunParams, options?: Core.RequestOptions): Core.APIPromise<RunsAPI.Run> {\r\n    return this._client.post('/threads/runs', {\r\n      body,\r\n      ...options,\r\n      headers: { 'OpenAI-Beta': 'assistants=v1', ...options?.headers },\r\n    });\r\n  }\r\n}\r\n\r\n/**\r\n * Represents a thread that contains\r\n * [messages](https://platform.openai.com/docs/api-reference/messages).\r\n */\r\nexport interface Thread {\r\n  /**\r\n   * The identifier, which can be referenced in API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the thread was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata: unknown | null;\r\n\r\n  /**\r\n   * The object type, which is always `thread`.\r\n   */\r\n  object: 'thread';\r\n}\r\n\r\nexport interface ThreadDeleted {\r\n  id: string;\r\n\r\n  deleted: boolean;\r\n\r\n  object: 'thread.deleted';\r\n}\r\n\r\nexport interface ThreadCreateParams {\r\n  /**\r\n   * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\r\n   * start the thread with.\r\n   */\r\n  messages?: Array<ThreadCreateParams.Message>;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n}\r\n\r\nexport namespace ThreadCreateParams {\r\n  export interface Message {\r\n    /**\r\n     * The content of the message.\r\n     */\r\n    content: string;\r\n\r\n    /**\r\n     * The role of the entity that is creating the message. Currently only `user` is\r\n     * supported.\r\n     */\r\n    role: 'user';\r\n\r\n    /**\r\n     * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\r\n     * the message should use. There can be a maximum of 10 files attached to a\r\n     * message. Useful for tools like `retrieval` and `code_interpreter` that can\r\n     * access and use files.\r\n     */\r\n    file_ids?: Array<string>;\r\n\r\n    /**\r\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n     * for storing additional information about the object in a structured format. Keys\r\n     * can be a maximum of 64 characters long and values can be a maxium of 512\r\n     * characters long.\r\n     */\r\n    metadata?: unknown | null;\r\n  }\r\n}\r\n\r\nexport interface ThreadUpdateParams {\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n}\r\n\r\nexport interface ThreadCreateAndRunParams {\r\n  /**\r\n   * The ID of the\r\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\r\n   * execute this run.\r\n   */\r\n  assistant_id: string;\r\n\r\n  /**\r\n   * Override the default system message of the assistant. This is useful for\r\n   * modifying the behavior on a per-run basis.\r\n   */\r\n  instructions?: string | null;\r\n\r\n  /**\r\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n   * for storing additional information about the object in a structured format. Keys\r\n   * can be a maximum of 64 characters long and values can be a maxium of 512\r\n   * characters long.\r\n   */\r\n  metadata?: unknown | null;\r\n\r\n  /**\r\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\r\n   * be used to execute this run. If a value is provided here, it will override the\r\n   * model associated with the assistant. If not, the model associated with the\r\n   * assistant will be used.\r\n   */\r\n  model?: string | null;\r\n\r\n  /**\r\n   * If no thread is provided, an empty thread will be created.\r\n   */\r\n  thread?: ThreadCreateAndRunParams.Thread;\r\n\r\n  /**\r\n   * Override the tools the assistant can use for this run. This is useful for\r\n   * modifying the behavior on a per-run basis.\r\n   */\r\n  tools?: Array<\r\n    | ThreadCreateAndRunParams.AssistantToolsCode\r\n    | ThreadCreateAndRunParams.AssistantToolsRetrieval\r\n    | ThreadCreateAndRunParams.AssistantToolsFunction\r\n  > | null;\r\n}\r\n\r\nexport namespace ThreadCreateAndRunParams {\r\n  /**\r\n   * If no thread is provided, an empty thread will be created.\r\n   */\r\n  export interface Thread {\r\n    /**\r\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\r\n     * start the thread with.\r\n     */\r\n    messages?: Array<Thread.Message>;\r\n\r\n    /**\r\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n     * for storing additional information about the object in a structured format. Keys\r\n     * can be a maximum of 64 characters long and values can be a maxium of 512\r\n     * characters long.\r\n     */\r\n    metadata?: unknown | null;\r\n  }\r\n\r\n  export namespace Thread {\r\n    export interface Message {\r\n      /**\r\n       * The content of the message.\r\n       */\r\n      content: string;\r\n\r\n      /**\r\n       * The role of the entity that is creating the message. Currently only `user` is\r\n       * supported.\r\n       */\r\n      role: 'user';\r\n\r\n      /**\r\n       * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\r\n       * the message should use. There can be a maximum of 10 files attached to a\r\n       * message. Useful for tools like `retrieval` and `code_interpreter` that can\r\n       * access and use files.\r\n       */\r\n      file_ids?: Array<string>;\r\n\r\n      /**\r\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\r\n       * for storing additional information about the object in a structured format. Keys\r\n       * can be a maximum of 64 characters long and values can be a maxium of 512\r\n       * characters long.\r\n       */\r\n      metadata?: unknown | null;\r\n    }\r\n  }\r\n\r\n  export interface AssistantToolsCode {\r\n    /**\r\n     * The type of tool being defined: `code_interpreter`\r\n     */\r\n    type: 'code_interpreter';\r\n  }\r\n\r\n  export interface AssistantToolsRetrieval {\r\n    /**\r\n     * The type of tool being defined: `retrieval`\r\n     */\r\n    type: 'retrieval';\r\n  }\r\n\r\n  export interface AssistantToolsFunction {\r\n    function: Shared.FunctionDefinition;\r\n\r\n    /**\r\n     * The type of tool being defined: `function`\r\n     */\r\n    type: 'function';\r\n  }\r\n}\r\n\r\nexport namespace Threads {\r\n  export import Thread = ThreadsAPI.Thread;\r\n  export import ThreadDeleted = ThreadsAPI.ThreadDeleted;\r\n  export import ThreadCreateParams = ThreadsAPI.ThreadCreateParams;\r\n  export import ThreadUpdateParams = ThreadsAPI.ThreadUpdateParams;\r\n  export import ThreadCreateAndRunParams = ThreadsAPI.ThreadCreateAndRunParams;\r\n  export import Runs = RunsAPI.Runs;\r\n  export import RequiredActionFunctionToolCall = RunsAPI.RequiredActionFunctionToolCall;\r\n  export import Run = RunsAPI.Run;\r\n  export import RunsPage = RunsAPI.RunsPage;\r\n  export import RunCreateParams = RunsAPI.RunCreateParams;\r\n  export import RunUpdateParams = RunsAPI.RunUpdateParams;\r\n  export import RunListParams = RunsAPI.RunListParams;\r\n  export import RunSubmitToolOutputsParams = RunsAPI.RunSubmitToolOutputsParams;\r\n  export import Messages = MessagesAPI.Messages;\r\n  export import MessageContentImageFile = MessagesAPI.MessageContentImageFile;\r\n  export import MessageContentText = MessagesAPI.MessageContentText;\r\n  export import ThreadMessage = MessagesAPI.ThreadMessage;\r\n  export import ThreadMessageDeleted = MessagesAPI.ThreadMessageDeleted;\r\n  export import ThreadMessagesPage = MessagesAPI.ThreadMessagesPage;\r\n  export import MessageCreateParams = MessagesAPI.MessageCreateParams;\r\n  export import MessageUpdateParams = MessagesAPI.MessageUpdateParams;\r\n  export import MessageListParams = MessagesAPI.MessageListParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport { APIResource } from \"../../resource\";\r\nimport * as AssistantsAPI from \"./assistants/assistants\";\r\nimport * as ChatAPI from \"./chat/chat\";\r\nimport * as ThreadsAPI from \"./threads/threads\";\r\n\r\nexport class Beta extends APIResource {\r\n  chat: ChatAPI.Chat = new ChatAPI.Chat(this._client);\r\n  assistants: AssistantsAPI.Assistants = new AssistantsAPI.Assistants(this._client);\r\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\r\n}\r\n\r\nexport namespace Beta {\r\n  export import Chat = ChatAPI.Chat;\r\n  export import Assistants = AssistantsAPI.Assistants;\r\n  export import Assistant = AssistantsAPI.Assistant;\r\n  export import AssistantDeleted = AssistantsAPI.AssistantDeleted;\r\n  export import AssistantsPage = AssistantsAPI.AssistantsPage;\r\n  export import AssistantCreateParams = AssistantsAPI.AssistantCreateParams;\r\n  export import AssistantUpdateParams = AssistantsAPI.AssistantUpdateParams;\r\n  export import AssistantListParams = AssistantsAPI.AssistantListParams;\r\n  export import Threads = ThreadsAPI.Threads;\r\n  export import Thread = ThreadsAPI.Thread;\r\n  export import ThreadDeleted = ThreadsAPI.ThreadDeleted;\r\n  export import ThreadCreateParams = ThreadsAPI.ThreadCreateParams;\r\n  export import ThreadUpdateParams = ThreadsAPI.ThreadUpdateParams;\r\n  export import ThreadCreateAndRunParams = ThreadsAPI.ThreadCreateAndRunParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../core\";\r\nimport { APIPromise } from \"../core\";\r\nimport { APIResource } from \"../resource\";\r\nimport * as CompletionsAPI from \"./completions\";\r\nimport { Stream } from \"../streaming\";\r\n\r\nexport class Completions extends APIResource {\r\n  /**\r\n   * Creates a completion for the provided prompt and parameters.\r\n   */\r\n  create(body: CompletionCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Completion>;\r\n  create(\r\n    body: CompletionCreateParamsStreaming,\r\n    options?: Core.RequestOptions,\r\n  ): APIPromise<Stream<Completion>>;\r\n  create(\r\n    body: CompletionCreateParamsBase,\r\n    options?: Core.RequestOptions,\r\n  ): APIPromise<Stream<Completion> | Completion>;\r\n  create(\r\n    body: CompletionCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\r\n    return this._client.post('/completions', { body, ...options, stream: body.stream ?? false }) as\r\n      | APIPromise<Completion>\r\n      | APIPromise<Stream<Completion>>;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents a completion response from the API. Note: both the streamed and\r\n * non-streamed response objects share the same shape (unlike the chat endpoint).\r\n */\r\nexport interface Completion {\r\n  /**\r\n   * A unique identifier for the completion.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The list of completion choices the model generated for the input prompt.\r\n   */\r\n  choices: Array<CompletionChoice>;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) of when the completion was created.\r\n   */\r\n  created: number;\r\n\r\n  /**\r\n   * The model used for completion.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always \"text_completion\"\r\n   */\r\n  object: 'text_completion';\r\n\r\n  /**\r\n   * This fingerprint represents the backend configuration that the model runs with.\r\n   *\r\n   * Can be used in conjunction with the `seed` request parameter to understand when\r\n   * backend changes have been made that might impact determinism.\r\n   */\r\n  system_fingerprint?: string;\r\n\r\n  /**\r\n   * Usage statistics for the completion request.\r\n   */\r\n  usage?: CompletionUsage;\r\n}\r\n\r\nexport interface CompletionChoice {\r\n  /**\r\n   * The reason the model stopped generating tokens. This will be `stop` if the model\r\n   * hit a natural stop point or a provided stop sequence, `length` if the maximum\r\n   * number of tokens specified in the request was reached, or `content_filter` if\r\n   * content was omitted due to a flag from our content filters.\r\n   */\r\n  finish_reason: 'stop' | 'length' | 'content_filter';\r\n\r\n  index: number;\r\n\r\n  logprobs: CompletionChoice.Logprobs | null;\r\n\r\n  text: string;\r\n}\r\n\r\nexport namespace CompletionChoice {\r\n  export interface Logprobs {\r\n    text_offset?: Array<number>;\r\n\r\n    token_logprobs?: Array<number>;\r\n\r\n    tokens?: Array<string>;\r\n\r\n    top_logprobs?: Array<Record<string, number>>;\r\n  }\r\n}\r\n\r\n/**\r\n * Usage statistics for the completion request.\r\n */\r\nexport interface CompletionUsage {\r\n  /**\r\n   * Number of tokens in the generated completion.\r\n   */\r\n  completion_tokens: number;\r\n\r\n  /**\r\n   * Number of tokens in the prompt.\r\n   */\r\n  prompt_tokens: number;\r\n\r\n  /**\r\n   * Total number of tokens used in the request (prompt + completion).\r\n   */\r\n  total_tokens: number;\r\n}\r\n\r\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\r\n\r\nexport interface CompletionCreateParamsBase {\r\n  /**\r\n   * ID of the model to use. You can use the\r\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\r\n   * see all of your available models, or see our\r\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\r\n   * descriptions of them.\r\n   */\r\n  model: (string & {}) | 'gpt-3.5-turbo-instruct' | 'davinci-002' | 'babbage-002';\r\n\r\n  /**\r\n   * The prompt(s) to generate completions for, encoded as a string, array of\r\n   * strings, array of tokens, or array of token arrays.\r\n   *\r\n   * Note that <|endoftext|> is the document separator that the model sees during\r\n   * training, so if a prompt is not specified the model will generate as if from the\r\n   * beginning of a new document.\r\n   */\r\n  prompt: string | Array<string> | Array<number> | Array<Array<number>> | null;\r\n\r\n  /**\r\n   * Generates `best_of` completions server-side and returns the \"best\" (the one with\r\n   * the highest log probability per token). Results cannot be streamed.\r\n   *\r\n   * When used with `n`, `best_of` controls the number of candidate completions and\r\n   * `n` specifies how many to return â€“ `best_of` must be greater than `n`.\r\n   *\r\n   * **Note:** Because this parameter generates many completions, it can quickly\r\n   * consume your token quota. Use carefully and ensure that you have reasonable\r\n   * settings for `max_tokens` and `stop`.\r\n   */\r\n  best_of?: number | null;\r\n\r\n  /**\r\n   * Echo back the prompt in addition to the completion\r\n   */\r\n  echo?: boolean | null;\r\n\r\n  /**\r\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\r\n   * existing frequency in the text so far, decreasing the model's likelihood to\r\n   * repeat the same line verbatim.\r\n   *\r\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\r\n   */\r\n  frequency_penalty?: number | null;\r\n\r\n  /**\r\n   * Modify the likelihood of specified tokens appearing in the completion.\r\n   *\r\n   * Accepts a JSON object that maps tokens (specified by their token ID in the GPT\r\n   * tokenizer) to an associated bias value from -100 to 100. You can use this\r\n   * [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs.\r\n   * Mathematically, the bias is added to the logits generated by the model prior to\r\n   * sampling. The exact effect will vary per model, but values between -1 and 1\r\n   * should decrease or increase likelihood of selection; values like -100 or 100\r\n   * should result in a ban or exclusive selection of the relevant token.\r\n   *\r\n   * As an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token\r\n   * from being generated.\r\n   */\r\n  logit_bias?: Record<string, number> | null;\r\n\r\n  /**\r\n   * Include the log probabilities on the `logprobs` most likely output tokens, as\r\n   * well the chosen tokens. For example, if `logprobs` is 5, the API will return a\r\n   * list of the 5 most likely tokens. The API will always return the `logprob` of\r\n   * the sampled token, so there may be up to `logprobs+1` elements in the response.\r\n   *\r\n   * The maximum value for `logprobs` is 5.\r\n   */\r\n  logprobs?: number | null;\r\n\r\n  /**\r\n   * The maximum number of [tokens](/tokenizer) that can be generated in the\r\n   * completion.\r\n   *\r\n   * The token count of your prompt plus `max_tokens` cannot exceed the model's\r\n   * context length.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\r\n   * for counting tokens.\r\n   */\r\n  max_tokens?: number | null;\r\n\r\n  /**\r\n   * How many completions to generate for each prompt.\r\n   *\r\n   * **Note:** Because this parameter generates many completions, it can quickly\r\n   * consume your token quota. Use carefully and ensure that you have reasonable\r\n   * settings for `max_tokens` and `stop`.\r\n   */\r\n  n?: number | null;\r\n\r\n  /**\r\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\r\n   * whether they appear in the text so far, increasing the model's likelihood to\r\n   * talk about new topics.\r\n   *\r\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\r\n   */\r\n  presence_penalty?: number | null;\r\n\r\n  /**\r\n   * If specified, our system will make a best effort to sample deterministically,\r\n   * such that repeated requests with the same `seed` and parameters should return\r\n   * the same result.\r\n   *\r\n   * Determinism is not guaranteed, and you should refer to the `system_fingerprint`\r\n   * response parameter to monitor changes in the backend.\r\n   */\r\n  seed?: number | null;\r\n\r\n  /**\r\n   * Up to 4 sequences where the API will stop generating further tokens. The\r\n   * returned text will not contain the stop sequence.\r\n   */\r\n  stop?: string | null | Array<string>;\r\n\r\n  /**\r\n   * Whether to stream back partial progress. If set, tokens will be sent as\r\n   * data-only\r\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\r\n   * as they become available, with the stream terminated by a `data: [DONE]`\r\n   * message.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\r\n   */\r\n  stream?: boolean | null;\r\n\r\n  /**\r\n   * The suffix that comes after a completion of inserted text.\r\n   */\r\n  suffix?: string | null;\r\n\r\n  /**\r\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\r\n   * make the output more random, while lower values like 0.2 will make it more\r\n   * focused and deterministic.\r\n   *\r\n   * We generally recommend altering this or `top_p` but not both.\r\n   */\r\n  temperature?: number | null;\r\n\r\n  /**\r\n   * An alternative to sampling with temperature, called nucleus sampling, where the\r\n   * model considers the results of the tokens with top_p probability mass. So 0.1\r\n   * means only the tokens comprising the top 10% probability mass are considered.\r\n   *\r\n   * We generally recommend altering this or `temperature` but not both.\r\n   */\r\n  top_p?: number | null;\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport namespace CompletionCreateParams {\r\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\r\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\r\n}\r\n\r\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\r\n  /**\r\n   * Whether to stream back partial progress. If set, tokens will be sent as\r\n   * data-only\r\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\r\n   * as they become available, with the stream terminated by a `data: [DONE]`\r\n   * message.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\r\n   */\r\n  stream?: false | null;\r\n}\r\n\r\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\r\n  /**\r\n   * Whether to stream back partial progress. If set, tokens will be sent as\r\n   * data-only\r\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\r\n   * as they become available, with the stream terminated by a `data: [DONE]`\r\n   * message.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\r\n   */\r\n  stream: true;\r\n}\r\n\r\nexport namespace Completions {\r\n  export import Completion = CompletionsAPI.Completion;\r\n  export import CompletionChoice = CompletionsAPI.CompletionChoice;\r\n  export import CompletionUsage = CompletionsAPI.CompletionUsage;\r\n  export import CompletionCreateParams = CompletionsAPI.CompletionCreateParams;\r\n  export import CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\r\n  export import CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../core\";\r\nimport { APIResource } from \"../resource\";\r\nimport * as EmbeddingsAPI from \"./embeddings\";\r\n\r\nexport class Embeddings extends APIResource {\r\n  /**\r\n   * Creates an embedding vector representing the input text.\r\n   */\r\n  create(\r\n    body: EmbeddingCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<CreateEmbeddingResponse> {\r\n    return this._client.post('/embeddings', { body, ...options });\r\n  }\r\n}\r\n\r\nexport interface CreateEmbeddingResponse {\r\n  /**\r\n   * The list of embeddings generated by the model.\r\n   */\r\n  data: Array<Embedding>;\r\n\r\n  /**\r\n   * The name of the model used to generate the embedding.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always \"list\".\r\n   */\r\n  object: 'list';\r\n\r\n  /**\r\n   * The usage information for the request.\r\n   */\r\n  usage: CreateEmbeddingResponse.Usage;\r\n}\r\n\r\nexport namespace CreateEmbeddingResponse {\r\n  /**\r\n   * The usage information for the request.\r\n   */\r\n  export interface Usage {\r\n    /**\r\n     * The number of tokens used by the prompt.\r\n     */\r\n    prompt_tokens: number;\r\n\r\n    /**\r\n     * The total number of tokens used by the request.\r\n     */\r\n    total_tokens: number;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents an embedding vector returned by embedding endpoint.\r\n */\r\nexport interface Embedding {\r\n  /**\r\n   * The embedding vector, which is a list of floats. The length of vector depends on\r\n   * the model as listed in the\r\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\r\n   */\r\n  embedding: Array<number>;\r\n\r\n  /**\r\n   * The index of the embedding in the list of embeddings.\r\n   */\r\n  index: number;\r\n\r\n  /**\r\n   * The object type, which is always \"embedding\".\r\n   */\r\n  object: 'embedding';\r\n}\r\n\r\nexport interface EmbeddingCreateParams {\r\n  /**\r\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\r\n   * inputs in a single request, pass an array of strings or array of token arrays.\r\n   * The input must not exceed the max input tokens for the model (8192 tokens for\r\n   * `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048\r\n   * dimensions or less.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\r\n   * for counting tokens.\r\n   */\r\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\r\n\r\n  /**\r\n   * ID of the model to use. You can use the\r\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\r\n   * see all of your available models, or see our\r\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\r\n   * descriptions of them.\r\n   */\r\n  model: (string & {}) | 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\r\n\r\n  /**\r\n   * The number of dimensions the resulting output embeddings should have. Only\r\n   * supported in `text-embedding-3` and later models.\r\n   */\r\n  dimensions?: number;\r\n\r\n  /**\r\n   * The format to return the embeddings in. Can be either `float` or\r\n   * [`base64`](https://pypi.org/project/pybase64/).\r\n   */\r\n  encoding_format?: 'float' | 'base64';\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport namespace Embeddings {\r\n  export import CreateEmbeddingResponse = EmbeddingsAPI.CreateEmbeddingResponse;\r\n  export import Embedding = EmbeddingsAPI.Embedding;\r\n  export import EmbeddingCreateParams = EmbeddingsAPI.EmbeddingCreateParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../core\";\r\nimport { APIResource } from \"../resource\";\r\nimport { isRequestOptions } from \"../core\";\r\nimport { type Response } from \"../_shims/index\";\r\nimport { sleep } from \"../core\";\r\nimport { APIConnectionTimeoutError } from \"../error\";\r\nimport * as FilesAPI from \"./files\";\r\nimport { type Uploadable, multipartFormRequestOptions } from \"../core\";\r\nimport { Page } from \"../pagination\";\r\n\r\nexport class Files extends APIResource {\r\n  /**\r\n   * Upload a file that can be used across various endpoints. The size of all the\r\n   * files uploaded by one organization can be up to 100 GB.\r\n   *\r\n   * The size of individual files can be a maximum of 512 MB or 2 million tokens for\r\n   * Assistants. See the\r\n   * [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools) to\r\n   * learn more about the types of files supported. The Fine-tuning API only supports\r\n   * `.jsonl` files.\r\n   *\r\n   * Please [contact us](https://help.openai.com/) if you need to increase these\r\n   * storage limits.\r\n   */\r\n  create(body: FileCreateParams, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\r\n    return this._client.post('/files', multipartFormRequestOptions({ body, ...options }));\r\n  }\r\n\r\n  /**\r\n   * Returns information about a specific file.\r\n   */\r\n  retrieve(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\r\n    return this._client.get(`/files/${fileId}`, options);\r\n  }\r\n\r\n  /**\r\n   * Returns a list of files that belong to the user's organization.\r\n   */\r\n  list(query?: FileListParams, options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\r\n  list(options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\r\n  list(\r\n    query: FileListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<FileObjectsPage, FileObject> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list({}, query);\r\n    }\r\n    return this._client.getAPIList('/files', FileObjectsPage, { query, ...options });\r\n  }\r\n\r\n  /**\r\n   * Delete a file.\r\n   */\r\n  del(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileDeleted> {\r\n    return this._client.delete(`/files/${fileId}`, options);\r\n  }\r\n\r\n  /**\r\n   * Returns the contents of the specified file.\r\n   */\r\n  content(fileId: string, options?: Core.RequestOptions): Core.APIPromise<Response> {\r\n    return this._client.get(`/files/${fileId}/content`, { ...options, __binaryResponse: true });\r\n  }\r\n\r\n  /**\r\n   * Returns the contents of the specified file.\r\n   *\r\n   * @deprecated The `.content()` method should be used instead\r\n   */\r\n  retrieveContent(fileId: string, options?: Core.RequestOptions): Core.APIPromise<string> {\r\n    return this._client.get(`/files/${fileId}/content`, {\r\n      ...options,\r\n      headers: { Accept: 'application/json', ...options?.headers },\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Waits for the given file to be processed, default timeout is 30 mins.\r\n   */\r\n  async waitForProcessing(\r\n    id: string,\r\n    { pollInterval = 5000, maxWait = 30 * 60 * 1000 }: { pollInterval?: number; maxWait?: number } = {},\r\n  ): Promise<FileObject> {\r\n    const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\r\n\r\n    const start = Date.now();\r\n    let file = await this.retrieve(id);\r\n\r\n    while (!file.status || !TERMINAL_STATES.has(file.status)) {\r\n      await sleep(pollInterval);\r\n\r\n      file = await this.retrieve(id);\r\n      if (Date.now() - start > maxWait) {\r\n        throw new APIConnectionTimeoutError({\r\n          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\r\n        });\r\n      }\r\n    }\r\n\r\n    return file;\r\n  }\r\n}\r\n\r\n/**\r\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\r\n */\r\nexport class FileObjectsPage extends Page<FileObject> {}\r\n\r\nexport type FileContent = string;\r\n\r\nexport interface FileDeleted {\r\n  id: string;\r\n\r\n  deleted: boolean;\r\n\r\n  object: 'file';\r\n}\r\n\r\n/**\r\n * The `File` object represents a document that has been uploaded to OpenAI.\r\n */\r\nexport interface FileObject {\r\n  /**\r\n   * The file identifier, which can be referenced in the API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The size of the file, in bytes.\r\n   */\r\n  bytes: number;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the file was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * The name of the file.\r\n   */\r\n  filename: string;\r\n\r\n  /**\r\n   * The object type, which is always `file`.\r\n   */\r\n  object: 'file';\r\n\r\n  /**\r\n   * The intended purpose of the file. Supported values are `fine-tune`,\r\n   * `fine-tune-results`, `assistants`, and `assistants_output`.\r\n   */\r\n  purpose: 'fine-tune' | 'fine-tune-results' | 'assistants' | 'assistants_output';\r\n\r\n  /**\r\n   * Deprecated. The current status of the file, which can be either `uploaded`,\r\n   * `processed`, or `error`.\r\n   */\r\n  status: 'uploaded' | 'processed' | 'error';\r\n\r\n  /**\r\n   * Deprecated. For details on why a fine-tuning training file failed validation,\r\n   * see the `error` field on `fine_tuning.job`.\r\n   */\r\n  status_details?: string;\r\n}\r\n\r\nexport interface FileCreateParams {\r\n  /**\r\n   * The File object (not file name) to be uploaded.\r\n   */\r\n  file: Uploadable;\r\n\r\n  /**\r\n   * The intended purpose of the uploaded file.\r\n   *\r\n   * Use \"fine-tune\" for\r\n   * [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning) and\r\n   * \"assistants\" for\r\n   * [Assistants](https://platform.openai.com/docs/api-reference/assistants) and\r\n   * [Messages](https://platform.openai.com/docs/api-reference/messages). This allows\r\n   * us to validate the format of the uploaded file is correct for fine-tuning.\r\n   */\r\n  purpose: 'fine-tune' | 'assistants';\r\n}\r\n\r\nexport interface FileListParams {\r\n  /**\r\n   * Only return files with the given purpose.\r\n   */\r\n  purpose?: string;\r\n}\r\n\r\nexport namespace Files {\r\n  export import FileContent = FilesAPI.FileContent;\r\n  export import FileDeleted = FilesAPI.FileDeleted;\r\n  export import FileObject = FilesAPI.FileObject;\r\n  export import FileObjectsPage = FilesAPI.FileObjectsPage;\r\n  export import FileCreateParams = FilesAPI.FileCreateParams;\r\n  export import FileListParams = FilesAPI.FileListParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../../core\";\r\nimport { APIResource } from \"../../resource\";\r\nimport { isRequestOptions } from \"../../core\";\r\nimport * as JobsAPI from \"./jobs\";\r\nimport { CursorPage, type CursorPageParams } from \"../../pagination\";\r\n\r\nexport class Jobs extends APIResource {\r\n  /**\r\n   * Creates a fine-tuning job which begins the process of creating a new model from\r\n   * a given dataset.\r\n   *\r\n   * Response includes details of the enqueued job including job status and the name\r\n   * of the fine-tuned models once complete.\r\n   *\r\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\r\n   */\r\n  create(body: JobCreateParams, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\r\n    return this._client.post('/fine_tuning/jobs', { body, ...options });\r\n  }\r\n\r\n  /**\r\n   * Get info about a fine-tuning job.\r\n   *\r\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\r\n   */\r\n  retrieve(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\r\n    return this._client.get(`/fine_tuning/jobs/${fineTuningJobId}`, options);\r\n  }\r\n\r\n  /**\r\n   * List your organization's fine-tuning jobs\r\n   */\r\n  list(\r\n    query?: JobListParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\r\n  list(options?: Core.RequestOptions): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\r\n  list(\r\n    query: JobListParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob> {\r\n    if (isRequestOptions(query)) {\r\n      return this.list({}, query);\r\n    }\r\n    return this._client.getAPIList('/fine_tuning/jobs', FineTuningJobsPage, { query, ...options });\r\n  }\r\n\r\n  /**\r\n   * Immediately cancel a fine-tune job.\r\n   */\r\n  cancel(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\r\n    return this._client.post(`/fine_tuning/jobs/${fineTuningJobId}/cancel`, options);\r\n  }\r\n\r\n  /**\r\n   * Get status updates for a fine-tuning job.\r\n   */\r\n  listEvents(\r\n    fineTuningJobId: string,\r\n    query?: JobListEventsParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\r\n  listEvents(\r\n    fineTuningJobId: string,\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\r\n  listEvents(\r\n    fineTuningJobId: string,\r\n    query: JobListEventsParams | Core.RequestOptions = {},\r\n    options?: Core.RequestOptions,\r\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent> {\r\n    if (isRequestOptions(query)) {\r\n      return this.listEvents(fineTuningJobId, {}, query);\r\n    }\r\n    return this._client.getAPIList(`/fine_tuning/jobs/${fineTuningJobId}/events`, FineTuningJobEventsPage, {\r\n      query,\r\n      ...options,\r\n    });\r\n  }\r\n}\r\n\r\nexport class FineTuningJobsPage extends CursorPage<FineTuningJob> {}\r\n\r\nexport class FineTuningJobEventsPage extends CursorPage<FineTuningJobEvent> {}\r\n\r\n/**\r\n * The `fine_tuning.job` object represents a fine-tuning job that has been created\r\n * through the API.\r\n */\r\nexport interface FineTuningJob {\r\n  /**\r\n   * The object identifier, which can be referenced in the API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\r\n   */\r\n  created_at: number;\r\n\r\n  /**\r\n   * For fine-tuning jobs that have `failed`, this will contain more information on\r\n   * the cause of the failure.\r\n   */\r\n  error: FineTuningJob.Error | null;\r\n\r\n  /**\r\n   * The name of the fine-tuned model that is being created. The value will be null\r\n   * if the fine-tuning job is still running.\r\n   */\r\n  fine_tuned_model: string | null;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The\r\n   * value will be null if the fine-tuning job is still running.\r\n   */\r\n  finished_at: number | null;\r\n\r\n  /**\r\n   * The hyperparameters used for the fine-tuning job. See the\r\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\r\n   * more details.\r\n   */\r\n  hyperparameters: FineTuningJob.Hyperparameters;\r\n\r\n  /**\r\n   * The base model that is being fine-tuned.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always \"fine_tuning.job\".\r\n   */\r\n  object: 'fine_tuning.job';\r\n\r\n  /**\r\n   * The organization that owns the fine-tuning job.\r\n   */\r\n  organization_id: string;\r\n\r\n  /**\r\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the\r\n   * results with the\r\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\r\n   */\r\n  result_files: Array<string>;\r\n\r\n  /**\r\n   * The current status of the fine-tuning job, which can be either\r\n   * `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\r\n   */\r\n  status: 'validating_files' | 'queued' | 'running' | 'succeeded' | 'failed' | 'cancelled';\r\n\r\n  /**\r\n   * The total number of billable tokens processed by this fine-tuning job. The value\r\n   * will be null if the fine-tuning job is still running.\r\n   */\r\n  trained_tokens: number | null;\r\n\r\n  /**\r\n   * The file ID used for training. You can retrieve the training data with the\r\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\r\n   */\r\n  training_file: string;\r\n\r\n  /**\r\n   * The file ID used for validation. You can retrieve the validation results with\r\n   * the\r\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\r\n   */\r\n  validation_file: string | null;\r\n}\r\n\r\nexport namespace FineTuningJob {\r\n  /**\r\n   * For fine-tuning jobs that have `failed`, this will contain more information on\r\n   * the cause of the failure.\r\n   */\r\n  export interface Error {\r\n    /**\r\n     * A machine-readable error code.\r\n     */\r\n    code: string;\r\n\r\n    /**\r\n     * A human-readable error message.\r\n     */\r\n    message: string;\r\n\r\n    /**\r\n     * The parameter that was invalid, usually `training_file` or `validation_file`.\r\n     * This field will be null if the failure was not parameter-specific.\r\n     */\r\n    param: string | null;\r\n  }\r\n\r\n  /**\r\n   * The hyperparameters used for the fine-tuning job. See the\r\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\r\n   * more details.\r\n   */\r\n  export interface Hyperparameters {\r\n    /**\r\n     * The number of epochs to train the model for. An epoch refers to one full cycle\r\n     * through the training dataset. \"auto\" decides the optimal number of epochs based\r\n     * on the size of the dataset. If setting the number manually, we support any\r\n     * number between 1 and 50 epochs.\r\n     */\r\n    n_epochs: 'auto' | number;\r\n  }\r\n}\r\n\r\n/**\r\n * Fine-tuning job event object\r\n */\r\nexport interface FineTuningJobEvent {\r\n  id: string;\r\n\r\n  created_at: number;\r\n\r\n  level: 'info' | 'warn' | 'error';\r\n\r\n  message: string;\r\n\r\n  object: 'fine_tuning.job.event';\r\n}\r\n\r\nexport interface JobCreateParams {\r\n  /**\r\n   * The name of the model to fine-tune. You can select one of the\r\n   * [supported models](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned).\r\n   */\r\n  model: (string & {}) | 'babbage-002' | 'davinci-002' | 'gpt-3.5-turbo';\r\n\r\n  /**\r\n   * The ID of an uploaded file that contains training data.\r\n   *\r\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/upload)\r\n   * for how to upload a file.\r\n   *\r\n   * Your dataset must be formatted as a JSONL file. Additionally, you must upload\r\n   * your file with the purpose `fine-tune`.\r\n   *\r\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\r\n   * for more details.\r\n   */\r\n  training_file: string;\r\n\r\n  /**\r\n   * The hyperparameters used for the fine-tuning job.\r\n   */\r\n  hyperparameters?: JobCreateParams.Hyperparameters;\r\n\r\n  /**\r\n   * A string of up to 18 characters that will be added to your fine-tuned model\r\n   * name.\r\n   *\r\n   * For example, a `suffix` of \"custom-model-name\" would produce a model name like\r\n   * `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.\r\n   */\r\n  suffix?: string | null;\r\n\r\n  /**\r\n   * The ID of an uploaded file that contains validation data.\r\n   *\r\n   * If you provide this file, the data is used to generate validation metrics\r\n   * periodically during fine-tuning. These metrics can be viewed in the fine-tuning\r\n   * results file. The same data should not be present in both train and validation\r\n   * files.\r\n   *\r\n   * Your dataset must be formatted as a JSONL file. You must upload your file with\r\n   * the purpose `fine-tune`.\r\n   *\r\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\r\n   * for more details.\r\n   */\r\n  validation_file?: string | null;\r\n}\r\n\r\nexport namespace JobCreateParams {\r\n  /**\r\n   * The hyperparameters used for the fine-tuning job.\r\n   */\r\n  export interface Hyperparameters {\r\n    /**\r\n     * Number of examples in each batch. A larger batch size means that model\r\n     * parameters are updated less frequently, but with lower variance.\r\n     */\r\n    batch_size?: 'auto' | number;\r\n\r\n    /**\r\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\r\n     * avoid overfitting.\r\n     */\r\n    learning_rate_multiplier?: 'auto' | number;\r\n\r\n    /**\r\n     * The number of epochs to train the model for. An epoch refers to one full cycle\r\n     * through the training dataset.\r\n     */\r\n    n_epochs?: 'auto' | number;\r\n  }\r\n}\r\n\r\nexport interface JobListParams extends CursorPageParams {}\r\n\r\nexport interface JobListEventsParams extends CursorPageParams {}\r\n\r\nexport namespace Jobs {\r\n  export import FineTuningJob = JobsAPI.FineTuningJob;\r\n  export import FineTuningJobEvent = JobsAPI.FineTuningJobEvent;\r\n  export import FineTuningJobsPage = JobsAPI.FineTuningJobsPage;\r\n  export import FineTuningJobEventsPage = JobsAPI.FineTuningJobEventsPage;\r\n  export import JobCreateParams = JobsAPI.JobCreateParams;\r\n  export import JobListParams = JobsAPI.JobListParams;\r\n  export import JobListEventsParams = JobsAPI.JobListEventsParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport { APIResource } from \"../../resource\";\r\nimport * as JobsAPI from \"./jobs\";\r\n\r\nexport class FineTuning extends APIResource {\r\n  jobs: JobsAPI.Jobs = new JobsAPI.Jobs(this._client);\r\n}\r\n\r\nexport namespace FineTuning {\r\n  export import Jobs = JobsAPI.Jobs;\r\n  export import FineTuningJob = JobsAPI.FineTuningJob;\r\n  export import FineTuningJobEvent = JobsAPI.FineTuningJobEvent;\r\n  export import FineTuningJobsPage = JobsAPI.FineTuningJobsPage;\r\n  export import FineTuningJobEventsPage = JobsAPI.FineTuningJobEventsPage;\r\n  export import JobCreateParams = JobsAPI.JobCreateParams;\r\n  export import JobListParams = JobsAPI.JobListParams;\r\n  export import JobListEventsParams = JobsAPI.JobListEventsParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../core\";\r\nimport { APIResource } from \"../resource\";\r\nimport * as ImagesAPI from \"./images\";\r\nimport { type Uploadable, multipartFormRequestOptions } from \"../core\";\r\n\r\nexport class Images extends APIResource {\r\n  /**\r\n   * Creates a variation of a given image.\r\n   */\r\n  createVariation(\r\n    body: ImageCreateVariationParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<ImagesResponse> {\r\n    return this._client.post('/images/variations', multipartFormRequestOptions({ body, ...options }));\r\n  }\r\n\r\n  /**\r\n   * Creates an edited or extended image given an original image and a prompt.\r\n   */\r\n  edit(body: ImageEditParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\r\n    return this._client.post('/images/edits', multipartFormRequestOptions({ body, ...options }));\r\n  }\r\n\r\n  /**\r\n   * Creates an image given a prompt.\r\n   */\r\n  generate(body: ImageGenerateParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\r\n    return this._client.post('/images/generations', { body, ...options });\r\n  }\r\n}\r\n\r\n/**\r\n * Represents the url or the content of an image generated by the OpenAI API.\r\n */\r\nexport interface Image {\r\n  /**\r\n   * The base64-encoded JSON of the generated image, if `response_format` is\r\n   * `b64_json`.\r\n   */\r\n  b64_json?: string;\r\n\r\n  /**\r\n   * The prompt that was used to generate the image, if there was any revision to the\r\n   * prompt.\r\n   */\r\n  revised_prompt?: string;\r\n\r\n  /**\r\n   * The URL of the generated image, if `response_format` is `url` (default).\r\n   */\r\n  url?: string;\r\n}\r\n\r\nexport interface ImagesResponse {\r\n  created: number;\r\n\r\n  data: Array<Image>;\r\n}\r\n\r\nexport interface ImageCreateVariationParams {\r\n  /**\r\n   * The image to use as the basis for the variation(s). Must be a valid PNG file,\r\n   * less than 4MB, and square.\r\n   */\r\n  image: Uploadable;\r\n\r\n  /**\r\n   * The model to use for image generation. Only `dall-e-2` is supported at this\r\n   * time.\r\n   */\r\n  model?: (string & {}) | 'dall-e-2' | null;\r\n\r\n  /**\r\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\r\n   * `n=1` is supported.\r\n   */\r\n  n?: number | null;\r\n\r\n  /**\r\n   * The format in which the generated images are returned. Must be one of `url` or\r\n   * `b64_json`.\r\n   */\r\n  response_format?: 'url' | 'b64_json' | null;\r\n\r\n  /**\r\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\r\n   * `1024x1024`.\r\n   */\r\n  size?: '256x256' | '512x512' | '1024x1024' | null;\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport interface ImageEditParams {\r\n  /**\r\n   * The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask\r\n   * is not provided, image must have transparency, which will be used as the mask.\r\n   */\r\n  image: Uploadable;\r\n\r\n  /**\r\n   * A text description of the desired image(s). The maximum length is 1000\r\n   * characters.\r\n   */\r\n  prompt: string;\r\n\r\n  /**\r\n   * An additional image whose fully transparent areas (e.g. where alpha is zero)\r\n   * indicate where `image` should be edited. Must be a valid PNG file, less than\r\n   * 4MB, and have the same dimensions as `image`.\r\n   */\r\n  mask?: Uploadable;\r\n\r\n  /**\r\n   * The model to use for image generation. Only `dall-e-2` is supported at this\r\n   * time.\r\n   */\r\n  model?: (string & {}) | 'dall-e-2' | null;\r\n\r\n  /**\r\n   * The number of images to generate. Must be between 1 and 10.\r\n   */\r\n  n?: number | null;\r\n\r\n  /**\r\n   * The format in which the generated images are returned. Must be one of `url` or\r\n   * `b64_json`.\r\n   */\r\n  response_format?: 'url' | 'b64_json' | null;\r\n\r\n  /**\r\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\r\n   * `1024x1024`.\r\n   */\r\n  size?: '256x256' | '512x512' | '1024x1024' | null;\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport interface ImageGenerateParams {\r\n  /**\r\n   * A text description of the desired image(s). The maximum length is 1000\r\n   * characters for `dall-e-2` and 4000 characters for `dall-e-3`.\r\n   */\r\n  prompt: string;\r\n\r\n  /**\r\n   * The model to use for image generation.\r\n   */\r\n  model?: (string & {}) | 'dall-e-2' | 'dall-e-3' | null;\r\n\r\n  /**\r\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\r\n   * `n=1` is supported.\r\n   */\r\n  n?: number | null;\r\n\r\n  /**\r\n   * The quality of the image that will be generated. `hd` creates images with finer\r\n   * details and greater consistency across the image. This param is only supported\r\n   * for `dall-e-3`.\r\n   */\r\n  quality?: 'standard' | 'hd';\r\n\r\n  /**\r\n   * The format in which the generated images are returned. Must be one of `url` or\r\n   * `b64_json`.\r\n   */\r\n  response_format?: 'url' | 'b64_json' | null;\r\n\r\n  /**\r\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\r\n   * `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or\r\n   * `1024x1792` for `dall-e-3` models.\r\n   */\r\n  size?: '256x256' | '512x512' | '1024x1024' | '1792x1024' | '1024x1792' | null;\r\n\r\n  /**\r\n   * The style of the generated images. Must be one of `vivid` or `natural`. Vivid\r\n   * causes the model to lean towards generating hyper-real and dramatic images.\r\n   * Natural causes the model to produce more natural, less hyper-real looking\r\n   * images. This param is only supported for `dall-e-3`.\r\n   */\r\n  style?: 'vivid' | 'natural' | null;\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport namespace Images {\r\n  export import Image = ImagesAPI.Image;\r\n  export import ImagesResponse = ImagesAPI.ImagesResponse;\r\n  export import ImageCreateVariationParams = ImagesAPI.ImageCreateVariationParams;\r\n  export import ImageEditParams = ImagesAPI.ImageEditParams;\r\n  export import ImageGenerateParams = ImagesAPI.ImageGenerateParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../core\";\r\nimport { APIResource } from \"../resource\";\r\nimport * as ModelsAPI from \"./models\";\r\nimport { Page } from \"../pagination\";\r\n\r\nexport class Models extends APIResource {\r\n  /**\r\n   * Retrieves a model instance, providing basic information about the model such as\r\n   * the owner and permissioning.\r\n   */\r\n  retrieve(model: string, options?: Core.RequestOptions): Core.APIPromise<Model> {\r\n    return this._client.get(`/models/${model}`, options);\r\n  }\r\n\r\n  /**\r\n   * Lists the currently available models, and provides basic information about each\r\n   * one such as the owner and availability.\r\n   */\r\n  list(options?: Core.RequestOptions): Core.PagePromise<ModelsPage, Model> {\r\n    return this._client.getAPIList('/models', ModelsPage, options);\r\n  }\r\n\r\n  /**\r\n   * Delete a fine-tuned model. You must have the Owner role in your organization to\r\n   * delete a model.\r\n   */\r\n  del(model: string, options?: Core.RequestOptions): Core.APIPromise<ModelDeleted> {\r\n    return this._client.delete(`/models/${model}`, options);\r\n  }\r\n}\r\n\r\n/**\r\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\r\n */\r\nexport class ModelsPage extends Page<Model> {}\r\n\r\n/**\r\n * Describes an OpenAI model offering that can be used with the API.\r\n */\r\nexport interface Model {\r\n  /**\r\n   * The model identifier, which can be referenced in the API endpoints.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The Unix timestamp (in seconds) when the model was created.\r\n   */\r\n  created: number;\r\n\r\n  /**\r\n   * The object type, which is always \"model\".\r\n   */\r\n  object: 'model';\r\n\r\n  /**\r\n   * The organization that owns the model.\r\n   */\r\n  owned_by: string;\r\n}\r\n\r\nexport interface ModelDeleted {\r\n  id: string;\r\n\r\n  deleted: boolean;\r\n\r\n  object: string;\r\n}\r\n\r\nexport namespace Models {\r\n  export import Model = ModelsAPI.Model;\r\n  export import ModelDeleted = ModelsAPI.ModelDeleted;\r\n  export import ModelsPage = ModelsAPI.ModelsPage;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from \"../core\";\r\nimport { APIResource } from \"../resource\";\r\nimport * as ModerationsAPI from \"./moderations\";\r\n\r\nexport class Moderations extends APIResource {\r\n  /**\r\n   * Classifies if text violates OpenAI's Content Policy\r\n   */\r\n  create(\r\n    body: ModerationCreateParams,\r\n    options?: Core.RequestOptions,\r\n  ): Core.APIPromise<ModerationCreateResponse> {\r\n    return this._client.post('/moderations', { body, ...options });\r\n  }\r\n}\r\n\r\nexport interface Moderation {\r\n  /**\r\n   * A list of the categories, and whether they are flagged or not.\r\n   */\r\n  categories: Moderation.Categories;\r\n\r\n  /**\r\n   * A list of the categories along with their scores as predicted by model.\r\n   */\r\n  category_scores: Moderation.CategoryScores;\r\n\r\n  /**\r\n   * Whether the content violates\r\n   * [OpenAI's usage policies](/policies/usage-policies).\r\n   */\r\n  flagged: boolean;\r\n}\r\n\r\nexport namespace Moderation {\r\n  /**\r\n   * A list of the categories, and whether they are flagged or not.\r\n   */\r\n  export interface Categories {\r\n    /**\r\n     * Content that expresses, incites, or promotes harassing language towards any\r\n     * target.\r\n     */\r\n    harassment: boolean;\r\n\r\n    /**\r\n     * Harassment content that also includes violence or serious harm towards any\r\n     * target.\r\n     */\r\n    'harassment/threatening': boolean;\r\n\r\n    /**\r\n     * Content that expresses, incites, or promotes hate based on race, gender,\r\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\r\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\r\n     * harassment.\r\n     */\r\n    hate: boolean;\r\n\r\n    /**\r\n     * Hateful content that also includes violence or serious harm towards the targeted\r\n     * group based on race, gender, ethnicity, religion, nationality, sexual\r\n     * orientation, disability status, or caste.\r\n     */\r\n    'hate/threatening': boolean;\r\n\r\n    /**\r\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\r\n     * suicide, cutting, and eating disorders.\r\n     */\r\n    'self-harm': boolean;\r\n\r\n    /**\r\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\r\n     * and eating disorders, or that gives instructions or advice on how to commit such\r\n     * acts.\r\n     */\r\n    'self-harm/instructions': boolean;\r\n\r\n    /**\r\n     * Content where the speaker expresses that they are engaging or intend to engage\r\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\r\n     */\r\n    'self-harm/intent': boolean;\r\n\r\n    /**\r\n     * Content meant to arouse sexual excitement, such as the description of sexual\r\n     * activity, or that promotes sexual services (excluding sex education and\r\n     * wellness).\r\n     */\r\n    sexual: boolean;\r\n\r\n    /**\r\n     * Sexual content that includes an individual who is under 18 years old.\r\n     */\r\n    'sexual/minors': boolean;\r\n\r\n    /**\r\n     * Content that depicts death, violence, or physical injury.\r\n     */\r\n    violence: boolean;\r\n\r\n    /**\r\n     * Content that depicts death, violence, or physical injury in graphic detail.\r\n     */\r\n    'violence/graphic': boolean;\r\n  }\r\n\r\n  /**\r\n   * A list of the categories along with their scores as predicted by model.\r\n   */\r\n  export interface CategoryScores {\r\n    /**\r\n     * The score for the category 'harassment'.\r\n     */\r\n    harassment: number;\r\n\r\n    /**\r\n     * The score for the category 'harassment/threatening'.\r\n     */\r\n    'harassment/threatening': number;\r\n\r\n    /**\r\n     * The score for the category 'hate'.\r\n     */\r\n    hate: number;\r\n\r\n    /**\r\n     * The score for the category 'hate/threatening'.\r\n     */\r\n    'hate/threatening': number;\r\n\r\n    /**\r\n     * The score for the category 'self-harm'.\r\n     */\r\n    'self-harm': number;\r\n\r\n    /**\r\n     * The score for the category 'self-harm/instructions'.\r\n     */\r\n    'self-harm/instructions': number;\r\n\r\n    /**\r\n     * The score for the category 'self-harm/intent'.\r\n     */\r\n    'self-harm/intent': number;\r\n\r\n    /**\r\n     * The score for the category 'sexual'.\r\n     */\r\n    sexual: number;\r\n\r\n    /**\r\n     * The score for the category 'sexual/minors'.\r\n     */\r\n    'sexual/minors': number;\r\n\r\n    /**\r\n     * The score for the category 'violence'.\r\n     */\r\n    violence: number;\r\n\r\n    /**\r\n     * The score for the category 'violence/graphic'.\r\n     */\r\n    'violence/graphic': number;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents policy compliance report by OpenAI's content moderation model against\r\n * a given input.\r\n */\r\nexport interface ModerationCreateResponse {\r\n  /**\r\n   * The unique identifier for the moderation request.\r\n   */\r\n  id: string;\r\n\r\n  /**\r\n   * The model used to generate the moderation results.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * A list of moderation objects.\r\n   */\r\n  results: Array<Moderation>;\r\n}\r\n\r\nexport interface ModerationCreateParams {\r\n  /**\r\n   * The input text to classify\r\n   */\r\n  input: string | Array<string>;\r\n\r\n  /**\r\n   * Two content moderations models are available: `text-moderation-stable` and\r\n   * `text-moderation-latest`.\r\n   *\r\n   * The default is `text-moderation-latest` which will be automatically upgraded\r\n   * over time. This ensures you are always using our most accurate model. If you use\r\n   * `text-moderation-stable`, we will provide advanced notice before updating the\r\n   * model. Accuracy of `text-moderation-stable` may be slightly lower than for\r\n   * `text-moderation-latest`.\r\n   */\r\n  model?: (string & {}) | 'text-moderation-latest' | 'text-moderation-stable';\r\n}\r\n\r\nexport namespace Moderations {\r\n  export import Moderation = ModerationsAPI.Moderation;\r\n  export import ModerationCreateResponse = ModerationsAPI.ModerationCreateResponse;\r\n  export import ModerationCreateParams = ModerationsAPI.ModerationCreateParams;\r\n}\r\n", "// File generated from our OpenAPI spec by Stainless.\r\n\r\nimport * as Core from './core';\r\nimport * as Errors from './error';\r\nimport { type Agent } from './_shims/index';\r\nimport * as Uploads from './uploads';\r\nimport * as Pagination from \"./pagination\";\r\nimport * as API from \"./resources/index\";\r\n\r\nexport interface ClientOptions {\r\n  /**\r\n   * Defaults to process.env['OPENAI_API_KEY'].\r\n   */\r\n  apiKey?: string | undefined;\r\n\r\n  /**\r\n   * Defaults to process.env['OPENAI_ORG_ID'].\r\n   */\r\n  organization?: string | null | undefined;\r\n\r\n  /**\r\n   * Override the default base URL for the API, e.g., \"https://api.example.com/v2/\"\r\n   *\r\n   * Defaults to process.env['OPENAI_BASE_URL'].\r\n   */\r\n  baseURL?: string | null | undefined;\r\n\r\n  /**\r\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\r\n   * from the server before timing out a single request.\r\n   *\r\n   * Note that request timeouts are retried by default, so in a worst-case scenario you may wait\r\n   * much longer than this timeout before the promise succeeds or fails.\r\n   */\r\n  timeout?: number;\r\n\r\n  /**\r\n   * An HTTP agent used to manage HTTP(S) connections.\r\n   *\r\n   * If not provided, an agent will be constructed by default in the Node.js environment,\r\n   * otherwise no agent is used.\r\n   */\r\n  httpAgent?: Agent;\r\n\r\n  /**\r\n   * Specify a custom `fetch` function implementation.\r\n   *\r\n   * If not provided, we use `node-fetch` on Node.js and otherwise expect that `fetch` is\r\n   * defined globally.\r\n   */\r\n  fetch?: Core.Fetch | undefined;\r\n\r\n  /**\r\n   * The maximum number of times that the client will retry a request in case of a\r\n   * temporary failure, like a network error or a 5XX error from the server.\r\n   *\r\n   * @default 2\r\n   */\r\n  maxRetries?: number;\r\n\r\n  /**\r\n   * Default headers to include with every request to the API.\r\n   *\r\n   * These can be removed in individual requests by explicitly setting the\r\n   * header to `undefined` or `null` in request options.\r\n   */\r\n  defaultHeaders?: Core.Headers;\r\n\r\n  /**\r\n   * Default query parameters to include with every request to the API.\r\n   *\r\n   * These can be removed in individual requests by explicitly setting the\r\n   * param to `undefined` in request options.\r\n   */\r\n  defaultQuery?: Core.DefaultQuery;\r\n\r\n  /**\r\n   * By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\r\n   * Only set this option to `true` if you understand the risks and have appropriate mitigations in place.\r\n   */\r\n  dangerouslyAllowBrowser?: boolean;\r\n}\r\n\r\n/** API Client for interfacing with the OpenAI API. */\r\nexport class OpenAI extends Core.APIClient {\r\n  apiKey: string;\r\n  organization: string | null;\r\n\r\n  private _options: ClientOptions;\r\n\r\n  /**\r\n   * API Client for interfacing with the OpenAI API.\r\n   *\r\n   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\r\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\r\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\r\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\r\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\r\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\r\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\r\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\r\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\r\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\r\n   */\r\n  constructor({\r\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\r\n    apiKey = Core.readEnv('OPENAI_API_KEY'),\r\n    organization = Core.readEnv('OPENAI_ORG_ID') ?? null,\r\n    ...opts\r\n  }: ClientOptions = {}) {\r\n    if (apiKey === undefined) {\r\n      throw new Errors.OpenAIError(\r\n        \"The OPENAI_API_KEY environment variable is missing or empty; either provide it, or instantiate the OpenAI client with an apiKey option, like new OpenAI({ apiKey: 'My API Key' }).\",\r\n      );\r\n    }\r\n\r\n    const options: ClientOptions = {\r\n      apiKey,\r\n      organization,\r\n      ...opts,\r\n      baseURL: baseURL || `https://api.openai.com/v1`,\r\n    };\r\n\r\n    if (!options.dangerouslyAllowBrowser && Core.isRunningInBrowser()) {\r\n      throw new Errors.OpenAIError(\r\n        \"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\",\r\n      );\r\n    }\r\n\r\n    super({\r\n      baseURL: options.baseURL!,\r\n      timeout: options.timeout ?? 600000 /* 10 minutes */,\r\n      httpAgent: options.httpAgent,\r\n      maxRetries: options.maxRetries,\r\n      fetch: options.fetch,\r\n    });\r\n    this._options = options;\r\n\r\n    this.apiKey = apiKey;\r\n    this.organization = organization;\r\n  }\r\n\r\n  completions: API.Completions = new API.Completions(this);\r\n  chat: API.Chat = new API.Chat(this);\r\n  embeddings: API.Embeddings = new API.Embeddings(this);\r\n  files: API.Files = new API.Files(this);\r\n  images: API.Images = new API.Images(this);\r\n  audio: API.Audio = new API.Audio(this);\r\n  moderations: API.Moderations = new API.Moderations(this);\r\n  models: API.Models = new API.Models(this);\r\n  fineTuning: API.FineTuning = new API.FineTuning(this);\r\n  beta: API.Beta = new API.Beta(this);\r\n\r\n  protected override defaultQuery(): Core.DefaultQuery | undefined {\r\n    return this._options.defaultQuery;\r\n  }\r\n\r\n  protected override defaultHeaders(opts: Core.FinalRequestOptions): Core.Headers {\r\n    return {\r\n      ...super.defaultHeaders(opts),\r\n      'OpenAI-Organization': this.organization,\r\n      ...this._options.defaultHeaders,\r\n    };\r\n  }\r\n\r\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\r\n    return { Authorization: `Bearer ${this.apiKey}` };\r\n  }\r\n\r\n  static OpenAI = this;\r\n\r\n  static OpenAIError = Errors.OpenAIError;\r\n  static APIError = Errors.APIError;\r\n  static APIConnectionError = Errors.APIConnectionError;\r\n  static APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\r\n  static APIUserAbortError = Errors.APIUserAbortError;\r\n  static NotFoundError = Errors.NotFoundError;\r\n  static ConflictError = Errors.ConflictError;\r\n  static RateLimitError = Errors.RateLimitError;\r\n  static BadRequestError = Errors.BadRequestError;\r\n  static AuthenticationError = Errors.AuthenticationError;\r\n  static InternalServerError = Errors.InternalServerError;\r\n  static PermissionDeniedError = Errors.PermissionDeniedError;\r\n  static UnprocessableEntityError = Errors.UnprocessableEntityError;\r\n}\r\n\r\nexport const {\r\n  OpenAIError,\r\n  APIError,\r\n  APIConnectionError,\r\n  APIConnectionTimeoutError,\r\n  APIUserAbortError,\r\n  NotFoundError,\r\n  ConflictError,\r\n  RateLimitError,\r\n  BadRequestError,\r\n  AuthenticationError,\r\n  InternalServerError,\r\n  PermissionDeniedError,\r\n  UnprocessableEntityError,\r\n} = Errors;\r\n\r\nexport import toFile = Uploads.toFile;\r\nexport import fileFromPath = Uploads.fileFromPath;\r\n\r\nexport namespace OpenAI {\r\n  // Helper functions\r\n  export import toFile = Uploads.toFile;\r\n  export import fileFromPath = Uploads.fileFromPath;\r\n\r\n  export import RequestOptions = Core.RequestOptions;\r\n\r\n  export import Page = Pagination.Page;\r\n  export import PageResponse = Pagination.PageResponse;\r\n\r\n  export import CursorPage = Pagination.CursorPage;\r\n  export import CursorPageParams = Pagination.CursorPageParams;\r\n  export import CursorPageResponse = Pagination.CursorPageResponse;\r\n\r\n  export import Completions = API.Completions;\r\n  export import Completion = API.Completion;\r\n  export import CompletionChoice = API.CompletionChoice;\r\n  export import CompletionUsage = API.CompletionUsage;\r\n  export import CompletionCreateParams = API.CompletionCreateParams;\r\n  export import CompletionCreateParamsNonStreaming = API.CompletionCreateParamsNonStreaming;\r\n  export import CompletionCreateParamsStreaming = API.CompletionCreateParamsStreaming;\r\n\r\n  export import Chat = API.Chat;\r\n  export import ChatCompletion = API.ChatCompletion;\r\n  export import ChatCompletionAssistantMessageParam = API.ChatCompletionAssistantMessageParam;\r\n  export import ChatCompletionChunk = API.ChatCompletionChunk;\r\n  export import ChatCompletionContentPart = API.ChatCompletionContentPart;\r\n  export import ChatCompletionContentPartImage = API.ChatCompletionContentPartImage;\r\n  export import ChatCompletionContentPartText = API.ChatCompletionContentPartText;\r\n  export import ChatCompletionFunctionCallOption = API.ChatCompletionFunctionCallOption;\r\n  export import ChatCompletionFunctionMessageParam = API.ChatCompletionFunctionMessageParam;\r\n  export import ChatCompletionMessage = API.ChatCompletionMessage;\r\n  export import ChatCompletionMessageParam = API.ChatCompletionMessageParam;\r\n  export import ChatCompletionMessageToolCall = API.ChatCompletionMessageToolCall;\r\n  export import ChatCompletionNamedToolChoice = API.ChatCompletionNamedToolChoice;\r\n  export import ChatCompletionRole = API.ChatCompletionRole;\r\n  export import ChatCompletionSystemMessageParam = API.ChatCompletionSystemMessageParam;\r\n  export import ChatCompletionTokenLogprob = API.ChatCompletionTokenLogprob;\r\n  export import ChatCompletionTool = API.ChatCompletionTool;\r\n  export import ChatCompletionToolChoiceOption = API.ChatCompletionToolChoiceOption;\r\n  export import ChatCompletionToolMessageParam = API.ChatCompletionToolMessageParam;\r\n  export import ChatCompletionUserMessageParam = API.ChatCompletionUserMessageParam;\r\n  export import ChatCompletionCreateParams = API.ChatCompletionCreateParams;\r\n  export import ChatCompletionCreateParamsNonStreaming = API.ChatCompletionCreateParamsNonStreaming;\r\n  export import ChatCompletionCreateParamsStreaming = API.ChatCompletionCreateParamsStreaming;\r\n\r\n  export import Embeddings = API.Embeddings;\r\n  export import CreateEmbeddingResponse = API.CreateEmbeddingResponse;\r\n  export import Embedding = API.Embedding;\r\n  export import EmbeddingCreateParams = API.EmbeddingCreateParams;\r\n\r\n  export import Files = API.Files;\r\n  export import FileContent = API.FileContent;\r\n  export import FileDeleted = API.FileDeleted;\r\n  export import FileObject = API.FileObject;\r\n  export import FileObjectsPage = API.FileObjectsPage;\r\n  export import FileCreateParams = API.FileCreateParams;\r\n  export import FileListParams = API.FileListParams;\r\n\r\n  export import Images = API.Images;\r\n  export import Image = API.Image;\r\n  export import ImagesResponse = API.ImagesResponse;\r\n  export import ImageCreateVariationParams = API.ImageCreateVariationParams;\r\n  export import ImageEditParams = API.ImageEditParams;\r\n  export import ImageGenerateParams = API.ImageGenerateParams;\r\n\r\n  export import Audio = API.Audio;\r\n\r\n  export import Moderations = API.Moderations;\r\n  export import Moderation = API.Moderation;\r\n  export import ModerationCreateResponse = API.ModerationCreateResponse;\r\n  export import ModerationCreateParams = API.ModerationCreateParams;\r\n\r\n  export import Models = API.Models;\r\n  export import Model = API.Model;\r\n  export import ModelDeleted = API.ModelDeleted;\r\n  export import ModelsPage = API.ModelsPage;\r\n\r\n  export import FineTuning = API.FineTuning;\r\n\r\n  export import Beta = API.Beta;\r\n\r\n  export import FunctionDefinition = API.FunctionDefinition;\r\n  export import FunctionParameters = API.FunctionParameters;\r\n}\r\n\r\nexport default OpenAI;\r\n"],
  "mappings": ";;;;;AAAO,IAAM,UAAU;;;AC0BhB,IAAI,OAAO;AACX,IAAI,OAAkC;AACtC,IAAIA,SAAoC;AACxC,IAAIC,WAAwC;AAC5C,IAAIC,YAA0C;AAC9C,IAAIC,WAAwC;AAC5C,IAAIC,YAA0C;AAC9C,IAAIC,QAAkC;AACtC,IAAIC,QAAkC;AACtC,IAAIC,kBAAsD;AAC1D,IAAI,6BAA8E;AAClF,IAAI,kBAAwD;AAC5D,IAAI,eAAkD;AACtD,IAAI,iBAAsD;AAE3D,SAAU,SAAS,OAAc,UAA6B,EAAE,MAAM,MAAK,GAAE;AACjF,MAAI,MAAM;AACR,UAAM,IAAI,MACR,mCAAmC,MAAM,IAAI,gDAAgD;;AAGjG,MAAI,MAAM;AACR,UAAM,IAAI,MAAM,gCAAgC,MAAM,IAAI,oCAAoC,IAAI,KAAK;;AAEzG,SAAO,QAAQ;AACf,SAAO,MAAM;AACb,EAAAP,SAAQ,MAAM;AACd,EAAAC,WAAU,MAAM;AAChB,EAAAC,YAAW,MAAM;AACjB,EAAAC,WAAU,MAAM;AAChB,EAAAC,YAAW,MAAM;AACjB,EAAAC,QAAO,MAAM;AACb,EAAAC,QAAO,MAAM;AACb,EAAAC,kBAAiB,MAAM;AACvB,+BAA6B,MAAM;AACnC,oBAAkB,MAAM;AACxB,iBAAe,MAAM;AACrB,mBAAiB,MAAM;AACzB;;;AC7DM,IAAO,gBAAP,MAAoB;EACxB,YAAmB,MAAS;AAAT,SAAA,OAAA;EAAY;EAC/B,KAAK,OAAO,WAAW,IAAC;AACtB,WAAO;EACT;;;;ACAI,SAAU,WAAW,EAAE,iBAAgB,IAAqC,CAAA,GAAE;AAClF,QAAM,iBACJ,mBACE,kCACA;;;;AAKJ,MAAI,QAAQ,UAAU,WAAW;AACjC,MAAI;AAEF,aAAS;AAET,eAAW;AAEX,gBAAY;AAEZ,eAAW;WACJ,OAAO;AACd,UAAM,IAAI,MACR,iEACG,MAAc,OACjB,KAAK,cAAc,EAAE;;AAIzB,SAAO;IACL,MAAM;IACN,OAAO;IACP,SAAS;IACT,UAAU;IACV,SAAS;IACT;;MAEE,OAAO,aAAa,cAAc,WAChC,MAAM,SAAQ;;QAEZ,cAAA;AACE,gBAAM,IAAI,MACR,qFAAqF,cAAc,EAAE;QAEzG;;;IAGN,MACE,OAAO,SAAS,cAAc,OAC5B,MAAM,KAAI;MACR,cAAA;AACE,cAAM,IAAI,MACR,iFAAiF,cAAc,EAAE;MAErG;;IAGN;;MAEE,OAAO,SAAS,cAAc,OAC5B,MAAM,KAAI;;QAER,cAAA;AACE,gBAAM,IAAI,MACR,iFAAiF,cAAc,EAAE;QAErG;;;IAGN;;MAEE,OAAO,mBAAmB,cAAc,iBACtC,MAAM,eAAc;;QAElB,cAAA;AACE,gBAAM,IAAI,MACR,uFAAuF,cAAc,EAAE;QAE3G;;;IAGN,4BAA4B,OAE1B,MACA,UACgC;MAChC,GAAG;MACH,MAAM,IAAI,cAAc,IAAI;;IAE9B,iBAAiB,CAAC,QAAgB;IAClC,cAAc,MAAK;AACjB,YAAM,IAAI,MACR,gJAAgJ;IAEpJ;IACA,gBAAgB,CAAC,UAAe;;AAEpC;;;ACjGA,IAAI,CAAO;AAAM,EAAM,SAAc,WAAW,GAAG,EAAE,MAAM,KAAK,CAAC;;;ACLjE;;;;;;;;;;;;;;;;AAIM,IAAO,cAAP,cAA2B,MAAK;;AAEhC,IAAO,WAAP,MAAO,kBAAiB,YAAW;EASvC,YACE,QACA,OACA,SACA,SAA4B;AAE5B,UAAM,GAAG,UAAS,YAAY,QAAQ,OAAO,OAAO,CAAC,EAAE;AACvD,SAAK,SAAS;AACd,SAAK,UAAU;AAEf,UAAM,OAAO;AACb,SAAK,QAAQ;AACb,SAAK,OAAO,6BAAO;AACnB,SAAK,QAAQ,6BAAO;AACpB,SAAK,OAAO,6BAAO;EACrB;EAEQ,OAAO,YAAY,QAA4B,OAAY,SAA2B;AAC5F,UAAM,OACJ,+BAAO,WACL,OAAO,MAAM,YAAY,WACvB,MAAM,UACN,KAAK,UAAU,MAAM,OAAO,IAC9B,QAAQ,KAAK,UAAU,KAAK,IAC5B;AAEJ,QAAI,UAAU,KAAK;AACjB,aAAO,GAAG,MAAM,IAAI,GAAG;;AAEzB,QAAI,QAAQ;AACV,aAAO,GAAG,MAAM;;AAElB,QAAI,KAAK;AACP,aAAO;;AAET,WAAO;EACT;EAEA,OAAO,SACL,QACA,eACA,SACA,SAA4B;AAE5B,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI,mBAAmB,EAAE,OAAO,YAAY,aAAa,EAAC,CAAE;;AAGrE,UAAM,QAAS,+CAAwC;AAEvD,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,gBAAgB,QAAQ,OAAO,SAAS,OAAO;;AAG5D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,sBAAsB,QAAQ,OAAO,SAAS,OAAO;;AAGlE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,yBAAyB,QAAQ,OAAO,SAAS,OAAO;;AAGrE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,eAAe,QAAQ,OAAO,SAAS,OAAO;;AAG3D,QAAI,UAAU,KAAK;AACjB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,WAAO,IAAI,UAAS,QAAQ,OAAO,SAAS,OAAO;EACrD;;AAGI,IAAO,oBAAP,cAAiC,SAAQ;EAG7C,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,QAAW,QAAW,WAAW,wBAAwB,MAAS;AAHxD,SAAA,SAAoB;EAItC;;AAGI,IAAO,qBAAP,cAAkC,SAAQ;EAG9C,YAAY,EAAE,SAAS,MAAK,GAAmD;AAC7E,UAAM,QAAW,QAAW,WAAW,qBAAqB,MAAS;AAHrD,SAAA,SAAoB;AAMpC,QAAI;AAAO,WAAK,QAAQ;EAC1B;;AAGI,IAAO,4BAAP,cAAyC,mBAAkB;EAC/D,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,EAAE,SAAS,WAAW,qBAAoB,CAAE;EACpD;;AAGI,IAAO,kBAAP,cAA+B,SAAQ;EAA7C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,sBAAP,cAAmC,SAAQ;EAAjD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,wBAAP,cAAqC,SAAQ;EAAnD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,gBAAP,cAA6B,SAAQ;EAA3C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,gBAAP,cAA6B,SAAQ;EAA3C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,2BAAP,cAAwC,SAAQ;EAAtD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,iBAAP,cAA8B,SAAQ;EAA5C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,sBAAP,cAAmC,SAAQ;;;;AC7I3C,IAAO,SAAP,MAAO,QAAM;EAGjB,YACU,UACR,YAA2B;AADnB,SAAA,WAAA;AAGR,SAAK,aAAa;EACpB;EAEA,OAAO,gBAAsB,UAAoB,YAA2B;AAC1E,QAAI,WAAW;AACf,UAAM,UAAU,IAAI,WAAU;AAE9B,oBAAgB,eAAY;AAC1B,UAAI,CAAC,SAAS,MAAM;AAClB,mBAAW,MAAK;AAChB,cAAM,IAAI,YAAY,mDAAmD;;AAG3E,YAAM,cAAc,IAAI,YAAW;AAEnC,YAAM,OAAO,4BAAmC,SAAS,IAAI;AAC7D,uBAAiB,SAAS,MAAM;AAC9B,mBAAW,QAAQ,YAAY,OAAO,KAAK,GAAG;AAC5C,gBAAM,MAAM,QAAQ,OAAO,IAAI;AAC/B,cAAI;AAAK,kBAAM;;;AAInB,iBAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,cAAM,MAAM,QAAQ,OAAO,IAAI;AAC/B,YAAI;AAAK,gBAAM;;IAEnB;AAEA,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,OAAO,aAAY,GAAI;AACtC,cAAI;AAAM;AAEV,cAAI,IAAI,KAAK,WAAW,QAAQ,GAAG;AACjC,mBAAO;AACP;;AAGF,cAAI,IAAI,UAAU,MAAM;AACtB,gBAAI;AAEJ,gBAAI;AACF,qBAAO,KAAK,MAAM,IAAI,IAAI;qBACnB,GAAG;AACV,sBAAQ,MAAM,sCAAsC,IAAI,IAAI;AAC5D,sBAAQ,MAAM,eAAe,IAAI,GAAG;AACpC,oBAAM;;AAGR,gBAAI,QAAQ,KAAK,OAAO;AACtB,oBAAM,IAAI,SAAS,QAAW,KAAK,OAAO,QAAW,MAAS;;AAGhE,kBAAM;;;AAGV,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AAEA,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;;;;;EAMA,OAAO,mBAAyB,gBAAgC,YAA2B;AACzF,QAAI,WAAW;AAEf,oBAAgB,YAAS;AACvB,YAAM,cAAc,IAAI,YAAW;AAEnC,YAAM,OAAO,4BAAmC,cAAc;AAC9D,uBAAiB,SAAS,MAAM;AAC9B,mBAAW,QAAQ,YAAY,OAAO,KAAK,GAAG;AAC5C,gBAAM;;;AAIV,iBAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,cAAM;;IAEV;AAEA,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,QAAQ,UAAS,GAAI;AACpC,cAAI;AAAM;AACV,cAAI;AAAM,kBAAM,KAAK,MAAM,IAAI;;AAEjC,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AAEA,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;EAEA,CAAC,OAAO,aAAa,IAAC;AACpB,WAAO,KAAK,SAAQ;EACtB;;;;;EAMA,MAAG;AACD,UAAM,OAA6C,CAAA;AACnD,UAAM,QAA8C,CAAA;AACpD,UAAM,WAAW,KAAK,SAAQ;AAE9B,UAAM,cAAc,CAAC,UAAoE;AACvF,aAAO;QACL,MAAM,MAAK;AACT,cAAI,MAAM,WAAW,GAAG;AACtB,kBAAM,SAAS,SAAS,KAAI;AAC5B,iBAAK,KAAK,MAAM;AAChB,kBAAM,KAAK,MAAM;;AAEnB,iBAAO,MAAM,MAAK;QACpB;;IAEJ;AAEA,WAAO;MACL,IAAI,QAAO,MAAM,YAAY,IAAI,GAAG,KAAK,UAAU;MACnD,IAAI,QAAO,MAAM,YAAY,KAAK,GAAG,KAAK,UAAU;;EAExD;;;;;;EAOA,mBAAgB;AACd,UAAM,OAAO;AACb,QAAI;AACJ,UAAM,UAAU,IAAI,YAAW;AAE/B,WAAO,IAAIC,gBAAe;MACxB,MAAM,QAAK;AACT,eAAO,KAAK,OAAO,aAAa,EAAC;MACnC;MACA,MAAM,KAAK,MAAI;AACb,YAAI;AACF,gBAAM,EAAE,OAAO,KAAI,IAAK,MAAM,KAAK,KAAI;AACvC,cAAI;AAAM,mBAAO,KAAK,MAAK;AAE3B,gBAAM,QAAQ,QAAQ,OAAO,KAAK,UAAU,KAAK,IAAI,IAAI;AAEzD,eAAK,QAAQ,KAAK;iBACX,KAAK;AACZ,eAAK,MAAM,GAAG;;MAElB;MACA,MAAM,SAAM;;AACV,gBAAMC,MAAA,KAAK,WAAL,gBAAAA,IAAA;MACR;KACD;EACH;;AAGF,IAAM,aAAN,MAAgB;EAKd,cAAA;AACE,SAAK,QAAQ;AACb,SAAK,OAAO,CAAA;AACZ,SAAK,SAAS,CAAA;EAChB;EAEA,OAAO,MAAY;AACjB,QAAI,KAAK,SAAS,IAAI,GAAG;AACvB,aAAO,KAAK,UAAU,GAAG,KAAK,SAAS,CAAC;;AAG1C,QAAI,CAAC,MAAM;AAET,UAAI,CAAC,KAAK,SAAS,CAAC,KAAK,KAAK;AAAQ,eAAO;AAE7C,YAAM,MAAuB;QAC3B,OAAO,KAAK;QACZ,MAAM,KAAK,KAAK,KAAK,IAAI;QACzB,KAAK,KAAK;;AAGZ,WAAK,QAAQ;AACb,WAAK,OAAO,CAAA;AACZ,WAAK,SAAS,CAAA;AAEd,aAAO;;AAGT,SAAK,OAAO,KAAK,IAAI;AAErB,QAAI,KAAK,WAAW,GAAG,GAAG;AACxB,aAAO;;AAGT,QAAI,CAAC,WAAW,GAAG,KAAK,IAAI,UAAU,MAAM,GAAG;AAE/C,QAAI,MAAM,WAAW,GAAG,GAAG;AACzB,cAAQ,MAAM,UAAU,CAAC;;AAG3B,QAAI,cAAc,SAAS;AACzB,WAAK,QAAQ;eACJ,cAAc,QAAQ;AAC/B,WAAK,KAAK,KAAK,KAAK;;AAGtB,WAAO;EACT;;AASF,IAAM,cAAN,MAAM,aAAW;EASf,cAAA;AACE,SAAK,SAAS,CAAA;AACd,SAAK,aAAa;EACpB;EAEA,OAAO,OAAY;AACjB,QAAI,OAAO,KAAK,WAAW,KAAK;AAEhC,QAAI,KAAK,YAAY;AACnB,aAAO,OAAO;AACd,WAAK,aAAa;;AAEpB,QAAI,KAAK,SAAS,IAAI,GAAG;AACvB,WAAK,aAAa;AAClB,aAAO,KAAK,MAAM,GAAG,EAAE;;AAGzB,QAAI,CAAC,MAAM;AACT,aAAO,CAAA;;AAGT,UAAM,kBAAkB,aAAY,cAAc,IAAI,KAAK,KAAK,SAAS,CAAC,KAAK,EAAE;AACjF,QAAI,QAAQ,KAAK,MAAM,aAAY,cAAc;AAEjD,QAAI,MAAM,WAAW,KAAK,CAAC,iBAAiB;AAC1C,WAAK,OAAO,KAAK,MAAM,CAAC,CAAE;AAC1B,aAAO,CAAA;;AAGT,QAAI,KAAK,OAAO,SAAS,GAAG;AAC1B,cAAQ,CAAC,KAAK,OAAO,KAAK,EAAE,IAAI,MAAM,CAAC,GAAG,GAAG,MAAM,MAAM,CAAC,CAAC;AAC3D,WAAK,SAAS,CAAA;;AAGhB,QAAI,CAAC,iBAAiB;AACpB,WAAK,SAAS,CAAC,MAAM,IAAG,KAAM,EAAE;;AAGlC,WAAO;EACT;EAEA,WAAW,OAAY;AACrB,QAAI,SAAS;AAAM,aAAO;AAC1B,QAAI,OAAO,UAAU;AAAU,aAAO;AAGtC,QAAI,OAAO,WAAW,aAAa;AACjC,UAAI,iBAAiB,QAAQ;AAC3B,eAAO,MAAM,SAAQ;;AAEvB,UAAI,iBAAiB,YAAY;AAC/B,eAAO,OAAO,KAAK,KAAK,EAAE,SAAQ;;AAGpC,YAAM,IAAI,YACR,wCAAwC,MAAM,YAAY,IAAI,mIAAmI;;AAKrM,QAAI,OAAO,gBAAgB,aAAa;AACtC,UAAI,iBAAiB,cAAc,iBAAiB,aAAa;AAC/D,aAAK,gBAAL,KAAK,cAAgB,IAAI,YAAY,MAAM;AAC3C,eAAO,KAAK,YAAY,OAAO,KAAK;;AAGtC,YAAM,IAAI,YACR,oDACG,MAAc,YAAY,IAC7B,gDAAgD;;AAIpD,UAAM,IAAI,YACR,gGAAgG;EAEpG;EAEA,QAAK;AACH,QAAI,CAAC,KAAK,OAAO,UAAU,CAAC,KAAK,YAAY;AAC3C,aAAO,CAAA;;AAGT,UAAM,QAAQ,CAAC,KAAK,OAAO,KAAK,EAAE,CAAC;AACnC,SAAK,SAAS,CAAA;AACd,SAAK,aAAa;AAClB,WAAO;EACT;;AA9FO,YAAA,gBAAgB,oBAAI,IAAI,CAAC,MAAM,MAAM,MAAQ,MAAQ,KAAQ,KAAQ,KAAQ,KAAQ,UAAU,QAAQ,CAAC;AACxG,YAAA,iBAAiB;AAgG1B,SAAS,UAAUC,MAAa,WAAiB;AAC/C,QAAM,QAAQA,KAAI,QAAQ,SAAS;AACnC,MAAI,UAAU,IAAI;AAChB,WAAO,CAACA,KAAI,UAAU,GAAG,KAAK,GAAG,WAAWA,KAAI,UAAU,QAAQ,UAAU,MAAM,CAAC;;AAGrF,SAAO,CAACA,MAAK,IAAI,EAAE;AACrB;AAQM,SAAU,4BAA+B,QAAW;AACxD,MAAI,OAAO,OAAO,aAAa;AAAG,WAAO;AAEzC,QAAM,SAAS,OAAO,UAAS;AAC/B,SAAO;IACL,MAAM,OAAI;AACR,UAAI;AACF,cAAM,SAAS,MAAM,OAAO,KAAI;AAChC,YAAI,iCAAQ;AAAM,iBAAO,YAAW;AACpC,eAAO;eACA,GAAG;AACV,eAAO,YAAW;AAClB,cAAM;;IAEV;IACA,MAAM,SAAM;AACV,YAAM,gBAAgB,OAAO,OAAM;AACnC,aAAO,YAAW;AAClB,YAAM;AACN,aAAO,EAAE,MAAM,MAAM,OAAO,OAAS;IACvC;IACA,CAAC,OAAO,aAAa,IAAC;AACpB,aAAO;IACT;;AAEJ;;;AC5VO,IAAM,iBAAiB,CAAC,UAC7B,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,QAAQ,YACrB,OAAO,MAAM,SAAS;AAEjB,IAAM,aAAa,CAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,iBAAiB,YAC9B,WAAW,KAAK;AAMX,IAAM,aAAa,CAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,cACtB,OAAO,MAAM,UAAU,cACvB,OAAO,MAAM,gBAAgB;AAExB,IAAM,eAAe,CAAC,UAAmC;AAC9D,SAAO,WAAW,KAAK,KAAK,eAAe,KAAK,KAAK,eAAe,KAAK;AAC3E;AAaA,eAAsB,OACpB,OACA,MACA,UAAuC,CAAA,GAAE;;AAGzC,UAAQ,MAAM;AAEd,MAAI,eAAe,KAAK,GAAG;AACzB,UAAM,OAAO,MAAM,MAAM,KAAI;AAC7B,aAAA,OAAS,IAAI,IAAI,MAAM,GAAG,EAAE,SAAS,MAAM,OAAO,EAAE,IAAG,KAAM;AAE7D,WAAO,IAAIC,MAAK,CAAC,IAAW,GAAG,MAAM,OAAO;;AAG9C,QAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,WAAA,OAAS,QAAQ,KAAK,KAAK;AAE3B,MAAI,CAAC,QAAQ,MAAM;AACjB,UAAM,QAAQC,MAAA,KAAK,CAAC,MAAN,gBAAAA,IAAiB;AAC/B,QAAI,OAAO,SAAS,UAAU;AAC5B,gBAAU,EAAE,GAAG,SAAS,KAAI;;;AAIhC,SAAO,IAAID,MAAK,MAAM,MAAM,OAAO;AACrC;AAEA,eAAe,SAAS,OAAkB;;AACxC,MAAI,QAAyB,CAAA;AAC7B,MACE,OAAO,UAAU,YACjB,YAAY,OAAO,KAAK;EACxB,iBAAiB,aACjB;AACA,UAAM,KAAK,KAAK;aACP,WAAW,KAAK,GAAG;AAC5B,UAAM,KAAK,MAAM,MAAM,YAAW,CAAE;aAEpC,wBAAwB,KAAK,GAC7B;AACA,qBAAiB,SAAS,OAAO;AAC/B,YAAM,KAAK,KAAiB;;SAEzB;AACL,UAAM,IAAI,MACR,yBAAyB,OAAO,KAAK,mBAAkBC,MAAA,+BAAO,gBAAP,gBAAAA,IACnD,IAAI,YAAY,cAAc,KAAK,CAAC,EAAE;;AAI9C,SAAO;AACT;AAEA,SAAS,cAAc,OAAU;AAC/B,QAAM,QAAQ,OAAO,oBAAoB,KAAK;AAC9C,SAAO,IAAI,MAAM,IAAI,CAAC,MAAM,IAAI,CAAC,GAAG,EAAE,KAAK,IAAI,CAAC;AAClD;AAEA,SAAS,QAAQ,OAAU;;AACzB,SACE,yBAAyB,MAAM,IAAI,KACnC,yBAAyB,MAAM,QAAQ;IAEvCA,MAAA,yBAAyB,MAAM,IAAI,MAAnC,gBAAAA,IAAsC,MAAM,SAAS;AAEzD;AAEA,IAAM,2BAA2B,CAAC,MAAoD;AACpF,MAAI,OAAO,MAAM;AAAU,WAAO;AAClC,MAAI,OAAO,WAAW,eAAe,aAAa;AAAQ,WAAO,OAAO,CAAC;AACzE,SAAO;AACT;AAEA,IAAM,0BAA0B,CAAC,UAC/B,SAAS,QAAQ,OAAO,UAAU,YAAY,OAAO,MAAM,OAAO,aAAa,MAAM;AAEhF,IAAM,kBAAkB,CAAC,SAC9B,QAAQ,OAAO,SAAS,YAAY,KAAK,QAAQ,KAAK,OAAO,WAAW,MAAM;AAezE,IAAM,8BAA8B,OACzC,SAC8C;AAC9C,QAAM,OAAO,MAAM,WAAW,KAAK,IAAI;AACvC,SAAO,2BAA2B,MAAM,IAAI;AAC9C;AAEO,IAAM,aAAa,OAAoC,SAA0C;AACtG,QAAM,OAAO,IAAIC,UAAQ;AACzB,QAAM,QAAQ,IAAI,OAAO,QAAQ,QAAQ,CAAA,CAAE,EAAE,IAAI,CAAC,CAAC,KAAK,KAAK,MAAM,aAAa,MAAM,KAAK,KAAK,CAAC,CAAC;AAClG,SAAO;AACT;AAaA,IAAM,eAAe,OAAO,MAAgB,KAAa,UAAiC;AACxF,MAAI,UAAU;AAAW;AACzB,MAAI,SAAS,MAAM;AACjB,UAAM,IAAI,UACR,sBAAsB,GAAG,6DAA6D;;AAK1F,MAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,SAAK,OAAO,KAAK,OAAO,KAAK,CAAC;aACrB,aAAa,KAAK,GAAG;AAC9B,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,SAAK,OAAO,KAAK,IAAY;aACpB,MAAM,QAAQ,KAAK,GAAG;AAC/B,UAAM,QAAQ,IAAI,MAAM,IAAI,CAAC,UAAU,aAAa,MAAM,MAAM,MAAM,KAAK,CAAC,CAAC;aACpE,OAAO,UAAU,UAAU;AACpC,UAAM,QAAQ,IACZ,OAAO,QAAQ,KAAK,EAAE,IAAI,CAAC,CAAC,MAAM,IAAI,MAAM,aAAa,MAAM,GAAG,GAAG,IAAI,IAAI,KAAK,IAAI,CAAC,CAAC;SAErF;AACL,UAAM,IAAI,UACR,wGAAwG,KAAK,UAAU;;AAG7H;;;;;;;;;;;;;;;;;;;;AC7MA,eAAe,qBAAwB,OAAuB;AAC5D,QAAM,EAAE,SAAQ,IAAK;AACrB,MAAI,MAAM,QAAQ,QAAQ;AACxB,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,SAAS,IAAI;AAKhF,QAAI,MAAM,QAAQ,eAAe;AAC/B,aAAO,MAAM,QAAQ,cAAc,gBAAgB,UAAU,MAAM,UAAU;;AAG/E,WAAO,OAAO,gBAAgB,UAAU,MAAM,UAAU;;AAI1D,MAAI,SAAS,WAAW,KAAK;AAC3B,WAAO;;AAGT,MAAI,MAAM,QAAQ,kBAAkB;AAClC,WAAO;;AAGT,QAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,QAAM,UACJ,2CAAa,SAAS,yBAAuB,2CAAa,SAAS;AACrE,MAAI,QAAQ;AACV,UAAM,OAAO,MAAM,SAAS,KAAI;AAEhC,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAEvE,WAAO;;AAGT,QAAM,OAAO,MAAM,SAAS,KAAI;AAChC,QAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAGvE,SAAO;AACT;AAMM,IAAO,aAAP,MAAO,oBAAsB,QAAU;EAG3C,YACU,iBACA,gBAAgE,sBAAoB;AAE5F,UAAM,CAAC,YAAW;AAIhB,cAAQ,IAAW;IACrB,CAAC;AARO,SAAA,kBAAA;AACA,SAAA,gBAAA;EAQV;EAEA,YAAe,WAAyB;AACtC,WAAO,IAAI,YAAW,KAAK,iBAAiB,OAAO,UAAU,UAAU,MAAM,KAAK,cAAc,KAAK,CAAC,CAAC;EACzG;;;;;;;;;;;;;;EAeA,aAAU;AACR,WAAO,KAAK,gBAAgB,KAAK,CAAC,MAAM,EAAE,QAAQ;EACpD;;;;;;;;;;;;;;EAcA,MAAM,eAAY;AAChB,UAAM,CAAC,MAAM,QAAQ,IAAI,MAAM,QAAQ,IAAI,CAAC,KAAK,MAAK,GAAI,KAAK,WAAU,CAAE,CAAC;AAC5E,WAAO,EAAE,MAAM,SAAQ;EACzB;EAEQ,QAAK;AACX,QAAI,CAAC,KAAK,eAAe;AACvB,WAAK,gBAAgB,KAAK,gBAAgB,KAAK,KAAK,aAAa;;AAEnE,WAAO,KAAK;EACd;EAES,KACP,aACA,YAAmF;AAEnF,WAAO,KAAK,MAAK,EAAG,KAAK,aAAa,UAAU;EAClD;EAES,MACP,YAAiF;AAEjF,WAAO,KAAK,MAAK,EAAG,MAAM,UAAU;EACtC;EAES,QAAQ,WAA2C;AAC1D,WAAO,KAAK,MAAK,EAAG,QAAQ,SAAS;EACvC;;AAGI,IAAgB,YAAhB,MAAyB;EAS7B,YAAY;IACV;IACA,aAAa;IACb,UAAU;;IACV;IACA,OAAO;EAAc,GAOtB;AACC,SAAK,UAAU;AACf,SAAK,aAAa,wBAAwB,cAAc,UAAU;AAClE,SAAK,UAAU,wBAAwB,WAAW,OAAO;AACzD,SAAK,YAAY;AAEjB,SAAK,QAAQ,kBAAkBC;EACjC;EAEU,YAAY,MAAyB;AAC7C,WAAO,CAAA;EACT;;;;;;;;;EAUU,eAAe,MAAyB;AAChD,WAAO;MACL,QAAQ;MACR,gBAAgB;MAChB,cAAc,KAAK,aAAY;MAC/B,GAAG,mBAAkB;MACrB,GAAG,KAAK,YAAY,IAAI;;EAE5B;;;;EAOU,gBAAgB,SAAkB,eAAsB;EAAG;EAE3D,wBAAqB;AAC7B,WAAO,wBAAwB,MAAK,CAAE;EACxC;EAEA,IAAc,MAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAO,MAAM,IAAI;EAC7C;EAEA,KAAe,MAAc,MAA0C;AACrE,WAAO,KAAK,cAAc,QAAQ,MAAM,IAAI;EAC9C;EAEA,MAAgB,MAAc,MAA0C;AACtE,WAAO,KAAK,cAAc,SAAS,MAAM,IAAI;EAC/C;EAEA,IAAc,MAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAO,MAAM,IAAI;EAC7C;EAEA,OAAiB,MAAc,MAA0C;AACvE,WAAO,KAAK,cAAc,UAAU,MAAM,IAAI;EAChD;EAEQ,cACN,QACA,MACA,MAA0C;AAE1C,WAAO,KAAK,QAAQ,QAAQ,QAAQ,IAAI,EAAE,KAAK,CAACC,WAAU,EAAE,QAAQ,MAAM,GAAGA,MAAI,EAAG,CAAC;EACvF;EAEA,WACE,MACAC,OACA,MAA0B;AAE1B,WAAO,KAAK,eAAeA,OAAM,EAAE,QAAQ,OAAO,MAAM,GAAG,KAAI,CAAE;EACnE;EAEQ,uBAAuB,MAAa;AAC1C,QAAI,OAAO,SAAS,UAAU;AAC5B,UAAI,OAAO,WAAW,aAAa;AACjC,eAAO,OAAO,WAAW,MAAM,MAAM,EAAE,SAAQ;;AAGjD,UAAI,OAAO,gBAAgB,aAAa;AACtC,cAAM,UAAU,IAAI,YAAW;AAC/B,cAAM,UAAU,QAAQ,OAAO,IAAI;AACnC,eAAO,QAAQ,OAAO,SAAQ;;;AAIlC,WAAO;EACT;EAEA,aAAkB,SAAiC;;AACjD,UAAM,EAAE,QAAQ,MAAM,OAAO,UAAmB,CAAA,EAAE,IAAK;AAEvD,UAAM,OACJ,gBAAgB,QAAQ,IAAI,IAAI,QAAQ,KAAK,OAC3C,QAAQ,OAAO,KAAK,UAAU,QAAQ,MAAM,MAAM,CAAC,IACnD;AACJ,UAAM,gBAAgB,KAAK,uBAAuB,IAAI;AAEtD,UAAM,MAAM,KAAK,SAAS,MAAO,KAAK;AACtC,QAAI,aAAa;AAAS,8BAAwB,WAAW,QAAQ,OAAO;AAC5E,UAAM,UAAU,QAAQ,WAAW,KAAK;AACxC,UAAM,YAAY,QAAQ,aAAa,KAAK,aAAa,gBAAgB,GAAG;AAC5E,UAAM,kBAAkB,UAAU;AAClC,QACE,SAAQC,MAAA,uCAAmB,YAAnB,gBAAAA,IAA4B,aAAY,YAChD,mBAAoB,UAAkB,QAAQ,WAAW,IACzD;AAKC,gBAAkB,QAAQ,UAAU;;AAGvC,QAAI,KAAK,qBAAqB,WAAW,OAAO;AAC9C,UAAI,CAAC,QAAQ;AAAgB,gBAAQ,iBAAiB,KAAK,sBAAqB;AAChF,cAAQ,KAAK,iBAAiB,IAAI,QAAQ;;AAG5C,UAAM,aAAa,KAAK,aAAa,EAAE,SAAS,SAAS,cAAa,CAAE;AAExE,UAAM,MAAmB;MACvB;MACA,GAAI,QAAQ,EAAE,KAAiB;MAC/B,SAAS;MACT,GAAI,aAAa,EAAE,OAAO,UAAS;;;MAGnC,QAAQ,QAAQ,UAAU;;AAG5B,WAAO,EAAE,KAAK,KAAK,QAAO;EAC5B;EAEQ,aAAa,EACnB,SACA,SACA,cAAa,GAKd;AACC,UAAM,aAAqC,CAAA;AAC3C,QAAI,eAAe;AACjB,iBAAW,gBAAgB,IAAI;;AAGjC,UAAM,iBAAiB,KAAK,eAAe,OAAO;AAClD,oBAAgB,YAAY,cAAc;AAC1C,oBAAgB,YAAY,OAAO;AAGnC,QAAI,gBAAgB,QAAQ,IAAI,KAAK,SAAc,QAAQ;AACzD,aAAO,WAAW,cAAc;;AAGlC,SAAK,gBAAgB,YAAY,OAAO;AAExC,WAAO;EACT;;;;EAKU,MAAM,eAAe,SAA4B;EAAkB;;;;;;;EAQnE,MAAM,eACd,SACA,EAAE,KAAK,QAAO,GAAiD;EAC/C;EAER,aAAa,SAAuC;AAC5D,WACE,CAAC,UAAU,CAAA,IACT,OAAO,YAAY,UACnB,OAAO,YAAY,MAAM,KAAK,OAA6B,EAAE,IAAI,CAAC,WAAW,CAAC,GAAG,MAAM,CAAC,CAAC,IACzF,EAAE,GAAG,QAAO;EAElB;EAEU,gBACR,QACA,OACA,SACA,SAA4B;AAE5B,WAAO,SAAS,SAAS,QAAQ,OAAO,SAAS,OAAO;EAC1D;EAEA,QACE,SACA,mBAAkC,MAAI;AAEtC,WAAO,IAAI,WAAW,KAAK,YAAY,SAAS,gBAAgB,CAAC;EACnE;EAEQ,MAAM,YACZ,cACA,kBAA+B;;AAE/B,UAAM,UAAU,MAAM;AACtB,QAAI,oBAAoB,MAAM;AAC5B,yBAAmB,QAAQ,cAAc,KAAK;;AAGhD,UAAM,KAAK,eAAe,OAAO;AAEjC,UAAM,EAAE,KAAK,KAAK,QAAO,IAAK,KAAK,aAAa,OAAO;AAEvD,UAAM,KAAK,eAAe,KAAK,EAAE,KAAK,QAAO,CAAE;AAE/C,UAAM,WAAW,KAAK,SAAS,IAAI,OAAO;AAE1C,SAAIA,MAAA,QAAQ,WAAR,gBAAAA,IAAgB,SAAS;AAC3B,YAAM,IAAI,kBAAiB;;AAG7B,UAAM,aAAa,IAAI,gBAAe;AACtC,UAAM,WAAW,MAAM,KAAK,iBAAiB,KAAK,KAAK,SAAS,UAAU,EAAE,MAAM,WAAW;AAE7F,QAAI,oBAAoB,OAAO;AAC7B,WAAI,aAAQ,WAAR,mBAAgB,SAAS;AAC3B,cAAM,IAAI,kBAAiB;;AAE7B,UAAI,kBAAkB;AACpB,eAAO,KAAK,aAAa,SAAS,gBAAgB;;AAEpD,UAAI,SAAS,SAAS,cAAc;AAClC,cAAM,IAAI,0BAAyB;;AAErC,YAAM,IAAI,mBAAmB,EAAE,OAAO,SAAQ,CAAE;;AAGlD,UAAM,kBAAkB,sBAAsB,SAAS,OAAO;AAE9D,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI,oBAAoB,KAAK,YAAY,QAAQ,GAAG;AAClD,cAAMC,gBAAe,aAAa,gBAAgB;AAClD,cAAM,oBAAoBA,aAAY,KAAK,SAAS,QAAQ,KAAK,eAAe;AAChF,eAAO,KAAK,aAAa,SAAS,kBAAkB,eAAe;;AAGrE,YAAM,UAAU,MAAM,SAAS,KAAI,EAAG,MAAM,CAAC,MAAM,YAAY,CAAC,EAAE,OAAO;AACzE,YAAM,UAAU,SAAS,OAAO;AAChC,YAAM,aAAa,UAAU,SAAY;AACzC,YAAM,eAAe,mBAAmB,kCAAkC;AAE1E,YAAM,oBAAoB,YAAY,KAAK,SAAS,QAAQ,KAAK,iBAAiB,UAAU;AAE5F,YAAM,MAAM,KAAK,gBAAgB,SAAS,QAAQ,SAAS,YAAY,eAAe;AACtF,YAAM;;AAGR,WAAO,EAAE,UAAU,SAAS,WAAU;EACxC;EAEA,eACEF,OACA,SAA4B;AAE5B,UAAM,UAAU,KAAK,YAAY,SAAS,IAAI;AAC9C,WAAO,IAAI,YAA6B,MAAM,SAASA,KAAI;EAC7D;EAEA,SAAc,MAAc,OAA6B;AACvD,UAAM,MACJ,cAAc,IAAI,IAChB,IAAI,IAAI,IAAI,IACZ,IAAI,IAAI,KAAK,WAAW,KAAK,QAAQ,SAAS,GAAG,KAAK,KAAK,WAAW,GAAG,IAAI,KAAK,MAAM,CAAC,IAAI,KAAK;AAEtG,UAAM,eAAe,KAAK,aAAY;AACtC,QAAI,CAAC,WAAW,YAAY,GAAG;AAC7B,cAAQ,EAAE,GAAG,cAAc,GAAG,MAAK;;AAGrC,QAAI,OAAO,UAAU,YAAY,SAAS,CAAC,MAAM,QAAQ,KAAK,GAAG;AAC/D,UAAI,SAAS,KAAK,eAAe,KAAgC;;AAGnE,WAAO,IAAI,SAAQ;EACrB;EAEU,eAAe,OAA8B;AACrD,WAAO,OAAO,QAAQ,KAAK,EACxB,OAAO,CAAC,CAAC,GAAG,KAAK,MAAM,OAAO,UAAU,WAAW,EACnD,IAAI,CAAC,CAAC,KAAK,KAAK,MAAK;AACpB,UAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,eAAO,GAAG,mBAAmB,GAAG,CAAC,IAAI,mBAAmB,KAAK,CAAC;;AAEhE,UAAI,UAAU,MAAM;AAClB,eAAO,GAAG,mBAAmB,GAAG,CAAC;;AAEnC,YAAM,IAAI,YACR,yBAAyB,OAAO,KAAK,mQAAmQ;IAE5S,CAAC,EACA,KAAK,GAAG;EACb;EAEA,MAAM,iBACJ,KACA,MACA,IACA,YAA2B;AAE3B,UAAM,EAAE,QAAQ,GAAG,QAAO,IAAK,QAAQ,CAAA;AACvC,QAAI;AAAQ,aAAO,iBAAiB,SAAS,MAAM,WAAW,MAAK,CAAE;AAErE,UAAM,UAAU,WAAW,MAAM,WAAW,MAAK,GAAI,EAAE;AAEvD,WACE,KAAK,iBAAgB,EAElB,MAAM,KAAK,QAAW,KAAK,EAAE,QAAQ,WAAW,QAAe,GAAG,QAAO,CAAE,EAC3E,QAAQ,MAAK;AACZ,mBAAa,OAAO;IACtB,CAAC;EAEP;EAEU,mBAAgB;AACxB,WAAO,EAAE,OAAO,KAAK,MAAK;EAC5B;EAEQ,YAAY,UAAkB;AAEpC,UAAM,oBAAoB,SAAS,QAAQ,IAAI,gBAAgB;AAG/D,QAAI,sBAAsB;AAAQ,aAAO;AACzC,QAAI,sBAAsB;AAAS,aAAO;AAG1C,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,UAAU;AAAK,aAAO;AAEnC,WAAO;EACT;EAEQ,MAAM,aACZ,SACA,kBACA,iBAAqC;AAErC,QAAI;AAGJ,UAAM,yBAAyB,mDAAkB;AACjD,QAAI,wBAAwB;AAC1B,YAAM,YAAY,WAAW,sBAAsB;AACnD,UAAI,CAAC,OAAO,MAAM,SAAS,GAAG;AAC5B,wBAAgB;;;AAKpB,UAAM,mBAAmB,mDAAkB;AAC3C,QAAI,oBAAoB,CAAC,eAAe;AACtC,YAAM,iBAAiB,WAAW,gBAAgB;AAClD,UAAI,CAAC,OAAO,MAAM,cAAc,GAAG;AACjC,wBAAgB,iBAAiB;aAC5B;AACL,wBAAgB,KAAK,MAAM,gBAAgB,IAAI,KAAK,IAAG;;;AAM3D,QAAI,EAAE,iBAAiB,KAAK,iBAAiB,gBAAgB,KAAK,MAAO;AACvE,YAAM,aAAa,QAAQ,cAAc,KAAK;AAC9C,sBAAgB,KAAK,mCAAmC,kBAAkB,UAAU;;AAEtF,UAAM,MAAM,aAAa;AAEzB,WAAO,KAAK,YAAY,SAAS,mBAAmB,CAAC;EACvD;EAEQ,mCAAmC,kBAA0B,YAAkB;AACrF,UAAM,oBAAoB;AAC1B,UAAM,gBAAgB;AAEtB,UAAM,aAAa,aAAa;AAGhC,UAAM,eAAe,KAAK,IAAI,oBAAoB,KAAK,IAAI,GAAG,UAAU,GAAG,aAAa;AAGxF,UAAM,SAAS,IAAI,KAAK,OAAM,IAAK;AAEnC,WAAO,eAAe,SAAS;EACjC;EAEQ,eAAY;AAClB,WAAO,GAAG,KAAK,YAAY,IAAI,OAAO,OAAO;EAC/C;;AAKI,IAAgB,eAAhB,MAA4B;EAOhC,YAAY,QAAmB,UAAoB,MAAe,SAA4B;AAN9F,yBAAA,IAAA,MAAA,MAAA;AAOE,2BAAA,MAAI,sBAAW,QAAM,GAAA;AACrB,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,OAAO;EACd;EAUA,cAAW;AACT,UAAM,QAAQ,KAAK,kBAAiB;AACpC,QAAI,CAAC,MAAM;AAAQ,aAAO;AAC1B,WAAO,KAAK,aAAY,KAAM;EAChC;EAEA,MAAM,cAAW;AACf,UAAM,WAAW,KAAK,aAAY;AAClC,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YACR,uFAAuF;;AAG3F,UAAM,cAAc,EAAE,GAAG,KAAK,QAAO;AACrC,QAAI,YAAY,YAAY,OAAO,YAAY,UAAU,UAAU;AACjE,kBAAY,QAAQ,EAAE,GAAG,YAAY,OAAO,GAAG,SAAS,OAAM;eACrD,SAAS,UAAU;AAC5B,YAAM,SAAS,CAAC,GAAG,OAAO,QAAQ,YAAY,SAAS,CAAA,CAAE,GAAG,GAAG,SAAS,IAAI,aAAa,QAAO,CAAE;AAClG,iBAAW,CAAC,KAAK,KAAK,KAAK,QAAQ;AACjC,iBAAS,IAAI,aAAa,IAAI,KAAK,KAAY;;AAEjD,kBAAY,QAAQ;AACpB,kBAAY,OAAO,SAAS,IAAI,SAAQ;;AAE1C,WAAO,MAAM,uBAAA,MAAI,sBAAA,GAAA,EAAS,eAAe,KAAK,aAAoB,WAAW;EAC/E;EAEA,OAAO,YAAS;AAEd,QAAI,OAA2B;AAC/B,UAAM;AACN,WAAO,KAAK,YAAW,GAAI;AACzB,aAAO,MAAM,KAAK,YAAW;AAC7B,YAAM;;EAEV;EAEA,SAAO,uBAAA,oBAAA,QAAA,GAAC,OAAO,cAAa,IAAC;AAC3B,qBAAiB,QAAQ,KAAK,UAAS,GAAI;AACzC,iBAAW,QAAQ,KAAK,kBAAiB,GAAI;AAC3C,cAAM;;;EAGZ;;AAYI,IAAO,cAAP,cAII,WAAqB;EAG7B,YACE,QACA,SACAA,OAA4E;AAE5E,UACE,SACA,OAAO,UAAU,IAAIA,MAAK,QAAQ,MAAM,UAAU,MAAM,qBAAqB,KAAK,GAAG,MAAM,OAAO,CAAC;EAEvG;;;;;;;;EASA,QAAQ,OAAO,aAAa,IAAC;AAC3B,UAAM,OAAO,MAAM;AACnB,qBAAiB,QAAQ,MAAM;AAC7B,YAAM;;EAEV;;AAGK,IAAM,wBAAwB,CACnC,YAC0B;AAC1B,SAAO,IAAI,MACT,OAAO;;IAEL,QAAQ,QAAO;EAAE,GAEnB;IACE,IAAI,QAAQ,MAAI;AACd,YAAM,MAAM,KAAK,SAAQ;AACzB,aAAO,OAAO,IAAI,YAAW,CAAE,KAAK,OAAO,GAAG;IAChD;GACD;AAEL;AA8BA,IAAM,qBAA+C;EACnD,QAAQ;EACR,MAAM;EACN,OAAO;EACP,MAAM;EACN,SAAS;EAET,YAAY;EACZ,QAAQ;EACR,SAAS;EACT,WAAW;EACX,QAAQ;EACR,gBAAgB;EAEhB,kBAAkB;EAClB,eAAe;;AAGV,IAAM,mBAAmB,CAAC,QAAuC;AACtE,SACE,OAAO,QAAQ,YACf,QAAQ,QACR,CAAC,WAAW,GAAG,KACf,OAAO,KAAK,GAAG,EAAE,MAAM,CAAC,MAAM,OAAO,oBAAoB,CAAC,CAAC;AAE/D;AA6BA,IAAM,wBAAwB,MAAyB;AACrD,MAAI,OAAO,SAAS,eAAe,KAAK,SAAS,MAAM;AACrD,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,KAAK,MAAM,EAAE;MACjD,oBAAoB,cAAc,KAAK,MAAM,IAAI;MACjD,uBAAuB;MACvB,+BAA+B,KAAK;;;AAGxC,MAAI,OAAO,gBAAgB,aAAa;AACtC,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB,SAAS,WAAW;MACxC,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,MAAI,OAAO,UAAU,SAAS,KAAK,OAAO,YAAY,cAAc,UAAU,CAAC,MAAM,oBAAoB;AACvG,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,QAAQ,QAAQ;MACpD,oBAAoB,cAAc,QAAQ,IAAI;MAC9C,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,QAAM,cAAc,eAAc;AAClC,MAAI,aAAa;AACf,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB;MACpB,uBAAuB,WAAW,YAAY,OAAO;MACrD,+BAA+B,YAAY;;;AAK/C,SAAO;IACL,oBAAoB;IACpB,+BAA+B;IAC/B,kBAAkB;IAClB,oBAAoB;IACpB,uBAAuB;IACvB,+BAA+B;;AAEnC;AAUA,SAAS,iBAAc;AACrB,MAAI,OAAO,cAAc,eAAe,CAAC,WAAW;AAClD,WAAO;;AAIT,QAAM,kBAAkB;IACtB,EAAE,KAAK,QAAiB,SAAS,uCAAsC;IACvE,EAAE,KAAK,MAAe,SAAS,uCAAsC;IACrE,EAAE,KAAK,MAAe,SAAS,6CAA4C;IAC3E,EAAE,KAAK,UAAmB,SAAS,yCAAwC;IAC3E,EAAE,KAAK,WAAoB,SAAS,0CAAyC;IAC7E,EAAE,KAAK,UAAmB,SAAS,oEAAmE;;AAIxG,aAAW,EAAE,KAAK,QAAO,KAAM,iBAAiB;AAC9C,UAAM,QAAQ,QAAQ,KAAK,UAAU,SAAS;AAC9C,QAAI,OAAO;AACT,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAE1B,aAAO,EAAE,SAAS,KAAK,SAAS,GAAG,KAAK,IAAI,KAAK,IAAI,KAAK,GAAE;;;AAIhE,SAAO;AACT;AAEA,IAAM,gBAAgB,CAAC,SAAsB;AAK3C,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,YAAY,SAAS;AAAO,WAAO;AAChD,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,aAAa,SAAS;AAAS,WAAO;AACnD,MAAI;AAAM,WAAO,SAAS,IAAI;AAC9B,SAAO;AACT;AAEA,IAAM,oBAAoB,CAAC,aAAkC;AAO3D,aAAW,SAAS,YAAW;AAM/B,MAAI,SAAS,SAAS,KAAK;AAAG,WAAO;AACrC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAU,WAAO;AAClC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI;AAAU,WAAO,SAAS,QAAQ;AACtC,SAAO;AACT;AAEA,IAAI;AACJ,IAAM,qBAAqB,MAAK;AAC9B,SAAQ,qBAAA,mBAAqB,sBAAqB;AACpD;AAEO,IAAM,WAAW,CAAC,SAAgB;AACvC,MAAI;AACF,WAAO,KAAK,MAAM,IAAI;WACf,KAAK;AACZ,WAAO;;AAEX;AAGA,IAAM,yBAAyB,IAAI,OAAO,mBAAmB,GAAG;AAChE,IAAM,gBAAgB,CAAC,QAAwB;AAC7C,SAAO,uBAAuB,KAAK,GAAG;AACxC;AAEO,IAAM,QAAQ,CAAC,OAAe,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,EAAE,CAAC;AAErF,IAAM,0BAA0B,CAAC,MAAc,MAAsB;AACnE,MAAI,OAAO,MAAM,YAAY,CAAC,OAAO,UAAU,CAAC,GAAG;AACjD,UAAM,IAAI,YAAY,GAAG,IAAI,qBAAqB;;AAEpD,MAAI,IAAI,GAAG;AACT,UAAM,IAAI,YAAY,GAAG,IAAI,6BAA6B;;AAE5D,SAAO;AACT;AAEO,IAAM,cAAc,CAAC,QAAmB;AAC7C,MAAI,eAAe;AAAO,WAAO;AACjC,SAAO,IAAI,MAAM,GAAG;AACtB;AAcO,IAAM,UAAU,CAAC,QAAmC;;AACzD,MAAI,OAAO,YAAY,aAAa;AAClC,aAAO,MAAAG,MAAA,QAAQ,QAAR,gBAAAA,IAAc,SAAd,mBAAoB,WAAU;;AAEvC,MAAI,OAAO,SAAS,aAAa;AAC/B,YAAO,sBAAK,QAAL,mBAAU,QAAV,4BAAgB,SAAhB,mBAAsB;;AAE/B,SAAO;AACT;AA4CM,SAAU,WAAW,KAA8B;AACvD,MAAI,CAAC;AAAK,WAAO;AACjB,aAAW,MAAM;AAAK,WAAO;AAC7B,SAAO;AACT;AAGM,SAAU,OAAO,KAAa,KAAW;AAC7C,SAAO,OAAO,UAAU,eAAe,KAAK,KAAK,GAAG;AACtD;AAQA,SAAS,gBAAgB,eAAwB,YAAmB;AAClE,aAAW,KAAK,YAAY;AAC1B,QAAI,CAAC,OAAO,YAAY,CAAC;AAAG;AAC5B,UAAM,WAAW,EAAE,YAAW;AAC9B,QAAI,CAAC;AAAU;AAEf,UAAM,MAAM,WAAW,CAAC;AAExB,QAAI,QAAQ,MAAM;AAChB,aAAO,cAAc,QAAQ;eACpB,QAAQ,QAAW;AAC5B,oBAAc,QAAQ,IAAI;;;AAGhC;AAEM,SAAU,MAAM,WAAmB,MAAW;AAClD,MAAI,OAAO,YAAY,eAAe,QAAQ,IAAI,OAAO,MAAM,QAAQ;AACrE,YAAQ,IAAI,gBAAgB,MAAM,IAAI,GAAG,IAAI;;AAEjD;AAKA,IAAM,QAAQ,MAAK;AACjB,SAAO,uCAAuC,QAAQ,SAAS,CAAC,MAAK;AACnE,UAAM,IAAK,KAAK,OAAM,IAAK,KAAM;AACjC,UAAM,IAAI,MAAM,MAAM,IAAK,IAAI,IAAO;AACtC,WAAO,EAAE,SAAS,EAAE;EACtB,CAAC;AACH;AAEO,IAAM,qBAAqB,MAAK;AACrC;;IAEE,OAAO,WAAW;IAElB,OAAO,OAAO,aAAa;IAE3B,OAAO,cAAc;;AAEzB;;;ACjkCM,IAAO,OAAP,cAA0B,aAAkB;EAKhD,YAAY,QAAmB,UAAoB,MAA0B,SAA4B;AACvG,UAAM,QAAQ,UAAU,MAAM,OAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;AACzB,SAAK,SAAS,KAAK;EACrB;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;;;;;;EAOA,iBAAc;AACZ,WAAO;EACT;EAEA,eAAY;AACV,WAAO;EACT;;AAaI,IAAO,aAAP,cACI,aAAkB;EAK1B,YACE,QACA,UACA,MACA,SAA4B;AAE5B,UAAM,QAAQ,UAAU,MAAM,OAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;EAC3B;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;;EAGA,iBAAc;AACZ,UAAM,OAAO,KAAK,aAAY;AAC9B,QAAI,CAAC;AAAM,aAAO;AAClB,QAAI,YAAY;AAAM,aAAO,KAAK;AAClC,UAAM,SAAS,OAAO,YAAY,KAAK,IAAI,YAAY;AACvD,QAAI,CAAC,OAAO,KAAK,MAAM,EAAE;AAAQ,aAAO;AACxC,WAAO;EACT;EAEA,eAAY;AApFd,QAAAC;AAqFI,UAAM,OAAO,KAAK,kBAAiB;AACnC,QAAI,CAAC,KAAK,QAAQ;AAChB,aAAO;;AAGT,UAAM,MAAKA,MAAA,KAAK,KAAK,SAAS,CAAC,MAApB,gBAAAA,IAAuB;AAClC,QAAI,CAAC,IAAI;AACP,aAAO;;AAGT,WAAO,EAAE,QAAQ,EAAE,OAAO,GAAE,EAAE;EAChC;;;;AC5FI,IAAO,cAAP,MAAkB;EAGtB,YAAY,QAAc;AACxB,SAAK,UAAU;EACjB;;;;ACCI,IAAO,cAAP,cAA2B,YAAW;EAgB1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAG,SAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAGlG;;AAs5BF,0BAAiBC,cAAW;AA8B5B,GA9BiB,gBAAA,cAAW,CAAA,EAAA;;;ACl7BtB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EACvF;;CAEA,SAAiBC,OAAI;AACL,EAAAA,MAAA,cAA6B;AA8B7C,GA/BiB,SAAA,OAAI,CAAA,EAAA;;;ACFf,IAAO,SAAP,cAAsB,YAAW;;;;EAIrC,OAAO,MAA0B,SAA6B;AAC5D,WAAO,KAAK,QAAQ,KAAK,iBAAiB,EAAE,MAAM,GAAG,SAAS,kBAAkB,KAAI,CAAE;EACxF;;AAmCF,0BAAiBC,SAAM;AAEvB,GAFiB,WAAA,SAAM,CAAA,EAAA;;;ACzCjB,IAAO,iBAAP,cAA8B,YAAW;;;;EAI7C,OAAO,MAAiC,SAA6B;AACnE,WAAO,KAAK,QAAQ,KAAK,yBAAyB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACrG;;AAyDF,0BAAiBC,iBAAc;AAG/B,GAHiB,mBAAA,iBAAc,CAAA,EAAA;;;AC/DzB,IAAO,eAAP,cAA4B,YAAW;;;;EAI3C,OAAO,MAA+B,SAA6B;AACjE,WAAO,KAAK,QAAQ,KAAK,uBAAuB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACnG;;AA2CF,0BAAiBC,eAAY;AAG7B,GAHiB,iBAAA,eAAY,CAAA,EAAA;;;ACjDvB,IAAO,QAAP,cAAqB,YAAW;EAAtC,cAAA;;AACE,SAAA,iBAAmD,IAAsB,eAAe,KAAK,OAAO;AACpG,SAAA,eAA6C,IAAoB,aAAa,KAAK,OAAO;AAC1F,SAAA,SAA2B,IAAc,OAAO,KAAK,OAAO;EAC9D;;CAEA,SAAiBC,QAAK;AACN,EAAAA,OAAA,iBAAmC;AAGnC,EAAAA,OAAA,eAA+B;AAG/B,EAAAA,OAAA,SAAmB;AAEnC,GATiB,UAAA,QAAK,CAAA,EAAA;;;ACLhB,IAAO,QAAP,cAAqB,YAAW;;;;;;EAMpC,OACE,aACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,WAAW,UAAU;MAC3D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,aACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,eAAe,WAAW,UAAU,MAAM,IAAI;MACpE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;EAcA,KACE,aACA,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,aAAa,CAAA,GAAI,KAAK;;AAEzC,WAAO,KAAK,QAAQ,WAAW,eAAe,WAAW,UAAU,oBAAoB;MACrF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,IACE,aACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,OAAO,eAAe,WAAW,UAAU,MAAM,IAAI;MACvE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,qBAAP,cAAkC,WAAyB;;CAiEjE,SAAiBC,QAAK;AAGN,EAAAA,OAAA,qBAA8B;AAG9C,GANiB,UAAA,QAAK,CAAA,EAAA;;;ACzIhB,IAAO,aAAP,cAA0B,YAAW;EAA3C,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;EAqEzD;;;;EAhEE,OAAO,MAA6B,SAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,eAAe;MACtC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,aAAqB,SAA6B;AACzD,WAAO,KAAK,QAAQ,IAAI,eAAe,WAAW,IAAI;MACpD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,aACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,WAAW,IAAI;MACrD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;EAUA,KACE,QAAmD,CAAA,GACnD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,eAAe,gBAAgB;MAC5D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,aAAqB,SAA6B;AACpD,WAAO,KAAK,QAAQ,OAAO,eAAe,WAAW,IAAI;MACvD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,iBAAP,cAA8B,WAAqB;;CAiRzD,SAAiBC,aAAU;AAGX,EAAAA,YAAA,iBAA+B;AAI/B,EAAAA,YAAA,QAAiB;AAGjB,EAAAA,YAAA,qBAA8B;AAG9C,GAbiB,eAAA,aAAU,CAAA,EAAA;;;ACtRrB,SAAU,4BACd,IAAO;AAEP,SAAO,OAAQ,GAAW,UAAU;AACtC;;;AC1EO,IAAM,qBAAqB,CAChC,YACkD;AAClD,UAAO,mCAAS,UAAS;AAC3B;AAEO,IAAM,oBAAoB,CAC/B,YACiD;AACjD,UAAO,mCAAS,UAAS;AAC3B;AAEO,IAAM,gBAAgB,CAC3B,YAC6C;AAC7C,UAAO,mCAAS,UAAS;AAC3B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAA,IAAM,+BAA+B;AAM/B,IAAgB,+BAAhB,MAA4C;EAuBhD,cAAA;;AApBA,SAAA,aAA8B,IAAI,gBAAe;AAEjD,mDAAA,IAAA,MAAA,MAAA;AACA,0DAAA,IAAA,MAAuC,MAAK;IAAE,CAAC;AAC/C,yDAAA,IAAA,MAAwD,MAAK;IAAE,CAAC;AAEhE,6CAAA,IAAA,MAAA,MAAA;AACA,oDAAA,IAAA,MAAiC,MAAK;IAAE,CAAC;AACzC,mDAAA,IAAA,MAAkD,MAAK;IAAE,CAAC;AAE1D,4CAAA,IAAA,MAA6E,CAAA,CAAE;AAErE,SAAA,mBAAqC,CAAA;AAC/C,SAAA,WAAyC,CAAA;AAEzC,wCAAA,IAAA,MAAS,KAAK;AACd,0CAAA,IAAA,MAAW,KAAK;AAChB,0CAAA,IAAA,MAAW,KAAK;AAChB,yDAAA,IAAA,MAA0B,KAAK;AAkR/B,8CAAA,IAAA,MAAe,CAAC,UAAkB;AAChC,MAAAC,wBAAA,MAAI,uCAAY,MAAI,GAAA;AACpB,UAAI,iBAAiB,SAAS,MAAM,SAAS,cAAc;AACzD,gBAAQ,IAAI,kBAAiB;;AAE/B,UAAI,iBAAiB,mBAAmB;AACtC,QAAAA,wBAAA,MAAI,uCAAY,MAAI,GAAA;AACpB,eAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,UAAI,iBAAiB,aAAa;AAChC,eAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,UAAI,iBAAiB,OAAO;AAC1B,cAAM,cAA2B,IAAI,YAAY,MAAM,OAAO;AAE9D,oBAAY,QAAQ;AACpB,eAAO,KAAK,MAAM,SAAS,WAAW;;AAExC,aAAO,KAAK,MAAM,SAAS,IAAI,YAAY,OAAO,KAAK,CAAC,CAAC;IAC3D,CAAC;AAlSC,IAAAA,wBAAA,MAAI,gDAAqB,IAAI,QAAc,CAAC,SAAS,WAAU;AAC7D,MAAAA,wBAAA,MAAI,uDAA4B,SAAO,GAAA;AACvC,MAAAA,wBAAA,MAAI,sDAA2B,QAAM,GAAA;IACvC,CAAC,GAAC,GAAA;AAEF,IAAAA,wBAAA,MAAI,0CAAe,IAAI,QAAc,CAAC,SAAS,WAAU;AACvD,MAAAA,wBAAA,MAAI,iDAAsB,SAAO,GAAA;AACjC,MAAAA,wBAAA,MAAI,gDAAqB,QAAM,GAAA;IACjC,CAAC,GAAC,GAAA;AAMF,IAAAC,wBAAA,MAAI,gDAAA,GAAA,EAAmB,MAAM,MAAK;IAAE,CAAC;AACrC,IAAAA,wBAAA,MAAI,0CAAA,GAAA,EAAa,MAAM,MAAK;IAAE,CAAC;EACjC;EAEU,KAAK,UAA4B;AAGzC,eAAW,MAAK;AACd,eAAQ,EAAG,KAAK,MAAK;AACnB,aAAK,WAAU;AACf,aAAK,MAAM,KAAK;MAClB,GAAGA,wBAAA,MAAI,2CAAA,GAAA,CAAa;IACtB,GAAG,CAAC;EACN;EAEU,mBAAmB,gBAA8B;;AACzD,SAAK,iBAAiB,KAAK,cAAc;AACzC,SAAK,MAAM,kBAAkB,cAAc;AAC3C,UAAM,WAAUC,MAAA,eAAe,QAAQ,CAAC,MAAxB,gBAAAA,IAA2B;AAC3C,QAAI;AAAS,WAAK,YAAY,OAAqC;AACnE,WAAO;EACT;EAEU,YAAY,SAAqC,OAAO,MAAI;AACpE,QAAI,EAAE,aAAa;AAAU,cAAQ,UAAU;AAE/C,SAAK,SAAS,KAAK,OAAO;AAE1B,QAAI,MAAM;AACR,WAAK,MAAM,WAAW,OAAO;AAC7B,WAAK,kBAAkB,OAAO,KAAK,cAAc,OAAO,MAAM,QAAQ,SAAS;AAE7E,aAAK,MAAM,sBAAsB,QAAQ,OAAiB;iBACjD,mBAAmB,OAAO,KAAK,QAAQ,eAAe;AAC/D,aAAK,MAAM,gBAAgB,QAAQ,aAAa;iBACvC,mBAAmB,OAAO,KAAK,QAAQ,YAAY;AAC5D,mBAAW,aAAa,QAAQ,YAAY;AAC1C,cAAI,UAAU,SAAS,YAAY;AACjC,iBAAK,MAAM,gBAAgB,UAAU,QAAQ;;;;;EAKvD;EAEU,aAAU;AAClB,QAAI,KAAK;AAAO;AAChB,IAAAD,wBAAA,MAAI,uDAAA,GAAA,EAAyB,KAA7B,IAAI;AACJ,SAAK,MAAM,SAAS;EACtB;EAEA,IAAI,QAAK;AACP,WAAOA,wBAAA,MAAI,qCAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,uCAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,uCAAA,GAAA;EACb;EAEA,QAAK;AACH,SAAK,WAAW,MAAK;EACvB;;;;;;;;EASA,GAA+B,OAAc,UAAyC;AACpF,UAAM,YACJA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,SAAQ,CAAE;AAC3B,WAAO;EACT;;;;;;;;EASA,IAAgC,OAAc,UAAyC;AACrF,UAAM,YAAYA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK;AACvC,QAAI,CAAC;AAAW,aAAO;AACvB,UAAM,QAAQ,UAAU,UAAU,CAAC,MAAM,EAAE,aAAa,QAAQ;AAChE,QAAI,SAAS;AAAG,gBAAU,OAAO,OAAO,CAAC;AACzC,WAAO;EACT;;;;;;EAOA,KAAiC,OAAc,UAAyC;AACtF,UAAM,YACJA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,UAAU,MAAM,KAAI,CAAE;AACvC,WAAO;EACT;;;;;;;;;;;;EAaA,QACE,OAAY;AAMZ,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAU;AACrC,MAAAD,wBAAA,MAAI,sDAA2B,MAAI,GAAA;AACnC,UAAI,UAAU;AAAS,aAAK,KAAK,SAAS,MAAM;AAChD,WAAK,KAAK,OAAO,OAAc;IACjC,CAAC;EACH;EAEA,MAAM,OAAI;AACR,IAAAA,wBAAA,MAAI,sDAA2B,MAAI,GAAA;AACnC,UAAMC,wBAAA,MAAI,0CAAA,GAAA;EACZ;;;;;EAMA,MAAM,sBAAmB;AACvB,UAAM,KAAK,KAAI;AACf,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI,CAAC;AAAY,YAAM,IAAI,YAAY,iDAAiD;AACxF,WAAO;EACT;;;;;EAUA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EAiBA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EAoBA,MAAM,oBAAiB;AACrB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;EACb;EAwBA,MAAM,0BAAuB;AAC3B,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;EACb;EAkBA,MAAM,aAAU;AACd,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI;EACb;EAEA,qBAAkB;AAChB,WAAO,CAAC,GAAG,KAAK,gBAAgB;EAClC;EAuBU,MAAkC,UAAiB,MAAoC;AAE/F,QAAIA,wBAAA,MAAI,qCAAA,GAAA,GAAS;AACf;;AAGF,QAAI,UAAU,OAAO;AACnB,MAAAD,wBAAA,MAAI,qCAAU,MAAI,GAAA;AAClB,MAAAC,wBAAA,MAAI,iDAAA,GAAA,EAAmB,KAAvB,IAAI;;AAGN,UAAM,YAA0DA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK;AACrF,QAAI,WAAW;AACb,MAAAA,wBAAA,MAAI,yCAAA,GAAA,EAAY,KAAK,IAAI,UAAU,OAAO,CAAC,MAAM,CAAC,EAAE,IAAI;AACxD,gBAAU,QAAQ,CAAC,EAAE,SAAQ,MAAY,SAAS,GAAG,IAAI,CAAC;;AAG5D,QAAI,UAAU,SAAS;AACrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,sDAAA,GAAA,KAA4B,EAAC,uCAAW,SAAQ;AACvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,sDAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,gDAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;AAChB;;AAGF,QAAI,UAAU,SAAS;AAGrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,sDAAA,GAAA,KAA4B,EAAC,uCAAW,SAAQ;AAOvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,sDAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,gDAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;;EAEpB;EAEU,aAAU;AAClB,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI;AAAY,WAAK,MAAM,uBAAuB,UAAU;AAC5D,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AACzD,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AAEzD,UAAM,oBAAoBA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;AAC9B,QAAI;AAAmB,WAAK,MAAM,qBAAqB,iBAAiB;AAExE,UAAM,0BAA0BA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;AACpC,QAAI,2BAA2B;AAAM,WAAK,MAAM,2BAA2B,uBAAuB;AAElG,QAAI,KAAK,iBAAiB,KAAK,CAAC,MAAM,EAAE,KAAK,GAAG;AAC9C,WAAK,MAAM,cAAcA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI,CAAuB;;EAExD;EAUU,MAAM,sBACd,aACA,QACA,SAA6B;AAE7B,UAAM,SAAS,mCAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,yCAAA,KAAA,4CAAA,EAAgB,KAApB,MAAqB,MAAM;AAE3B,UAAM,iBAAiB,MAAM,YAAY,OACvC,EAAE,GAAG,QAAQ,QAAQ,MAAK,GAC1B,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,WAAO,KAAK,mBAAmB,cAAc;EAC/C;EAEU,MAAM,mBACd,aACA,QACA,SAA6B;AAE7B,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAEjC,WAAO,MAAM,KAAK,sBAAsB,aAAa,QAAQ,OAAO;EACtE;EAEU,MAAM,cACd,aACA,QAGA,SAAuB;;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,gBAAgB,QAAQ,QAAQ,GAAG,WAAU,IAAK;AAC1D,UAAM,uBAAuB,OAAO,kBAAkB,aAAY,+CAAe;AACjF,UAAM,EAAE,qBAAqB,6BAA4B,IAAK,WAAW,CAAA;AAEzE,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,OAAO,WAAW;AAChC,sBAAgB,EAAE,QAAQ,EAAE,SAAS,IAAI,IAAI;;AAG/C,UAAM,YAAmD,OAAO,UAAU,IACxE,CAAC,OAA4C;MAC3C,MAAM,EAAE,QAAQ,EAAE,SAAS;MAC3B,YAAY,EAAE;MACd,aAAa,EAAE;MACf;AAGJ,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,aACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7B,OAAO;AAET,YAAM,WAAUC,MAAA,eAAe,QAAQ,CAAC,MAAxB,gBAAAA,IAA2B;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ;AAAe;AAC5B,YAAM,EAAE,MAAM,WAAW,KAAI,IAAK,QAAQ;AAC1C,YAAM,KAAK,gBAAgB,IAAI;AAC/B,UAAI,CAAC,IAAI;AACP,cAAMC,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,4BAA4B,UACvF,IAAI,CAAC,MAAM,KAAK,UAAU,EAAE,IAAI,CAAC,EACjC,KAAK,IAAI,CAAC;AAEb,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;iBACS,wBAAwB,yBAAyB,MAAM;AAChE,cAAMA,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UACtE,oBAAoB,CACrB;AAED,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;;AAGF,UAAI;AACJ,UAAI;AACF,iBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;eAC3D,OAAO;AACd,aAAK,YAAY;UACf;UACA;UACA,SAAS,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;SAC/D;AACD;;AAIF,YAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,YAAM,UAAUF,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAE5D,WAAK,YAAY,EAAE,MAAM,MAAM,QAAO,CAAE;AAExC,UAAI;AAAsB;;EAE9B;EAEU,MAAM,UACd,aACA,QAGA,SAAuB;;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,cAAc,QAAQ,QAAQ,GAAG,WAAU,IAAK;AACxD,UAAM,uBAAuB,OAAO,gBAAgB,cAAYC,MAAA,2CAAa,aAAb,gBAAAA,IAAuB;AACvF,UAAM,EAAE,qBAAqB,6BAA4B,IAAK,WAAW,CAAA;AAEzE,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,OAAO,OAAO;AAC5B,UAAI,EAAE,SAAS,YAAY;AACzB,wBAAgB,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS,IAAI,IAAI,EAAE;;;AAIrE,UAAM,QACJ,WAAW,SACT,OAAO,MAAM,IAAI,CAAC,MAChB,EAAE,SAAS,aACT;MACE,MAAM;MACN,UAAU;QACR,MAAM,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS;QAC7C,YAAY,EAAE,SAAS;QACvB,aAAa,EAAE,SAAS;;QAG3B,CAAmC,IAEvC;AAEL,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,aACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7B,OAAO;AAET,YAAM,WAAU,oBAAe,QAAQ,CAAC,MAAxB,mBAA2B;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ,YAAY;AACvB;;AAGF,iBAAW,aAAa,QAAQ,YAAY;AAC1C,YAAI,UAAU,SAAS;AAAY;AACnC,cAAM,eAAe,UAAU;AAC/B,cAAM,EAAE,MAAM,WAAW,KAAI,IAAK,UAAU;AAC5C,cAAM,KAAK,gBAAgB,IAAI;AAE/B,YAAI,CAAC,IAAI;AACP,gBAAMC,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,4BAA4B,MACnF,IAAI,CAAC,MAAM,KAAK,UAAU,EAAE,SAAS,IAAI,CAAC,EAC1C,KAAK,IAAI,CAAC;AAEb,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;mBACS,wBAAwB,yBAAyB,MAAM;AAChE,gBAAMA,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UAClE,oBAAoB,CACrB;AAED,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAGF,YAAI;AACJ,YAAI;AACF,mBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;iBAC3D,OAAO;AACd,gBAAMA,WAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACrE,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAIF,cAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,cAAM,UAAUF,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAC5D,aAAK,YAAY,EAAE,MAAM,cAAc,QAAO,CAAE;AAEhD,YAAI,sBAAsB;AACxB;;;;AAKN;EACF;;;AAnaE,SAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI,EAAoB,WAAW;AAC5C,GAAC,gDAAA,SAAAG,iDAAA;AAYC,MAAI,IAAI,KAAK,SAAS;AACtB,SAAO,MAAM,GAAG;AACd,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,GAAG;AAC/B,aAAO,EAAE,GAAG,SAAS,SAAS,QAAQ,WAAW,KAAI;;;AAGzD,QAAM,IAAI,YAAY,4EAA4E;AACpG,GAAC,qDAAA,SAAAC,sDAAA;;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,MAAK,mCAAS,gBAAe;AACzD,aAAO,QAAQ;;AAEjB,QAAI,mBAAmB,OAAO,OAAKH,MAAA,mCAAS,eAAT,gBAAAA,IAAqB,SAAQ;AAC9D,cAAO,aAAQ,WAAW,GAAG,EAAE,MAAxB,mBAA2B;;;AAItC;AACF,GAAC,2DAAA,SAAAI,4DAAA;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,kBAAkB,OAAO,KAAK,QAAQ,WAAW,MAAM;AACzD,aAAO,QAAQ;;AAEjB,QACE,cAAc,OAAO,KACrB,QAAQ,WAAW,QACnB,KAAK,SAAS,KACZ,CAAC,MAAG;;AACF,eAAE,SAAS,iBACXJ,MAAA,EAAE,eAAF,gBAAAA,IAAc,KAAK,CAAC,MAAM,EAAE,SAAS,cAAc,EAAE,OAAO,QAAQ;KAAa,GAErF;AACA,aAAO,QAAQ;;;AAInB;AACF,GAAC,oDAAA,SAAAK,qDAAA;AAQC,QAAM,QAAyB;IAC7B,mBAAmB;IACnB,eAAe;IACf,cAAc;;AAEhB,aAAW,EAAE,MAAK,KAAM,KAAK,kBAAkB;AAC7C,QAAI,OAAO;AACT,YAAM,qBAAqB,MAAM;AACjC,YAAM,iBAAiB,MAAM;AAC7B,YAAM,gBAAgB,MAAM;;;AAGhC,SAAO;AACT,GAAC,+CAAA,SAAAC,8CAkGe,QAAkC;AAChD,MAAI,OAAO,KAAK,QAAQ,OAAO,IAAI,GAAG;AACpC,UAAM,IAAI,YACR,8HAA8H;;AAGpI,GAAC,4DAAA,SAAAC,2DA6N4B,YAAmB;AAC9C,SACE,OAAO,eAAe,WAAW,aAC/B,eAAe,SAAY,cAC3B,KAAK,UAAU,UAAU;AAE/B;;;ACrmBI,IAAO,uBAAP,MAAO,8BAA6B,6BAAwD;;EAEhG,OAAO,aACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,mCAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,aAAa,QAAQ,IAAI,CAAC;AACjE,WAAO;EACT;EAEA,OAAO,SACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,mCAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,aAAa,QAAQ,IAAI,CAAC;AAC7D,WAAO;EACT;EAES,YAAY,SAAmC;AACtD,UAAM,YAAY,OAAO;AACzB,QAAI,mBAAmB,OAAO,KAAK,QAAQ,SAAS;AAClD,WAAK,MAAM,WAAW,QAAQ,OAAiB;;EAEnD;;;;;;;;;;;;;;;;;;;;;;;;;;ACzCI,IAAO,uBAAP,MAAO,8BACH,6BAAwD;EADlE,cAAA;;;AAIE,wDAAA,IAAA,MAAA,MAAA;EA+NF;EA7NE,IAAI,gCAA6B;AAC/B,WAAOC,wBAAA,MAAI,qDAAA,GAAA;EACb;;;;;;;;EASA,OAAO,mBAAmB,QAAsB;AAC9C,UAAM,SAAS,IAAI,sBAAoB;AACvC,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;EAEA,OAAO,qBACL,aACA,QACA,SAA6B;AAE7B,UAAM,SAAS,IAAI,sBAAoB;AACvC,WAAO,KAAK,MACV,OAAO,mBACL,aACA,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAG,SAAS,SAAS,EAAE,GAAG,mCAAS,SAAS,6BAA6B,SAAQ,EAAE,CAAE,CACxF;AAEH,WAAO;EACT;EA4BmB,MAAM,sBACvB,aACA,QACA,SAA6B;;AAE7B,UAAM,SAAS,mCAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AACJ,UAAM,SAAS,MAAM,YAAY,OAC/B,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,SAAIC,MAAA,OAAO,WAAW,WAAlB,gBAAAA,IAA0B,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBD,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAEU,MAAM,oBACd,gBACA,SAA6B;;AAE7B,UAAM,SAAS,mCAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AACJ,SAAK,WAAU;AACf,UAAM,SAAS,OAAO,mBAAwC,gBAAgB,KAAK,UAAU;AAC7F,QAAI;AACJ,qBAAiB,SAAS,QAAQ;AAChC,UAAI,UAAU,WAAW,MAAM,IAAI;AAEjC,aAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;;AAG5C,MAAAA,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;AACpB,eAAS,MAAM;;AAEjB,SAAIC,MAAA,OAAO,WAAW,WAAlB,gBAAAA,IAA0B,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBD,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAqEA,EAAA,sDAAA,oBAAA,QAAA,GAAA,kCAAA,oBAAA,QAAA,GAAA,qCAAA,SAAAE,sCAAA;AAjJE,QAAI,KAAK;AAAO;AAChB,IAAAC,wBAAA,MAAI,qDAAkC,QAAS,GAAA;EACjD,GAAC,iCAAA,SAAAC,gCACS,OAA0B;;AAClC,QAAI,KAAK;AAAO;AAChB,UAAM,aAAaJ,wBAAA,MAAI,iCAAA,KAAA,8CAAA,EAA0B,KAA9B,MAA+B,KAAK;AACvD,SAAK,MAAM,SAAS,OAAO,UAAU;AACrC,UAAM,SAAQ,MAAAC,MAAA,MAAM,QAAQ,CAAC,MAAf,gBAAAA,IAAkB,UAAlB,mBAAyB;AACvC,UAAM,YAAW,gBAAW,QAAQ,CAAC,MAApB,mBAAuB;AACxC,QAAI,SAAS,SAAQ,qCAAU,UAAS,gBAAe,qCAAU,UAAS;AACxE,WAAK,MAAM,WAAW,OAAO,SAAS,OAAO;;EAEjD,GAAC,mCAAA,SAAAI,oCAAA;AAEC,QAAI,KAAK,OAAO;AACd,YAAM,IAAI,YAAY,yCAAyC;;AAEjE,UAAM,WAAWL,wBAAA,MAAI,qDAAA,GAAA;AACrB,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YAAY,0CAA0C;;AAElE,IAAAG,wBAAA,MAAI,qDAAkC,QAAS,GAAA;AAC/C,WAAO,uBAAuB,QAAQ;EACxC,GAAC,iDAAA,SAAAG,gDAuDyB,OAA0B;;AAClD,QAAI,WAAWN,wBAAA,MAAI,qDAAA,GAAA;AACnB,UAAM,EAAE,SAAS,GAAG,KAAI,IAAK;AAC7B,QAAI,CAAC,UAAU;AACb,iBAAWG,wBAAA,MAAI,qDAAkC;QAC/C,GAAG;QACH,SAAS,CAAA;SACV,GAAA;WACI;AACL,aAAO,OAAO,UAAU,IAAI;;AAG9B,eAAW,EAAE,OAAO,eAAe,OAAO,WAAW,MAAM,GAAG,MAAK,KAAM,MAAM,SAAS;AACtF,UAAI,SAAS,SAAS,QAAQ,KAAK;AACnC,UAAI,CAAC,QAAQ;AACX,iBAAS,SAAS,QAAQ,KAAK,IAAI,EAAE,eAAe,OAAO,SAAS,CAAA,GAAI,UAAU,GAAG,MAAK;;AAG5F,UAAI,UAAU;AACZ,YAAI,CAAC,OAAO,UAAU;AACpB,iBAAO,WAAW,OAAO,OAAO,CAAA,GAAI,QAAQ;eACvC;AACL,gBAAM,EAAE,SAAAI,UAAS,GAAGC,MAAI,IAAK;AAC7B,iBAAO,OAAO,OAAO,UAAUA,KAAI;AACnC,cAAID,UAAS;AACX,aAAAN,MAAA,OAAO,UAAS,YAAOA,IAAP,UAAY,CAAA;AAC5B,mBAAO,SAAS,QAAQ,KAAK,GAAGM,QAAO;;;;AAK7C,UAAI;AAAe,eAAO,gBAAgB;AAC1C,aAAO,OAAO,QAAQ,KAAK;AAE3B,UAAI,CAAC;AAAO;AACZ,YAAM,EAAE,SAAS,eAAe,MAAM,YAAY,GAAGC,MAAI,IAAK;AAC9D,aAAO,OAAO,OAAO,SAASA,KAAI;AAElC,UAAI;AAAS,eAAO,QAAQ,WAAW,OAAO,QAAQ,WAAW,MAAM;AACvE,UAAI;AAAM,eAAO,QAAQ,OAAO;AAChC,UAAI,eAAe;AACjB,YAAI,CAAC,OAAO,QAAQ,eAAe;AACjC,iBAAO,QAAQ,gBAAgB;eAC1B;AACL,cAAI,cAAc;AAAM,mBAAO,QAAQ,cAAc,OAAO,cAAc;AAC1E,cAAI,cAAc,WAAW;AAC3B,aAAA,KAAA,OAAO,QAAQ,eAAc,cAAS,GAAT,YAAc;AAC3C,mBAAO,QAAQ,cAAc,aAAa,cAAc;;;;AAI9D,UAAI,YAAY;AACd,YAAI,CAAC,OAAO,QAAQ;AAAY,iBAAO,QAAQ,aAAa,CAAA;AAC5D,mBAAW,EAAE,OAAAC,QAAO,IAAI,MAAM,UAAU,IAAI,GAAGD,MAAI,KAAM,YAAY;AACnE,gBAAM,aAAY,KAAC,OAAO,QAAQ,YAAWC,MAAK,MAAA,GAALA,MAAK,IAAM,CAAA;AACxD,iBAAO,OAAO,WAAWD,KAAI;AAC7B,cAAI;AAAI,sBAAU,KAAK;AACvB,cAAI;AAAM,sBAAU,OAAO;AAC3B,cAAI;AAAI,sBAAU,aAAV,UAAU,WAAa,EAAE,WAAW,GAAE;AAC9C,cAAI,yBAAI;AAAM,sBAAU,SAAU,OAAO,GAAG;AAC5C,cAAI,yBAAI;AAAW,sBAAU,SAAU,aAAa,GAAG;;;;AAI7D,WAAO;EACT,GAEC,OAAO,cAAa,IAAC;AACpB,UAAM,YAAmC,CAAA;AACzC,UAAM,YAAkE,CAAA;AACxE,QAAI,OAAO;AAEX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,KAAK;aACP;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,MAAS;;AAElB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,YAAyD;AAC7D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAAyC,CAAC,YAAY,UAAU,KAAK,OAAO,CAAC,EAAE,KACxF,CAACE,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAGzF,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC;;EAEJ;EAEA,mBAAgB;AACd,UAAM,SAAS,IAAI,OAAO,KAAK,OAAO,aAAa,EAAE,KAAK,IAAI,GAAG,KAAK,UAAU;AAChF,WAAO,OAAO,iBAAgB;EAChC;;AAGF,SAAS,uBAAuB,UAAgC;AAC9D,QAAM,EAAE,IAAI,SAAS,SAAS,OAAO,oBAAoB,GAAG,KAAI,IAAK;AACrE,SAAO;IACL,GAAG;IACH;IACA,SAAS,QAAQ,IACf,CAAC,EAAE,SAAS,eAAe,OAAO,UAAU,GAAG,WAAU,MAA6B;AACpF,UAAI,CAAC;AAAe,cAAM,IAAI,YAAY,oCAAoC,KAAK,EAAE;AACrF,YAAM,EAAE,UAAU,MAAM,eAAe,YAAY,GAAG,YAAW,IAAK;AACtE,YAAM,OAAO,QAAQ;AACrB,UAAI,CAAC;AAAM,cAAM,IAAI,YAAY,2BAA2B,KAAK,EAAE;AACnE,UAAI,eAAe;AACjB,cAAM,EAAE,WAAW,MAAM,KAAI,IAAK;AAClC,YAAI,QAAQ;AAAM,gBAAM,IAAI,YAAY,8CAA8C,KAAK,EAAE;AAC7F,YAAI,CAAC;AAAM,gBAAM,IAAI,YAAY,yCAAyC,KAAK,EAAE;AACjF,eAAO;UACL,GAAG;UACH,SAAS,EAAE,SAAS,eAAe,EAAE,WAAW,MAAM,KAAI,GAAI,KAAI;UAClE;UACA;UACA;;;AAGJ,UAAI,YAAY;AACd,eAAO;UACL,GAAG;UACH;UACA;UACA;UACA,SAAS;YACP,GAAG;YACH;YACA;YACA,YAAY,WAAW,IAAI,CAAC,WAAW,MAAK;AAC1C,oBAAM,EAAE,UAAU,IAAI,MAAM,IAAAC,KAAI,GAAG,SAAQ,IAAK;AAChD,oBAAM,EAAE,WAAW,MAAM,MAAM,GAAG,OAAM,IAAK,MAAM,CAAA;AACnD,kBAAIA,OAAM;AACR,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAS,IAAI,QAAQ,CAAC,EAAE;AACzF,kBAAI,QAAQ;AACV,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAW,IAAI,QAAQ,CAAC,EAAE;AAC3F,kBAAI,QAAQ;AACV,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAoB,IAAI,QAAQ,CAAC,EAAE;AAEhF,kBAAI,QAAQ;AACV,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAyB,IAAI,QAAQ,CAAC,EAAE;AAGrF,qBAAO,EAAE,GAAG,UAAU,IAAAA,KAAI,MAAM,UAAU,EAAE,GAAG,QAAQ,MAAM,WAAW,KAAI,EAAE;YAChF,CAAC;;;;AAIP,aAAO;QACL,GAAG;QACH,SAAS,EAAE,GAAG,aAAa,SAAS,KAAI;QACxC;QACA;QACA;;IAEJ,CAAC;IAEH;IACA;IACA,QAAQ;IACR,GAAI,qBAAqB,EAAE,mBAAkB,IAAK,CAAA;;AAEtD;AAEA,SAAS,IAAI,GAAU;AACrB,SAAO,KAAK,UAAU,CAAC;AACzB;;;ACzSM,IAAO,gCAAP,MAAO,uCACH,qBAAoB;EAG5B,OAAgB,mBAAmB,QAAsB;AACvD,UAAM,SAAS,IAAI,+BAA6B;AAChD,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;;EAGA,OAAO,aACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,+BAA6B;AAChD,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,mCAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,aAAa,QAAQ,IAAI,CAAC;AACjE,WAAO;EACT;EAEA,OAAO,SACL,aACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,+BAA6B;AAChD,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,mCAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,aAAa,QAAQ,IAAI,CAAC;AAC7D,WAAO;EACT;;;;ACpCI,IAAOC,eAAP,cAA2B,YAAW;EAY1C,aACE,MAGA,SAA6B;AAE7B,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,aACnC,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;;AAGX,WAAO,qBAAqB,aAC1B,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;EAEX;EAmBA,SACE,MAGA,SAA6B;AAE7B,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,SACnC,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;;AAGX,WAAO,qBAAqB,SAC1B,KAAK,QAAQ,KAAK,aAClB,MACA,OAAO;EAEX;;;;EAKA,OAAO,MAAkC,SAA6B;AACpE,WAAO,qBAAqB,qBAAqB,KAAK,QAAQ,KAAK,aAAa,MAAM,OAAO;EAC/F;;;;ACnGI,IAAOC,QAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmBC,aAAY,KAAK,OAAO;EACvF;;CAEA,SAAiBD,OAAI;AACL,EAAAA,MAAA,cAA6BC;AAC7C,GAFiBD,UAAAA,QAAI,CAAA,EAAA;;;ACDf,IAAOE,SAAP,cAAqB,YAAW;;;;EAIpC,SACE,UACA,WACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,aAAa,SAAS,UAAU,MAAM,IAAI;MACpF,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;EAgBA,KACE,UACA,WACA,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,WAAW,CAAA,GAAI,KAAK;;AAEjD,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,aAAa,SAAS,UAAU,kBAAkB;MACnG;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,mBAAP,cAAgC,WAAuB;;CA6C7D,SAAiBA,QAAK;AAEN,EAAAA,OAAA,mBAA4B;AAE5C,GAJiBA,WAAAA,SAAK,CAAA,EAAA;;;AC3FhB,IAAO,WAAP,cAAwB,YAAW;EAAzC,cAAA;;AACE,SAAA,QAAwB,IAAaC,OAAM,KAAK,OAAO;EAsEzD;;;;EAjEE,OACE,UACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa;MACxD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,UACA,WACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,aAAa,SAAS,IAAI;MACpE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,WACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa,SAAS,IAAI;MACrE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAAiD,CAAA,GACjD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,aAAa,oBAAoB;MAClF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,qBAAP,cAAkC,WAAyB;;CAuPjE,SAAiBC,WAAQ;AAKT,EAAAA,UAAA,qBAAiC;AAIjC,EAAAA,UAAA,QAAiBD;AAEjB,EAAAC,UAAA,mBAA4B;AAE5C,GAbiB,aAAA,WAAQ,CAAA,EAAA;;;ACjUnB,IAAO,QAAP,cAAqB,YAAW;;;;EAIpC,SACE,UACA,OACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,UAAU,MAAM,IAAI;MAC5E,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;EAgBA,KACE,UACA,OACA,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,OAAO,CAAA,GAAI,KAAK;;AAE7C,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,KAAK,UAAU,cAAc;MACvF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,eAAP,cAA4B,WAAmB;;CAuUrD,SAAiBC,QAAK;AAON,EAAAA,OAAA,eAAwB;AAExC,GATiB,UAAA,QAAK,CAAA,EAAA;;;ACpXhB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;EA2FzD;;;;EAtFE,OAAO,UAAkB,MAAuB,SAA6B;AAC3E,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS;MACpD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkB,OAAe,SAA6B;AACrE,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC5D,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC7D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAA6C,CAAA,GAC7C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,UAAU;MACpE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,OAAe,SAA6B;AACnE,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,WAAW;MACpE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;;;;EAQA,kBACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,wBAAwB;MACjF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,WAAP,cAAwB,WAAe;;CA6X7C,SAAiBC,OAAI;AAGL,EAAAA,MAAA,WAAmB;AAKnB,EAAAA,MAAA,QAAiB;AAOjB,EAAAA,MAAA,eAAwB;AAExC,GAjBiB,SAAA,OAAI,CAAA,EAAA;;;AC3df,IAAO,UAAP,cAAuB,YAAW;EAAxC,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;AAClD,SAAA,WAAiC,IAAgB,SAAS,KAAK,OAAO;EA8DxE;EAvDE,OACE,OAAiD,CAAA,GACjD,SAA6B;AAE7B,QAAI,iBAAiB,IAAI,GAAG;AAC1B,aAAO,KAAK,OAAO,CAAA,GAAI,IAAI;;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY;MACnC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkB,SAA6B;AACtD,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,IAAI;MAC9C,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,MAA0B,SAA6B;AAC9E,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,IAAI;MAC/C;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,UAAkB,SAA6B;AACjD,WAAO,KAAK,QAAQ,OAAO,YAAY,QAAQ,IAAI;MACjD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;;;EAKA,aAAa,MAAgC,SAA6B;AACxE,WAAO,KAAK,QAAQ,KAAK,iBAAiB;MACxC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,mCAAS,QAAO;KAC/D;EACH;;CA0NF,SAAiBC,UAAO;AAMR,EAAAA,SAAA,OAAe;AAGf,EAAAA,SAAA,WAAmB;AAKnB,EAAAA,SAAA,WAAuB;AAKvB,EAAAA,SAAA,qBAAiC;AAIjD,GAvBiB,YAAA,UAAO,CAAA,EAAA;;;AC5RlB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,OAAqB,IAAYC,MAAK,KAAK,OAAO;AAClD,SAAA,aAAuC,IAAkB,WAAW,KAAK,OAAO;AAChF,SAAA,UAA8B,IAAe,QAAQ,KAAK,OAAO;EACnE;;CAEA,SAAiBC,OAAI;AACL,EAAAA,MAAA,OAAeD;AACf,EAAAC,MAAA,aAA2B;AAG3B,EAAAA,MAAA,iBAA+B;AAI/B,EAAAA,MAAA,UAAqB;AAMrC,GAfiB,SAAA,OAAI,CAAA,EAAA;;;ACLf,IAAOC,eAAP,cAA2B,YAAW;EAa1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAG,SAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAG7F;;AA6RF,0BAAiBA,cAAW;AAO5B,GAPiBA,iBAAAA,eAAW,CAAA,EAAA;;;ACnTtB,IAAO,aAAP,cAA0B,YAAW;;;;EAIzC,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,EAAE,MAAM,GAAG,QAAO,CAAE;EAC9D;;AAyGF,0BAAiBC,aAAU;AAI3B,GAJiB,eAAA,aAAU,CAAA,EAAA;;;AC5GrB,IAAOC,SAAP,cAAqB,YAAW;;;;;;;;;;;;;;EAcpC,OAAO,MAAwB,SAA6B;AAC1D,WAAO,KAAK,QAAQ,KAAK,UAAU,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACtF;;;;EAKA,SAAS,QAAgB,SAA6B;AACpD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,IAAI,OAAO;EACrD;EAOA,KACE,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,UAAU,iBAAiB,EAAE,OAAO,GAAG,QAAO,CAAE;EACjF;;;;EAKA,IAAI,QAAgB,SAA6B;AAC/C,WAAO,KAAK,QAAQ,OAAO,UAAU,MAAM,IAAI,OAAO;EACxD;;;;EAKA,QAAQ,QAAgB,SAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAY,EAAE,GAAG,SAAS,kBAAkB,KAAI,CAAE;EAC5F;;;;;;EAOA,gBAAgB,QAAgB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAY;MAClD,GAAG;MACH,SAAS,EAAE,QAAQ,oBAAoB,GAAG,mCAAS,QAAO;KAC3D;EACH;;;;EAKA,MAAM,kBACJ,IACA,EAAE,eAAe,KAAM,UAAU,KAAK,KAAK,IAAI,IAAkD,CAAA,GAAE;AAEnG,UAAM,kBAAkB,oBAAI,IAAI,CAAC,aAAa,SAAS,SAAS,CAAC;AAEjE,UAAM,QAAQ,KAAK,IAAG;AACtB,QAAI,OAAO,MAAM,KAAK,SAAS,EAAE;AAEjC,WAAO,CAAC,KAAK,UAAU,CAAC,gBAAgB,IAAI,KAAK,MAAM,GAAG;AACxD,YAAM,MAAM,YAAY;AAExB,aAAO,MAAM,KAAK,SAAS,EAAE;AAC7B,UAAI,KAAK,IAAG,IAAK,QAAQ,SAAS;AAChC,cAAM,IAAI,0BAA0B;UAClC,SAAS,iCAAiC,EAAE,+BAA+B,OAAO;SACnF;;;AAIL,WAAO;EACT;;AAMI,IAAO,kBAAP,cAA+B,KAAgB;;CAsFrD,SAAiBA,QAAK;AAIN,EAAAA,OAAA,kBAA2B;AAG3C,GAPiBA,WAAAA,SAAK,CAAA,EAAA;;;AC1LhB,IAAO,OAAP,cAAoB,YAAW;;;;;;;;;;EAUnC,OAAO,MAAuB,SAA6B;AACzD,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAG,QAAO,CAAE;EACpE;;;;;;EAOA,SAAS,iBAAyB,SAA6B;AAC7D,WAAO,KAAK,QAAQ,IAAI,qBAAqB,eAAe,IAAI,OAAO;EACzE;EAUA,KACE,QAA6C,CAAA,GAC7C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,qBAAqB,oBAAoB,EAAE,OAAO,GAAG,QAAO,CAAE;EAC/F;;;;EAKA,OAAO,iBAAyB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,KAAK,qBAAqB,eAAe,WAAW,OAAO;EACjF;EAcA,WACE,iBACA,QAAmD,CAAA,GACnD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,WAAW,iBAAiB,CAAA,GAAI,KAAK;;AAEnD,WAAO,KAAK,QAAQ,WAAW,qBAAqB,eAAe,WAAW,yBAAyB;MACrG;MACA,GAAG;KACJ;EACH;;AAGI,IAAO,qBAAP,cAAkC,WAAyB;;AAE3D,IAAO,0BAAP,cAAuC,WAA8B;;CAiO3E,SAAiBC,OAAI;AAGL,EAAAA,MAAA,qBAA6B;AAC7B,EAAAA,MAAA,0BAAkC;AAIlD,GARiB,SAAA,OAAI,CAAA,EAAA;;;ACjTf,IAAO,aAAP,cAA0B,YAAW;EAA3C,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;EACpD;;CAEA,SAAiBC,aAAU;AACX,EAAAA,YAAA,OAAe;AAGf,EAAAA,YAAA,qBAA6B;AAC7B,EAAAA,YAAA,0BAAkC;AAIlD,GATiB,eAAA,aAAU,CAAA,EAAA;;;ACFrB,IAAO,SAAP,cAAsB,YAAW;;;;EAIrC,gBACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,sBAAsB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAClG;;;;EAKA,KAAK,MAAuB,SAA6B;AACvD,WAAO,KAAK,QAAQ,KAAK,iBAAiB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAC7F;;;;EAKA,SAAS,MAA2B,SAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,uBAAuB,EAAE,MAAM,GAAG,QAAO,CAAE;EACtE;;AA+KF,0BAAiBC,SAAM;AAMvB,GANiB,WAAA,SAAM,CAAA,EAAA;;;ACtMjB,IAAO,SAAP,cAAsB,YAAW;;;;;EAKrC,SAAS,OAAe,SAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,WAAW,KAAK,IAAI,OAAO;EACrD;;;;;EAMA,KAAK,SAA6B;AAChC,WAAO,KAAK,QAAQ,WAAW,WAAW,YAAY,OAAO;EAC/D;;;;;EAMA,IAAI,OAAe,SAA6B;AAC9C,WAAO,KAAK,QAAQ,OAAO,WAAW,KAAK,IAAI,OAAO;EACxD;;AAMI,IAAO,aAAP,cAA0B,KAAW;;CAmC3C,SAAiBC,SAAM;AAGP,EAAAA,QAAA,aAAuB;AACvC,GAJiB,WAAA,SAAM,CAAA,EAAA;;;ACjEjB,IAAO,cAAP,cAA2B,YAAW;;;;EAI1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAG,QAAO,CAAE;EAC/D;;AAoMF,0BAAiBC,cAAW;AAI5B,GAJiB,gBAAA,cAAW,CAAA,EAAA;;;;AC/HtB,IAAO,SAAP,cAA2B,UAAS;;;;;;;;;;;;;;;EAoBxC,YAAY,EACV,UAAe,QAAQ,iBAAiB,GACxC,SAAc,QAAQ,gBAAgB,GACtC,eAAoB,QAAQ,eAAe,KAAK,MAChD,GAAG,KAAI,IACU,CAAA,GAAE;AACnB,QAAI,WAAW,QAAW;AACxB,YAAM,IAAW,YACf,oLAAoL;;AAIxL,UAAM,UAAyB;MAC7B;MACA;MACA,GAAG;MACH,SAAS,WAAW;;AAGtB,QAAI,CAAC,QAAQ,2BAAgC,mBAAkB,GAAI;AACjE,YAAM,IAAW,YACf,obAAob;;AAIxb,UAAM;MACJ,SAAS,QAAQ;MACjB,SAAS,QAAQ,WAAW;MAC5B,WAAW,QAAQ;MACnB,YAAY,QAAQ;MACpB,OAAO,QAAQ;KAChB;AAOH,SAAA,cAA+B,IAAQC,aAAY,IAAI;AACvD,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAClC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,QAAmB,IAAQC,OAAM,IAAI;AACrC,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,QAAmB,IAAQ,MAAM,IAAI;AACrC,SAAA,cAA+B,IAAQ,YAAY,IAAI;AACvD,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAfhC,SAAK,WAAW;AAEhB,SAAK,SAAS;AACd,SAAK,eAAe;EACtB;EAamB,eAAY;AAC7B,WAAO,KAAK,SAAS;EACvB;EAEmB,eAAe,MAA8B;AAC9D,WAAO;MACL,GAAG,MAAM,eAAe,IAAI;MAC5B,uBAAuB,KAAK;MAC5B,GAAG,KAAK,SAAS;;EAErB;EAEmB,YAAY,MAA8B;AAC3D,WAAO,EAAE,eAAe,UAAU,KAAK,MAAM,GAAE;EACjD;;;AAEO,OAAA,SAAS;AAET,OAAA,cAAqB;AACrB,OAAA,WAAkB;AAClB,OAAA,qBAA4B;AAC5B,OAAA,4BAAmC;AACnC,OAAA,oBAA2B;AAC3B,OAAA,gBAAuB;AACvB,OAAA,gBAAuB;AACvB,OAAA,iBAAwB;AACxB,OAAA,kBAAyB;AACzB,OAAA,sBAA6B;AAC7B,OAAA,sBAA6B;AAC7B,OAAA,wBAA+B;AAC/B,OAAA,2BAAkC;AAGpC,IAAM,EACX,aAAAC,cACA,UAAAC,WACA,oBAAAC,qBACA,2BAAAC,4BACA,mBAAAC,oBACA,eAAAC,gBACA,eAAAC,gBACA,gBAAAC,iBACA,iBAAAC,kBACA,qBAAAC,sBACA,qBAAAC,sBACA,uBAAAC,wBACA,0BAAAC,0BAAwB,IACtB;AAEE,IAAQC,UAAiB;AACzB,IAAQC,gBAAuB;CAErC,SAAiBC,SAAM;AAEP,EAAAA,QAAA,SAAiB;AACjB,EAAAA,QAAA,eAAuB;AAIvB,EAAAA,QAAA,OAAkB;AAGlB,EAAAA,QAAA,aAAwB;AAIxB,EAAAA,QAAA,cAAkBjB;AAQlB,EAAAiB,QAAA,OAAW;AAwBX,EAAAA,QAAA,aAAiB;AAKjB,EAAAA,QAAA,QAAYhB;AAIZ,EAAAgB,QAAA,kBAAsB;AAItB,EAAAA,QAAA,SAAa;AAOb,EAAAA,QAAA,QAAY;AAEZ,EAAAA,QAAA,cAAkB;AAKlB,EAAAA,QAAA,SAAa;AAGb,EAAAA,QAAA,aAAiB;AAEjB,EAAAA,QAAA,aAAiB;AAEjB,EAAAA,QAAA,OAAW;AAI3B,GApFiB,WAAA,SAAM,CAAA,EAAA;AAsFvB,IAAA,iBAAe;",
  "names": ["fetch", "Request", "Response", "Headers", "FormData", "Blob", "File", "ReadableStream", "ReadableStream", "_a", "str", "File", "_a", "FormData", "fetch", "opts", "Page", "_a", "retryMessage", "_a", "_a", "Completions", "Chat", "Speech", "Transcriptions", "Translations", "Audio", "Files", "Assistants", "__classPrivateFieldSet", "__classPrivateFieldGet", "_a", "content", "_AbstractChatCompletionRunner_getFinalMessage", "_AbstractChatCompletionRunner_getFinalFunctionCall", "_AbstractChatCompletionRunner_getFinalFunctionCallResult", "_AbstractChatCompletionRunner_calculateTotalUsage", "_AbstractChatCompletionRunner_validateParams", "_AbstractChatCompletionRunner_stringifyFunctionCallResult", "__classPrivateFieldGet", "_a", "_ChatCompletionStream_beginRequest", "__classPrivateFieldSet", "_ChatCompletionStream_addChunk", "_ChatCompletionStream_endRequest", "_ChatCompletionStream_accumulateChatCompletion", "content", "rest", "index", "chunk", "id", "Completions", "Chat", "Completions", "Files", "Files", "Messages", "Steps", "Runs", "Threads", "Chat", "Beta", "Completions", "Embeddings", "Files", "Jobs", "FineTuning", "Images", "Models", "Moderations", "Completions", "Files", "OpenAIError", "APIError", "APIConnectionError", "APIConnectionTimeoutError", "APIUserAbortError", "NotFoundError", "ConflictError", "RateLimitError", "BadRequestError", "AuthenticationError", "InternalServerError", "PermissionDeniedError", "UnprocessableEntityError", "toFile", "fileFromPath", "OpenAI"]
}
